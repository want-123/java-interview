重写版

# Java

## Java基础

### lambda表达式和函数式接口

其实，我们可以将lambda表达式，就是实现了函数式接口的那一个抽象方法。

在 Java 中，**函数式接口**是一个只包含**一个抽象方法**的接口（可以有多个默认方法或静态方法，但只能有一个抽象方法）。

### 序列化的意义是什么？

- **序列化的本质**就是将复杂的数据结构（如对象、结构体等）转换为**字节流**（byte stream）。
- 网络传输只能传输**字节流**，不支持直接传输高级编程语言中的对象、数据结构等。这是因为网络协议（如 TCP/IP）在传输数据时，只能处理一系列的字节，而无法直接理解 Java、Python、C++ 等编程语言的数据结构。
- **序列化**会将数据转成字节序列，传输到目标机器后再进行反序列化，将字节流还原成原来的数据结构。

### Clone方法

- 默认情况下，想要调用clone，就必须实现Cloneable接口，然后重写clone方法。如果重写方法是调用父类的clone，即调用super.clone()，那其实是一个浅拷贝。即拷贝一个对象，如果成员变量是基础类型，就赋值，如果是对象，那么就只是创建一个引用，指向了原先的对象。
- 还有一种方式是使用序列化与反序列化来实现对象的拷贝。即先将一个对象序列化到一个二进制文件，然后再将该对象反序列化出来，这样即是两个完全不同的实例。但要支持序列化，对应的类需要实现 `Serializable` 接口。此外，因为使用序列化与反序列化比较重，其性能不如原生的 `clone()` 方式。

### 自定义注解

- 使用@interface进行修饰。

  - ```java
    public @interface Information {
    }
    ```

  - 想要使用注解，如果是在Spring环境下，可以利用AOP，针对于注解方法做一个前置通知，在前置通知里写好具体的处理逻辑。

  - 如果在非Spring的环境下，那么就需要利用反射，然后检查对应的方法或者字段上有没有注解，有注解再根据注解里的信息做具体的操作。

    - ```java
      public static void main(String[] args) throws Exception {
              Class<?> clazz = PersonService.class;
              Method method = clazz.getMethod("outputPersonInfo", Person.class);
              if (!method.isAnnotationPresent(Information.class)){
                  System.out.println(method.getName()+"方法没有标注@Information注解！");
                  return;
              }
              Person person = new Person();
              Information information = method.getAnnotation(Information.class);
              person.setName(information.name());
              person.setAddress(information.address());
              person.setAge(information.age());
              person.setHobbies(Arrays.asList(information.hobbies()).toString());
              PersonService personService=new PersonService();
              method.invoke(personService,person);
          }
      ```

### 元注解

- 元注解就是专门修饰注解的注解。
- 比如可以用来标记该注解可以用于哪里，是方法还是参数，还是成员变量。@Target注解。
- @Retention，即用来修饰自定义注解的生命力
- @Document注解，指定自定义注解是否能随着被定义的java文件生成到JavaDoc文档当中

### jdk和jre的区别是什么

jre：是java的运行环境，即Java runtime enviroment，面向的是Java程序的使用者，即安装jre后，可以运行java程序，但是不能开发。这里不包含编译器和调试器，即只包含核心类库，jvm等。

jdk：java development kit，是Java的标准开发工具包，包含了jre，且有编译和调试工具。

### JDK21新特性

- 为 Java 集合框架引入了序列化集合接口，使得集合如 `Set` 和 `Map` 可以按照插入顺序进行遍历。
- 引入了一种新的变量类型 `Scoped Values`，支持在多线程中安全地传递不可变数据，替代 `ThreadLocal`。
- 将虚拟线程引入 Java 平台，为并发编程提供轻量级线程的支持。
  - 而`虚拟线程`是JDK基于`平台线程`实现的`轻量级线程`，`虚拟线程`依附于`平台线程`(此时称为`载体线程`)运行，它的创建成本很低，不会像平台线程独占操作系统线程，Java 通过将大量虚拟线程映射到少量平台线程来提供充足线程的假象。

### JDK17新特性

- Sealed Classes，允许类或接口限制哪些类可以扩展或实现它们。

  ```java
  public sealed class Shape permits Circle, Square { }
  public final class Circle extends Shape { }
  public final class Square extends Shape { }
  ```

### 接口可以由哪些关键字修饰

- 接口可以用public和abstract进行修饰。自java 1.9之后，接口可以使用private进行修饰。
  - 当使用private 和 default修饰接口时，必须要实现该接口，即该接口必须要有具体的实现，而不能是一个抽象的方法。
  - private 方法可以用于接口内部的辅助方法，**主要是为了减少代码重复和提高代码的封装性。这些 private 方法不能被实现类访问**，一般用于default方法当中。
  - 接口中的方法，默认是public abstract修饰的。用abstract修饰的方法，子类在实现或者继承时，必须要实现该方法。
- 接口无法使用static关键字修饰，也无法使用protected修饰。
  - 因为接口不是一个具体的类，无法被实例化，所以不能用static修饰。
  - **使用protected修饰的方法，只能在被同一个包中的类或者子类访问**，这其实与接口的设计理念相悖。

### Final有什么作用

- 被final修饰的类不可以被继承 
- 被final修饰的方法不可以被重写
- 被final修饰的变量不可以被改变。如果修饰引用，那么表示引用不可变，引用指向的内容可变。
-  被final修饰的方法，JVM会尝试将其内联，以提高运行效率 ，(内联：将方法代码复制粘贴到调用方法处)
- 被final修饰的常量，在编译阶段会存入常量池中。

### Integer 与String 的可变性

```java
public static void main(String[] args) {
    LKHot100 lkHot100 = new LKHot100();
    Integer a = 1;
    lkHot100.test(a);
    System.out.println(a);
}

public void test(Integer i) {
    i++;
}
```

这段代码中，输出的a的值是1。因为Integer也具有不可变性，在上边做修改就会new 一个新的对象出来，虽然对象传递的是引用，但是由于Integer不可变，在内部的修改时会将引用只想一个新的Integer 2。

这里的a是一个引用，传递过后，i是a引用的拷贝，并不是a引用本身。他们同时指向原先的1，但是++过后i就指向了一个新的对象。原先的a还是指向之前的1。

- 针对于String的一些问题，如果我们new String("111")，哪怕字符串常量池中已经存在了111这个字符串，仍然会在堆中创建一个新的111字符串对象，如果字符串常量池中没有，那么也会在常量池中增加一个111。

### StringBuilder默认容量，扩容机制

- 默认的容量是16
- 扩容机制的话，每次扩大2倍再加2。
- 然后会将旧的数据复制到新的char数组中，并追加新的内容。

### Integer相关介绍

- 首先，Integer是一个包装类，是一个对象。
- 它缓存了-128-127之间的数字，如果使用Integer a = 1 或者Integer a = Integer.valueOf() 这种写法，如果数值范围在缓存范围内，就会返回已经缓存的对象。否则会去创建新的对象。
- 至于说进行比较，== 一般默认的是比较两个对象指向的地址是否相同，相同则为true。而使用equals进行比较，则看我们是否重写了equals，如果没重写则默认方式也是按照 == 进行比较。

### oop、面向对象的特性？

- 面向对象的特性就是封装、继承、多态
- **封装**：封装是将对象的状态（属性）和行为（方法）包装在一起的过程。这可以**隐藏对象的内部实现细节**，只通过对象提供的方法来访问和修改对象的状态。
- **继承**：继承是一种可以创建新类的方式，新类继承了一个或多个已存在的类的属性和方法。这使得代码可以被复用。
- **多态**：多态是指一个接口可以被多种实际类型所实现。在运行时，可以根据实际类型来执行相应的方法。这使得代码更加灵活和可扩展。**调用同一个方法，显示出不同的结果**。
- java当中，一切皆对象，不同于C语言这种面向过程的，他往往采用高度封装，将对应的方法封装到对象中，然后通过不同的对象调用不同的方法，替代C语言一个一个函数实现的功能。

### **面向对象的开闭原则？**

- 对扩展开放，对修改封闭

### java 与c++的区别？

- 最大的一个区别，Java有垃圾收集器，不需要程序员手动回收内存垃圾，而C++则需要手动回收。
- 另一方面，C++应该是编译后执行，而Java 是编译与解释共存的。
- Java有虚拟机，跨平台特性比较好。

### 多态的实现原理（方法表）？

- 通过方法表。方法表中存储了每一个方法的名称，以及参数列表。包括它的返回值类型。
  - Java 虚拟机（JVM）在运行时为每个类维护一张方法表（method table），它包含了该类及其所有父类中的方法信息。当一个对象调用某个方法时，JVM 会根据对象的实际类型，通过方法表找到对应的实现，从而实现**动态绑定**（也就是我们所说的多态机制）。
  - Java运行时多态的底层原理依赖于：
    1. **动态方法分派**：JVM在运行时根据对象的实际类型来决定调用哪个方法。
    2. **虚方法表（V-Table）**：用于记录每个类的虚方法，并在运行时进行方法查找。
    3. **`invokevirtual`字节码指令**：确保方法调用时根据对象的实际类型动态选择正确的方法。
  - **其实在实际调用时，会先确定对象的实际类型(对象头重Klass Pointer会指向Class对象)，然后拿到实际类型的方法表，然后根据具体的名称以及参数找到具体要调用的方法。**
  
- 其实，上边说的可能是定位某一个具体方法的原理。
- 多态的实现从表面上来看，主要是基于继承和实现接口这两种方案来实现的。
- 子类继承父类，拥有父类的非私有的方法和成员属性，可以重写父类非final修饰的方法。

### ==和equals的区别？

- 这里取决于我们是否重写了equals方法。如果我们未重写equals方法，那么Object自带的equals方法就是返回==。对于基础类型的变量，比较的是他们的值，而对于对象这种，比较的就是他们的引用只想的是否是同一个对象。

- 而重写equals方法后，就取决于我们自定义的思路。

### 什么是反射？反射怎么用？优缺点？

- 反射是java语言的一种特性，它允许我们在运行时动态获取类，包括类的方法，成员变量，并执行类的某些方法。提供了更高的灵活性。
- 缺点就是反射的运行效率会相对低一点，原因？因为反射是在运行时进行类型检查和动态调用，直接调用是在编译时检查的。
- 另外，反射的一些错误可能在运行时才会发现，这增加的调试的成本。

```java
public class Test {
  public static void main(String[] args) {
    Class clazz = Class.forName("");
      // 获取String类的Class实例
Class<String> stringClass = String.class;
      String str = new String("test");
// str是String实例，返回String的Class
Class<? extends String> strClass = str.getClass();
  }
}
```

### 反射的原理是什么？

- 在加载类的时候会为类创建Class对象
- 通过三种方法获取到Class对象后，通过Class对象API去获取属性或者方法

### 反射获取private属性或者方法的原理是什么？

- 通过setAccessible(true)可以告诉编译器暂时不对该属性进行访问权限的检查

### 泛型，上下界问题？

- 泛型是参数化类型，将类型参数化。示例：

- ```java
  ArrayList list = new ArrayList();//没有规定list里面元素的类型
  list.add("aaaa");//不会报错
  list.add(111);//不会报错
  //编译时不会报错，但是运行时报错，因此我们希望在编译时进行类型的检测，那么就可以使用泛型，比如
  ArrayList<String> list = new ArrayList<>();
  list.add(111);//编译时报错
  ```

- 泛型方法

- ```java
  public <T> T getV(T value){
      return value;
  }
  //普通方法可以操作的数据类型单一，而泛型方法可以操作多种数据类型
  Integer v1 = getV(1111);
  String v2 = getV("ssssssss");//自动推断数据类型
  Double v3 = MyClass.<Double>getV(3.14);//显式设置T的类型
  ```

- 假设我们的泛型为<? extends City>(上界)，那就意味着所有继承了City 的类，即City的所有子类都可以。可读不可写

- ```java
  ArrayList<Integer> list1 = new ArrayList<>();
  list1.add(1);
  list1.add(2);
  
  ArrayList<String> list2 = new ArrayList<>();
  
  void printList(ArrayList<? extends Object> list){
      for(Object obj : list){
          Sytem.out.println(obj);
      }
  }
  
  //只可读，不可写，因为不能确定具体是哪一个子类,假设list实际指向的是一个ArrayList<Integer>, 那么虽然Double是NUmber的子类，但是却不能使用list.add(Double)，会出现类型转换错位。
  ```

- 如果是<? super City>(下界)，那就意味着只有City的父类直到Object才可以。可写不可读

- ```java
  ArrayList<? super Number> list = new ArrayList<>();
  list.add(new Integer(1));//编译正确
  list.add(new Float(1.1));//编译正确
  //只可写不可读，假设list实际指向的就是Arraylist<Number>,那么Integer或者Float转向NUmber是可以的(子类转向父类是安全的)。但是由于不清楚到底是哪个类型，获取的时候也就不知道因该转成什么类型读取，所以不可读(但是可以转成Object进行读取)
  ```

- java是伪范型，编译过后范型就被擦除了。

### 为什么重写了equals同时要重写hashcode？

- 最重要的原因在于，Java 的有些方法可能会同时根据这两者来判断一个对象是否相等。
- 比如说Java 的hashmap，它就是先根据hashcode来确定元素应该位于哪个桶，**然后再根据equals方法来判断是要覆盖，还是发生了冲突，要解决哈希冲突。**
- Java里边有一个要求，如果两个对象的equals相等，那么hashcode必须相等。
- 如果两个对象的hashcode不相等，那么equals必须不相等。

### oom 和 stackoverflow区别？什么情况下会出现？

- oom是堆满了报错。主要原因可能是我们创建了大量的对象，解决办法是：考虑引入对象池，看看是否可以通过对象复用减少新对象的创建。
- 另外，如果栈允许向堆申请内存，那么栈这边递归过深的时候，一值向堆中申请内存，会导致堆益处。
- stackoverflow是虚拟机栈溢出报错。最大的可能是某个递归的方法，一直没有出口，导致一直在创建栈贞，一直压栈，导致溢出。
- 虚拟机栈，是每个线程私有的，一个线程每次调用方法，都会创建一个栈帧，并且栈帧会入栈，栈帧中会存储方法的局部变量，包括指向对象的引用，动态链接等。如果这些内容过多，也可能导致栈溢出。

### sleep和wait的区别

- sleep和wait都是阻塞当前线程，但是最大的区别在于sleep在给定时间过后可以直接被jvm唤醒，而调用wait的线程则只能等到有某个线程调用notify才可以被唤醒。
- **`sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁** 。
- `wait()` 通常被用于线程间交互/通信，`sleep()`通常被用于暂停执行。

### wait 和 notify为什么必须在同步代码块中使用？

- 这里主要是为了一致性。假设不在同步代码块中，我们一个线程在执行wait到一半时被打断，另一个线程执行了notify，却没有唤醒任何线程，当线程切换回去后，完成了完整的wait。那么这个线程就会一直等待，无法被唤醒。（**保证wait和notify方法的原子性**）

- 另外一点，调用wait时，会在对应的作为加锁对象的类的阻塞队列中，加入当前线程。用于后续notify唤醒线程。

- ```java
  Test test = new Test();
  Test test2 = new Test();
  synchronized (test) {
    test2.wait();
  }
  ```

- 上述代码，~~被当作锁的对象时test，它有一个阻塞队列，当test2调用wait时，就会将当前线程加入到test的阻塞队列中，后续有获取到test的监视器锁的线程，调用notify时，就会从队列中随机唤醒一个线程。~~

- 上述代码在执行时，会报错InterruptedException，因为调用wait的并非当前拥有锁的线程。current thread is not owner。锁是加在test，即当前线程只拥有了test对象的监视器锁，它并没有拥有test2对象的监视器锁。

- ```java
  Test test = new Test();
  Test test2 = new Test();
  synchronized (test) {
    test.wait();
  }
  ```

- 每个对象都会有一个等待集合，**当对象调用wait时，当前线程就会被加入等待集合当中。**

- 当另一个试图获取test对象的监视器锁的线程，如果获取失败，会被阻塞，进入对象的池锁当中。

- 当调用了nofityAll的时候，该对象的等待队列中所有线程都会被设置为可运行状态，然后他们会去争抢锁，谁拿到锁谁就可以执行，没拿到锁的继续阻塞。调用notify也是同样的效果，进入可运行的状态。

### java的深拷贝与浅拷贝

- 深拷贝就是说会拷贝整个对象，包括它的成员属性，比如说它有某个成员属性是另外一个对象，那么深拷贝会在堆中也创建一个一摸一样的对象。~~但是浅拷贝仅仅会创建一个引用，指向同一个对象。~~

- 浅拷贝，会创建一个新的对象，但是对象内部的成员属性，如果有其他对象，那么就只是拷贝一个引用，如果是基础类型，那就拷贝值。

  - ```java
    class Address {
        String city;
        Address(String city) {
            this.city = city;
        }
    }
    
    class Person implements Cloneable {
        String name;
        int age;
        Address address;
    
        Person(String name, int age, Address address) {
            this.name = name;
            this.age = age;
            this.address = address;
        }
    
        // 浅拷贝，通过实现 Cloneable 接口
        @Override
        protected Object clone() throws CloneNotSupportedException {
            return super.clone();  // 默认实现是浅拷贝
        }
    }
    
    public class Main {
        public static void main(String[] args) throws CloneNotSupportedException {
            Address address = new Address("New York");
            Person person1 = new Person("John", 30, address);
    
            // 浅拷贝
            Person person2 = (Person) person1.clone();
    
            // 修改person2的地址
            person2.address.city = "Los Angeles";
    
            System.out.println(person1.address.city);  // 输出 "Los Angeles"
            System.out.println(person2.address.city);  // 输出 "Los Angeles"
        }
    }
    
    ```
  
- 但是深拷贝会创建一个完全独立的对象。它的成员属性如果是对象，也会重新创建。

  - ```java
    class Address implements Cloneable {
        String city;
    
        Address(String city) {
            this.city = city;
        }
    
        @Override
        protected Object clone() throws CloneNotSupportedException {
            return super.clone();  // 浅拷贝实现
        }
    }
    
    class Person implements Cloneable {
        String name;
        int age;
        Address address;
    
        Person(String name, int age, Address address) {
            this.name = name;
            this.age = age;
            this.address = address;
        }
    
        // 深拷贝，递归克隆引用类型
        @Override
        protected Object clone() throws CloneNotSupportedException {
            Person cloned = (Person) super.clone();
            cloned.address = (Address) address.clone();  // 深拷贝 Address 对象
            return cloned;
        }
    }
    
    public class Main {
        public static void main(String[] args) throws CloneNotSupportedException {
            Address address = new Address("New York");
            Person person1 = new Person("John", 30, address);
    
            // 深拷贝
            Person person2 = (Person) person1.clone();
    
            // 修改person2的地址
            person2.address.city = "Los Angeles";
    
            System.out.println(person1.address.city);  // 输出 "New York"
            System.out.println(person2.address.city);  // 输出 "Los Angeles"
        }
    }
    ```


### 静态方法为什么不能调用非静态的成员变量？静态属性和方法属于谁的？

- 这里的主要原因在于，静态变量和静态方法是属于类的，即Class对象，而不属于这个Class对象的某个实例。所以说某一个静态方法，无法调用属于某一个实例的成员变量。
- 静态方法无法调用非静态的成员属性，但是非静态方法可以调用静态的成员属性
  - 因为静态变量在类加载的时候就已经被初始化了，并不从属于某一个实例，并不需要管该实例是否被实例化。
  - 而静态方法则属于Class对象，如果不实例化一个对象，它是无法调用对象的非静态成员属性的。

### 一个Java对象有哪些部分组成

- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250825165811118.png" alt="image-20250825165811118" style="zoom: 25%;" />
- 一个对象分为：对象头，对象体和对齐字节
  - 对象头
    - _mark Word：包括GC年龄、哈希码和锁标记(锁状态)
    - _klass Pointer（类对象指针），用于存放此对象的元数据（InstanceKlass）的
      地址。通过klass指针，虚拟机通过可以确定这个对象是哪个类的实例
    - Array Length（数组长度）
  - 对象体
    - 成员变量
  - 对齐字节： 填充对齐，其作用是用来保证Java对象在所占内存字节数为8的倍数

### 一个java对象，它的属性都存储在哪个位置？

- **堆内存（Heap）**：用于存储对象实例及其成员变量，静态变量，字符串常量池

- **方法区（Method Area）**：存储类信息、~~静态变量~~、运行时常量池、方法字节码（包括静态方法和非静态方法）。

- **栈内存（Stack）**：存储方法的局部变量、方法调用帧、返回值和操作数栈。

所以说，一个对象的创建，它的非静态成员变量，会连同该对象的实例，一起存储在堆当中。而它的静态属性，就会存储在方法区，或者叫元空间当中。

**而它的方法，不管是静态的还是非静态的，都会存储在方法区当中。**

### **Java为什么是解释与编译共存的**

- 因为Java 的普通代码，经过编译后，会变为JVM可以识别的字节码，这些字节码会被jvm边解释边执行。（这里是解释为机器码）。对于那些反复执行的热点代码，会直接编译为机器码缓存起来。所以说它的编译与解释共存的。

### java的string为什么是不可变的

- 最核心的原因是，string里边的byte数组，是由final和private修饰的。不可被继承，也没有直接提供修改的set方法，所以说是无法修改的。

### String设计为不可变的好处是什么？

- 作为Map的key，提高了访问效率：String的不可变使得能将hash值缓存起来，不用重复计算
- 不可变性天生线程安全
- 字符串常量池得以实现

### 什么是spi

- spi，**Service Provider Interface**，即服务提供者接口，主要用于扩展、修改原来的框架。

- ~~我个人的理解，SPI它是相当于某个工具类，他提供了一组接口，然后他封装好调用接口的代码。而将具体接口的实现交给了我们。API是接口的提供者和实现者是一起的，而SPI是接口的实现者和提供者分开了。~~
- 像java提供的spi机制，主要是允许在运行时动态的去加载某个接口的实现类，而不是在编译阶段去进行。即在运行时动态的发现服务的实现，而不是编译时执行。
- 为某个接口寻找服务实现的机制。
- 一个典型的例子就是JDBC，它是由Java提供了一组接口，但是实现确实由不同的数据库厂商去自定义实现的。
- **另一种说法，spi是一种运行时动态发现和加载实现接口的服务提供者。**
- 针对于普通的类，在编译时就已经知道了要加载的具体的类是什么，new MyClass()，在编译时已经知道了要加载MyClass这个类，但是还未加载。代码实际执行到这里时才加载。而spi相关的类，在编译时并不知道要加载哪个类。

### **Java的异常体系？顶级父类是什么？**

- 最顶级的父类是Throwable。有两个子类
- 分为两类，一种是Exception，这种是可以被捕获处理的。一种是error，这种是比较严重的，一般是jvm出现错误，无法继续运行。
- 而Exception又分为两种，一种是运行时异常(**非受检异常**)，这种是我们代码运行时报错，我们选择是否捕获处理，一种是编译时异常(受检异常)，这种不处理代码无法通过编译。

### Java的集合体系，顶级父类是什么？

- 是Collection

- ```tex
  Collection
  ├─ List
  │  ├─ ArrayList
  │  ├─ LinkedList
  │  └─ Vector
  │     └─ Stack
  ├─ Set
  │  ├─ HashSet
  │  │  └─ LinkedHashSet
  │  └─ TreeSet
  └─ Queue
     ├─ LinkedList
     ├─ ArrayDeque
     └─ PriorityQueue
  
  Map
  ├─ HashMap
  │  └─ LinkedHashMap
  ├─ TreeMap
  ├─ Hashtable
  └─ ConcurrentHashMap
  ```

  

### java 内存泄漏？

- 内存泄漏就是有些对象已经不再被引用，也就是不再使用了，但是没有被回收，导致内存的浪费。一种比较经典的场景就是Threadlocal，它存在一种情况，key已经不在了，但是value还在。
- 原因：ThreadLocal的key是一个弱引用（专门这样设计的），而value的值则是一个强引用。key比较容易被回收。
- 解决办法：每次调用时，会检查是否存在key为null的，如果存在就remove。

### **接口和抽象类的区别是什么？**（从语法角度和设计角度去考虑）

- 从语法角度，abstract修饰的类是抽象类，而且它的成员变量可以用所有修饰符修饰。而接口只能用public修饰，1.9之后可以用private修饰，但只能用于接口内的default方法。
- 从设计角度：抽象类一般是对一个类整体的抽象，它更多的描述的是is-a的关系。而接口则是对类部分的抽象。比如说我们可以定义一个接口，有一个方法fly，那么鸟和飞机都可以实现这个接口，代表这两个类有一个都有一部分的特性相同，即他们都可以飞。但是一般不会定一个抽象类，让这两个类去继承这个抽象类。抽象类更多的是为了代码的复用。

### 继承中的构造器问题

- 对于无参父类构造函数，如果在子类的构造函数中没有显式地调用，编译器会默认加上super()
- 如果父类有参数构造，那么子类必须要在自己的构造函数中**显式地调用super**(参数1，参数2，... )

### JIT的原理？什么是JIT？（即时编译器）

- 前端编译:编译器（javac）将源文件（.java）编译成java字节码文件（.class）的步骤是前端编译。
- 解释执行: 在JVM加载字节码后，每次执行方法调用时，JVM都会将字节码翻译成机器码，然后执行机器码，这个 过程叫解释执行。**启动快，执行慢**
- 编译执行:与解释执行相反，JVM加载字节码的时候，直接将字节码转换为机器码，在执行方法调用时直接执行机 器码，不需要做翻译工作，这样的过程叫编译执行，**执行快，启动慢**

- JIT，即即使编译器，又称为运行时编译。

- JIT的主要作用就是在运行时将经过**编译器编译的字节码转化为机器码**。
- ~~他可以实现解释执行。~~
- 注意：解释执行的是jvm虚拟机，它负责将字节码解释执行，而jit则是主要负责将热点代码编译为机器码然后执行。
- 另外，它也可以讲反复执行的热点代码直接编译为机器码，然后存储起来，下次执行时就不用变解释边执行。

### Java的基本数据类型，每个类型占用多大空间？

- int 4字节 32位，
- long 8字节64位，
- double 8字节64位，
- bollean 1字节，
- char  2字节16位、
- byte 1字节 8位、
- short 2字节 16位，
- float 32位，4字节。

### 形参和实参的区别？

- 形参就是方法内部传进来的，就是形参，而实参就是调用方法时传递的值。

### Java中值传递和引用传递的区别？

- 值传递，往往都是基本类型，它会复制一份实参，在方法内修改不影响原来的实参。
- 而引用传递，它传递的是指向实参的一个引用，对引用传递的修改会影响到原来的数据。

### java中形参是数组或者对象的话，修改形参会影响实参吗

- 会。
- 因为数组是对象的一种，当参数传递的是对象时，并不会直接拷贝一份对象，而是传递对象的引用，那么方法中操作的对象实际上指向的就是方法外的对象。

### JDK动态代理为什么只能基于接口？

- 因为Java是单一继承的，JDK的动态代理会让每一个代理类都继承一个Proxy类，继承了该类后如果用户传入的是一个类，就无法继续继承用户的类，拿不到用户的方法，就无法在用户原有的功能基础上做扩展。**所以只能依赖于用户提供接口，拿到用户的实现类，在上边做扩展**。

- 另一方面，只有接口才可以实现多态。才能在运行时动态的去确定调用哪一个具体的类，才能够替换掉我们自己实现的类，直接调用代理类。

- **基于接口的代理**：JDK动态代理依赖于**接口**。只有实现了某个接口的类才能通过JDK动态代理来生成代理对象。如果一个类没有实现任何接口，就无法使用JDK动态代理。

  **核心类：`java.lang.reflect.Proxy`**：JDK动态代理通过 `Proxy` 类和 `InvocationHandler` 接口来实现动态代理。

  **代理对象在运行时生成**：代理类不会在编译期生成，而是在运行时通过反射机制动态生成。
  
  ```java
  import java.lang.reflect.InvocationHandler;
  import java.lang.reflect.Method;
  import java.lang.reflect.Proxy;
  
  // 定义一个接口
  interface Subject {
      void request();
  }
  
  // 实现接口的具体类
  class RealSubject implements Subject {
      @Override
      public void request() {
          System.out.println("RealSubject: Handling request.");
      }
  }
  
  // 实现 InvocationHandler 接口
  class ProxyHandler implements InvocationHandler {
      private final Object target;
  
      public ProxyHandler(Object target) {
          this.target = target;
      }
  
      @Override
      public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
          System.out.println("Before method call");
          Object result = method.invoke(target, args);//在这里调用具体类的方法，通过反射拿到具体类方法的Method对象，调用method.invoke(目标类，参数)就能调用具体的方法
          System.out.println("After method call");
          return result;
      }
  }
  
  public class DynamicProxyExample {
      public static void main(String[] args) {
          // 创建真实对象
          RealSubject realSubject = new RealSubject();
  
          // 创建 InvocationHandler 对象
          ProxyHandler handler = new ProxyHandler(realSubject);
  
          // 创建代理对象
          Subject proxySubject = (Subject) Proxy.newProxyInstance(
                  Subject.class.getClassLoader(),
                  new Class<?>[]{Subject.class},
                  handler
          );//Proxy类的静态方法生成代理对象
  
          // 调用代理对象的方法
          proxySubject.request();
      }
  }
  ```
  
  

### CGLib实现动态代理

- **运行时生成字节码**：当你通过 CGLIB 动态代理为目标类创建代理对象时，CGLIB 使用 **ASM 库（字节码操作库）**来动态生成一个新的子类，并在这个子类中重写目标类的方法，注入代理逻辑。整个代理对象的生成过程是在**运行时**完成的。
- 被代理的类必须能够被继承，如果是final修饰的，则无法使用cglib动态代理。

### ArrayList遍历期间删元素

- 如果是从前往后遍历，那么就会出现问题。因为ArrayList每删除一个元素之后，后边的元素会往前移动。且可能出现数组越界。
- 从后往前遍历删除后边的元素不影响。
- 或者**使用迭代器，迭代器是将其转化为了链表**。(错误)
- 迭代器的原理是指针cursor指向当前迭代的位置

### java重载与重写的区别？

- 重写主要指的是**子类重写父类的方法**，一个类需要存在继承关系才可以重写。而且无法重写父类用final修饰的方法。

- 重载的话是在一个类内部就可以完成的，**多个方法同名，但是参数不同**，~~返回值也可以不同~~，返回值并不能作为重载的条件。

  > 注意，Java中确定一个方法的唯一性是根据**方法的名称以及参数列表来确定的。**
  >
  > 普通方法的重载，比如说同一个类当中的，在编译时根据参数就可以确定调用的是哪一个方法。
  >
  > 但是基于继承的重载，就没有这么好确定。
  >
  > **对重载方法的选择，是根据变量的静态类型来确定的，而不是实际类型**。比如代码`Human man = new Man()`，`Human`就是变量`man`的静态类型，而`Man`是它的实际类型。我们都知道，在多态的情况下调用方法，会根据实际类型调用实际对象的方法，但是在重载中，是根据静态类型来确定调用哪一个方法的。

方法的重载，是在jvm编译期间就可以确定具体调用的是哪个方法。

而重写的方法，是在运行时动态确定的，这种也叫多态。

### static加在方法上和加在代码块上有什么区别？

- 如果加在方法上，就表明了该方法是属于某个类的，可以直接通过类名去调用这个方法。
- 如果加在代码块上，他有点类似于类初始化的代码。在类加载阶段，会执行该类的静态代码块。**静态代码块**是定义在类中的静态（`static`）块，**它在类被加载到内存时执行，只执行一次**。静态代码块常用于初始化类的静态变量。

### java中线程的run和start有什么区别

- **1.start()** 方法来启动线程，真正实现了多线程运行。这时无需等待 run 方法体代码执行完毕，可以直接继续执行下面的代码；通过调用 Thread 类的 start() 方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运行。 然后通过此 Thread 类调用方法 run() 来完成其运行操作的， 这里方法 run() 称为线程体，它包含了要执行的这个线程的内容， run 方法运行结束， 此线程终止。然后 CPU 再调度其它线程。
- **2.run()** 方法当作普通方法的方式调用。程序还是要顺序执行，要等待 run 方法体执行完毕后，才可继续执行下面的代码； 程序中只有主线程——这一个线程， 其程序执行路径还是只有一条， 这样就没有达到写线程的目的。

> 总结来看，其实run并不是真正意义的多线程，它的代码执行还是顺序的。但是start却不一样，它使得当前的线程处于就绪状态，然后可以直接执行后续的代码。当线程分配到cpu之后，会去执行thread中的run方法内的代码。

### hashmap底层数据结构是什么

- 主要是一个数组 + 链表的形式。冲突较多时会转化为数组 + 链表 + 红黑树
- 这里在jdk1.7和1.8的实现还是有些不同的，1.8才开始使用红黑树优化链表。

### 单例有哪些实现方式？懒汉式怎么保证线程安全？

- 懒汉式

  ```java
  public class Singleton {
      private static Singleton instance;
  
      private Singleton() {}
  
      public static synchronized Singleton getInstance() {
          if (instance == null) {
              instance = new Singleton();
          }
          return instance;
      }
  }
  ```
  

这种方式是在真正使用该对象的时候才会去创建对应的对象。

保证线程安全就是采用加锁的方式，**即每次只能有一个线程来访问。**

- 饿汉式

  ```java
  public class Singleton {
      private static final Singleton INSTANCE = new Singleton();
  
      private Singleton() {}
  
      public static Singleton getInstance() {
          return INSTANCE;
      }
  }
  ```

  该方式创建的单例是线程安全的。因为使用了static修饰，它在执行类加载的时候就被创建了。

- 双重锁校验

  ```java
  public class Singleton {
      private static volatile Singleton instance;
  
      private Singleton() {}
  
      public static Singleton getInstance() {
          if (instance == null) {
              synchronized (Singleton.class) {
                  if (instance == null) {
                      instance = new Singleton();
                  }
              }
          }
          return instance;
      }
  }
  ```

  这种方式确保了线程安全，而且性能会好。
  
  在上面的代码中，`instance = new Singleton();` 这个操作实际上是一个非原子的过程，通常可以分为三步：
  
  1. 分配内存空间
  2. 初始化对象
  3. 将内存地址赋值给 `instance` 变量

如果不使用volatile修饰，可能会发生指令冲排序，即2、3两步交换，那么就会出现引用已经指向了内存空间，但是却没有初始化对象。

### 受检异常和非受检异常的区别，有哪些非受检异常

- 从我观察到的结果来看，受检异常和非受检异常可能类似于编译时异常和运行时异常。
  - 其中受检异常就是编译时异常，如果不进行处理是没有办法通过编译的。
  - 而非受检异常就是运行时异常。编译器不需要强行检查这些异常。

- NullPointerException

### string的定义方式（直接赋值和new String）及区别

- 直接赋值
  - 用直接赋值的方式创建字符串时，实际上是在使用字符串字面量。
  - 在这种方式下，Java虚拟机（JVM）会首先检查字符串常量池（String Pool）。如果池中已经存在相同的字符串字面量，它就会重用这个对象，而不是创建一个新的对象。这种方式更节省内存，因为它避免了创建多个相同字符串的实例。

- 采用new 的方式
  - 该方式下，不管如何每次都会在字符串常量池中创建一个新的对象出来。

```java
String s1 = "Hello";
String s2 = "Hello";
String s3 = new String("Hello");
String s4 = new String("Hello");

// s1 和 s2 指向相同的内存地址（字符串常量池中的同一个对象）
System.out.println(s1 == s2); // 输出 true

// s3 在堆上创建了一个新的对象
System.out.println(s1 == s3); // 输出 false

// s3 和 s4 指向堆上的不同对象，即使它们的内容相同
System.out.println(s3 == s4); // 输出 false

// 使用 equals() 方法比较字符串内容
System.out.println(s1.equals(s3)); // 输出 true
System.out.println(s3.equals(s4)); // 输出 true
```

### string stringbuffer stringbuilder的区别

- string 是一个对象，然后它是不可变的
- 而另外的两种，stringbuffer stringbuilder是专门提供的可变字符串。
- StringBuffer 就是为了解决大量拼接字符串时产生很多中间对象问题而提供的一个类。它提供了 append 和 add 方法，可以将字符串添加到已有序列的末尾或指定位置，它的本质是一个线程安全的可修改的字符序列。
- 与 `StringBuffer` 不同的是，`StringBuilder` 的方法不是同步的。这意味着它不是线程安全的，但在单线程环境下它的性能比 `StringBuffer` 要好，因为它避免了线程同步的开销。

### 为什么要用泛型，泛型类能否直接被使用

- Java泛型的实现采取了“**伪泛型**”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“**类型擦除**”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型）

- **类型安全**：泛型使得代码在编译时期就能检查到类型错误，而不是在运行时期。这样可以大大减少运行时出现 `ClassCastException` 等类型转换错误的可能性。

- **代码复用**：通过泛型，我们可以编写在多种数据类型上都可以操作的通用代码。

  ```java
  private static int add(int a, int b) {
      System.out.println(a + "+" + b + "=" + (a + b));
      return a + b;
  }
  
  private static float add(float a, float b) {
      System.out.println(a + "+" + b + "=" + (a + b));
      return a + b;
  }
  
  private static double add(double a, double b) {
      System.out.println(a + "+" + b + "=" + (a + b));
      return a + b;
  }
  
  private static <T extends Number> double add(T a, T b) {
      System.out.println(a + "+" + b + "=" + (a.doubleValue() + b.doubleValue()));
      return a.doubleValue() + b.doubleValue();
  }
  ```

- 泛型类的格式如下：

  ```java
  public class SingleGenerics<T> {
      private T name;
      public T getName() {
          return name;
      }
      public void setName(T name) {
          this.name = name;
      }
  }
  
  public class Main {
  
      public static void main(String[] args) {
          // 泛型类的测试代码
          SingleGenerics<Integer> testClass = new SingleGenerics<>();
          testClass.setName(1);
  
          SingleGenerics<String> secondClass = new SingleGenerics<>();
          secondClass.setName("testName");
      }
  
  }
  ```

  它是不能够被直接使用的，当我们定义了一个泛型类后，实际上我们**定义的是一种模板**，这个模板可以用来生成多种具体的类型。在使用这个泛型类时，我们需要为其指定一个具体的类型。

### 静态代理和动态代理的区别

- **动态代理**又被称为JDK**代理**或接口**代理**。 
- **静态代理**与**动态代理的区别**主要在： **静态代理**在编译时就已经实现，编译完成后**代理**类是一个实际的class文件.
- **动态代理**是在运行时**动态**生成的，即编译完成后没有实际的class文件，而是在运行时**动态**生成类字节码，并加载到JVM中

## 集合

### 讲一下HashMap的put。（这里重点主要是hash冲突）

首先，调用put方法时需要传入一个key和value，会先计算key 的hashcode，然后去哈希桶中的对应位置去找是否为空，如果为空就直接插入，如果不为空，则会调用equals方法去比较一下key的值是否相等，如果相等就覆盖，不想等就说明出现哈希冲突。**优先采用链地址法解决冲突。当链表长度大于8且数组容量>= 64（否则会优先扩容）时，就会转换为红黑树。**

### 说一下HashMap的扩容机制，为什么是大小2^n 

- HashMap初始大小为16， 这里，HashMap有一个负载因子，默认为0.75，当真实存储的元素数量与数组大小的比例超过负载因子时，就会出发扩容机制。每次大小* 2。
- **计算索引高效**：而且会保证大小一直为2的整数次幂(**因为当数组的长度是 2 的 n 次方时，hash & (length - 1) = hash % length**, **& 操作的结果就是将哈希值的高位全部归零，只保留低位值**)。**&运算比%运算更快**
- **为什么&运算比%运算更快**：hash % 8=hash保留了低3位，而hash & (8 - 1)=对高位全部置为0，对低3位保留
- **扩容时元素迁移更高效**：然后，2的次幂保证了它并不需要重新计算每个元素的hashcode，只需要判断一下原先的hashcode的高位是0还是1，就可以确定到底是在原来的位置还是说往高位进。例如，原始容量为16，16 - 1的二进制表示为01111，经过扩容后变为32，32 - 1的二进制表示为：011111，相较于原来的**新增了一位**，这一位就是前文所说的高位，比如`oldIndex = hash & (oldCap - 1) = 00010101 & 00001111 = 00000101`，即原索引为 5；`newIndex = hash & (newCap - 1) = 00010101 & 00011111 = 00010101`，**即新索引为 21（原索引 5 + 原容量 16）**，可以看见的是在新增的那一位(最高位),索引5是0，索引21是1
- 新理解：如果`hash & oldCap == 0`：新位置 = 旧位置（低位不变）；若 `hash & oldCap != 0`：新位置 = 旧位置 + oldCap（低位 + 旧容量）；也就是说低位没变 hash * old = hash & new,如果变化了低位+旧容器

###  为什么采用红黑树？

- 红黑树是一种平衡性要求不那么高的搜索树。他的机制保证了最长的路径不会是最短的路径的2倍。它并不会像平衡树那样频繁的自旋来完成平衡的调整，对于插入相对友好。而他查询也可以做到logn，针对于java这种频繁插入和读取的场景，属于一个折中的选择。
- 不采用B+树是因为B+树的键，~~也就是key是会重复的~~，而HashMap的数据是存储在内存当中的。并不需要这种机制来解决磁盘读取过慢的问题

### hashmap线程安全，为什么不安全？

- 并不是线程安全的。因为他的底层实现并没有加任何同步操作。插入元素如果出现哈希冲突，很可能存在覆盖元素的情况。并且size的计算也可能出错。

### 有哪些线程安全的map？（concurrentHashMap，hashTable）

- concurrentHashMap

### 它是如何保证线程安全的？1.7和1.8的区别

- 在1.7中，它采用了sagement分段锁的机制，所有的操作都加了锁。即一个段中会有多个hashcode的值，锁的粒度相对较大。默认是分了16个段，即最大并发访问数为16，这个值可以设定。
- 而1.8当中，采用了Node + CAS + Synachored。~~这种设计，每一个node一把锁，即一个hashcode。锁的粒度更小，性能会更好。而且在修改操作时，不再加重量级的锁，而是采用cas + 自旋的这种形式去修改。只有当新插入数据时，才会使用同步代码块。~~
- 上边正好说反了，只有在头节点为空，新插入头节点元素时，会采用cas+自旋的方式，如果是更新或者删除或者调整树的结构或者是在插入时发生的hash冲突，就是采用Synachored重量级锁。
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250903161527012.png" alt="image-20250903161527012" style="zoom:33%;" />
- 它的其他实现和hashmap一样。
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250601152549566.png" alt="image-20250601152549566" style="zoom:50%;" />

### ArrayList和LinkedList区别，**ArrayList怎么扩容**

- 一个是基于数组来实现的，需要连续空间，可以做到o(1)时间复杂度访问对应下标元素。
- 扩容时，重新申请一个是**原来1.5倍大的数组**，将原先的元素拷贝过去，system.arraycopy,然后清空原数组。
- LinkedList是基于链表来实现的，它不需要连续空间，元素的访问需要依赖前置节点的next引用。它不能够随机访问元素。但是插入元素时性能较好。(好的前提是拿到要插入位置的前一个节点，另外它不需要移动元素。)

### Set底层怎么实现的

- set的底层其实就是一个hashmap。key存储具体的元素，**value是一个object**。没有什么特殊含义。

### **TreeMap了解吗**？底层怎么实现？

- 有序集合。底层是红黑树。

### LRU（最近最久未使用）需要用Java的哪种数据结构？

- 底层需要一个双端链表加一个hashmap。
- 因为需要在o1时间内找到对应的元素，而且想要将一个元素从链表中移动到队头，需要获取它的前置节点。双端链表可以直接获取该节点的前置节点。而HashMap则是为了o1时间内获取到使用了的节点。

### LinkedHashMap，为什么采用双端链表？

- 原因同上。

### Java的阻塞队列

- 阻塞队列，我知道的，应该有一个获取元素为空时，就阻塞，直到元素不为空。往队列中添加元素时，如果队列满了，~~就阻塞添加线程，直到队列不满。~~（这在说什么，胡言乱语）。如果队列满了，就阻塞当前的插入操作，直到队列不满。

- BlockingQueue 一般用于生产者-消费者模式，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。**BlockingQueue 就是存放元素的容器**，队列为空，消费者阻塞；队列满，生产者阻塞

- #### ArrayBlockingQueue 数组实现 有界阻塞队列，生产者和消费者不能同时操作队列(没有独立锁)

- LinkedBlockingQueue 链表实现,生产者端和消费者端分别采用了**独立的锁**来控制数据同步，这也意味着在高并发 的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能

### 阻塞队列的原理是什么？

- 底层使用ReentranLock和两个condition来实现
- 使用锁对put/take操作加锁，当队列为空或者满时，使用对应的condition将线程加入到等待队列

### **线程安全的ArrayList是什么？CopyOnWriteArrayList是什么样的？**

- CopyOnWriteArrayList是一个线程安全的list。
- 它采用了写时复制技术，允许同时读写。
- 具体来说，他在修改时，在JDK8中会使用ReentrantLock进行加锁(**在JDK9开始使用监视器进行加锁**)，然后，永远会将原先的数组复制一份，然后在备份上进行修改，然后将原来数组的引用指向修改后的数据。而正是由于这一特性，使得它的性能并不是很高。
- CopyOnWriteArrayList在写操作时，会先加锁，然后复制一份数组，然后在新数组里边写。**内存占用较大**
- 对读操作不进行加锁
- 不能实时数据一致，只能最终数据一致

## 并发

### 悲观锁

对资源操作之前加锁，实现方式有

- synchronized
- lock
- 数据库的行锁，间隙锁，表锁等

### 乐观锁

对资源不进行加锁，但是通过某些方法进行资源控制

- CAS
- 版本控制

### 并发容器和同步容器

- 同步容器简单说是使用synchronized控制的容器(vector,hashtable)，多线程以**串行的方式访问整个容器**
- 并发容器将自己分段或者分区(concurrenthashmap),减小锁的粒度，多线程可以同时访问整个容器的不同端或者不同区

### synchronized关键字可以用于静态代码块吗？

```java
synchronized static {

}
```

上边这种写法是不允许的。但是允许以下写法

```java
static {
  synchronized (Object.class) {
    
  }
}
```

### synchronized关键字，原理？

- `synchronized`的工作原理基于Java的每个对象都自带一个内置锁（也称为监视器锁或互斥锁）。当一个线程要访问一个被`synchronized`修饰的代码块或方法时，它首先需要获取到该对象的锁。如果锁已经被其他线程持有，那么这个线程就会被阻塞，直到锁被释放。当线程完成`synchronized`代码块或方法的执行后，它会自动释放锁，这样其他正在等待的线程就可以获取到锁并开始执行。
- 该题可以这么回答，它是一个同步代码块，加锁原理就在于在代码块的前后分别加上monitorenter 和monitorexit这两个指令。该指令会使得区间内代码块缓存失效，它会去主内存读取最新值，这就保证了可见性。保证了代码块中间的代码**不会被中断以及重排序**，保证了原子性和有序性。这里不完全是原子性，只是不会去响应中断。
- 每个对象都有一个监视器锁，当执行**monitorenter**指令时，会尝试获取对象的监视器锁，如果值为0，说明没有被其他线程获取，那么就会将监视器锁设置为1，重入时就加1。监视器锁会指向加锁的线程。

### synchronized锁升级

- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250825172736564.png" alt="image-20250825172736564" style="zoom:33%;" />
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250825173310657.png" alt="image-20250825173310657" style="zoom: 33%;" />
- 锁升级的过程，先加偏向锁。此时只需要把对象头的**mark word** 指向加锁的线程即可。（其实就是mark word中的锁标记位）
- 此时如果有另外一个线程来竞争加锁，jvm会撤销偏向锁，~~此时每个线程都需要在栈中创建一个锁记录LR，然后采用CAS+自选的方式，将mark word 中的锁标记位指向该锁记录，哪个线程修改成功，哪个线程就获取到了轻量级锁。而失败的会继续尝试获取锁，当次数过多时，就会升级为重量级锁~~。
- JVM首先会在当前线程的栈帧中创建用于存储锁记录的空间，**并将对象头中的Mark Word复制到锁记录中**。然后，JVM尝试使用CAS操作（Compare and Swap，比较并交换）**将对象头中的Mark Word替换为指向锁记录的指针**；**线程栈帧的锁记录`owner`** 会指向该对象的 Mark Word 原始值。如果替换成功，那么这个线程就成功获取到了锁，并且对象处于轻量级锁定状态。
- ~~此时的实现就是基于操作系统的一个信号量来实现的，此时对象头中的锁标记位会指向一个ObjectMonitor。而且重量级锁之后，加锁失败的线程会直接被阻塞。~~
- 当轻量级锁竞争过一段时间还未获取到时，就会升级为重量级锁。此时JVM会创建一个C++实现的Object Monitor类，然后将对象头中的Mark word替换为指向该对象的指针。

为了减少获得锁和释放锁所带来的性能消耗，引入了偏向锁和轻量级锁，**增加了锁升级的过程**，由无锁->偏向锁->自旋锁->重量级锁

- 偏向锁：大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。**偏向第一个获得锁的线程**，偏向锁在资源无竞争情况下消除了同步语句，如果存在线程竞争锁，则会进行锁升级，撤销偏向锁，膨胀到轻量级锁
- 轻量级锁：多个线程在不同时段获取同一把锁，即不存在锁竞争的情况，也就没有线程阻塞。针对这种情况，JVM 采用轻量级锁来避免线程的阻塞与唤醒。线程尝试获取锁（**虚拟机首先在栈中创建锁记录并拷贝对象头中的Mark Word复制到锁记录，然后用 CAS 将锁的 Mark Word 替换为指向锁记录的指针并将锁记录中的owner指向锁对象。如果成功，当前线程获得锁，如果失败，表示 Mark Word 已经被替换成了其他线程的锁记录**），如果获取失败，说明在与其它线程竞争锁，当前线程就尝试**使用自旋来获取锁**。如果自旋到一定程度，依然没有获取到锁，称为自旋失败，那么这个**线程会阻塞**。同时这个锁就会**升级成重量级锁**
- 重量级锁：线程尝试获取锁失败，它会直接进入阻塞状态，等待操作系统的调度
- ![image-20250317201555778](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250317201555778.png)

### 偏向锁的撤销和膨胀

- 偏向锁撤销的开销花费还是挺大的，其大概的过程如下：  
  - （1）JVM需要等待一个全局安全点（global safe point），当JVM到达全局安全点后，所有 的用户线程都是暂停的，当然，在此时，持有偏向锁的用户线程也被暂停了。  
  - （2）遍历线程的栈帧，检查是否存在存在锁记录。如果存在锁记录的话，需要清空锁记录， 使其变成无锁状态，并修复锁记录指向的Mark Word，清除其线程ID。  
  - （3）将当前锁升级（或碰撞）成轻量级锁。少数场景直接升级为重量级锁。  
  - （4）唤醒当前线程。

### 全局安全点

- 如何进入全局安全点：
  - （1）JVM设置一个global safe point 标志位，各用户线程主动去检查这个标志位，发现全局 global safe point 标志位为 true 时，就将自己挂起。 (**设置全局安全点标志位**) 
  - （2）各用户线程都有自己的安全点（safe point），当用户线程到达safe point后，都会去检查全局global safe point 标志位，如果发现标志位为true，安全地将自己挂起。(**线程到达自己的局部安全点会检查全局安全点**)  
  - （3）JVM 里面所有的用户线程都到底安全点（safe point）之后，此时，所有的用户线程都 已经挂起，JVM处于STW停顿状态，JVM也达到一个全局安全点global safe point(**所有用户线程都挂起了就到达了全局安全点**)
- 对于JIT编译后的代码，JIT会在代码特定的位置(通常在方法的返回处和跳出循环后)插入安全点检查代码(**特定位置插入安全点检查点**)
- 对于解释执行的代码，JVM会设置一个2字节的dispatch tables放置全局安全点的请求。 解释器执行的时候会经常去检查这个dispatch tables，当有全局安全点请求的时候，就会 让线程去进行安全点检查。(**设置dispatch tables**)

### 重量级锁原理

重量级锁状态时，对象的Mark Word中会有一个指向与对象关联的ObjectMonitor

- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250826141602088.png" alt="image-20250826141602088" style="zoom: 33%;" />
- Owner:当前获取到锁的线程
- Cxq:竞争队列：是一个单向虚拟队列，当竞争锁的线程通过CAS自旋没有获取到锁时，该线程会被包装成一个ObjectWaitter插入到Cxq队列
- EntryList:当Owner释放锁后，Owner线程会将Cxq(从队尾取)中的线程转移到EntryList中，会选择一个节点(一般是头节点)作为Ready Thread，但是此时并不会将锁给Ready Thread, 而是新来的线程进行竞争。如果Ready Thread没有获取锁，EntryList不会将他移除队列
- WaitSet : 当线程调用了锁对象的wait()，他会被放到WaitSet队列中 

### 虚拟队列

没有具体的队列节点的数据结构，比如上文中的Cxq队列，新节点ObjectWaitter使用头插法插入队列，ObjectWaitter不是Cxq定义的队列节点

### AQS，原理，CLH队列了解吗？

- AQS是一个队列同步器。核心思想：**如果被请求的共享资源空闲，则当前线程能够成功获取资源；否则，它将进入一个等待队列，等待获取资源。当某个线程释放共享资源后，就会从队列中唤醒一个等待的线程，使其得以工作。**state使用volatile修饰
- AQS提供了两种模式，一种独占模式(资源只能被一个线程获取)，一种共享模式()。典型代表reentrantlock，一种countdownlunch。
- 实现主要是依靠一个state同步变量以及一个CLH阻塞队列来实现的。
- 但一个线程尝试加锁时，会先判断state是否为0，如果为0则说明可以加锁，否则进入阻塞队列。
- CLH队列的头部是当前持有锁的线程，队列中是获取锁失败被阻塞的线程。
- waitStatus：节点状态，常用值有：
  - `0`：初始状态，节点正常等待。
  - `SIGNAL（-1）`：当前节点的后继节点需要被唤醒（当前节点会负责唤醒后继）。
  - `CANCELLED（1）`：节点已取消等待（如线程中断），需从队列中移除。
- **新的理解：**
  - 线程先调用tryAcquire()去尝试获取锁，也就是CAS修改state: :zero:=>:one:, 修改成功则获取成功。直接返回；否则进行下一步
  - 自旋入队：当前线程会被包装成一个Node节点，通过CAS设置队尾指针tail为自己的Node节点来自旋入队，入队成功则进行下一步；失败继续自旋
  - 在成功入队后，会通过 CAS 将其前驱节点（记为 `prev`）的 `waitStatus` 设为 `SIGNAL`（-1）。这一步的意义是：**`prev` 节点承诺：如果自身释放锁，会唤醒 `node` 节点**（避免 `node` 永久自旋）。
  - 在前驱节点上自旋：判断前驱节点是否头节点(头节点一定是获取到锁的)，如果前驱是head节点，则尝试获取锁(tryAcquire)，如果获取到了锁则进行移除头节点并将自己设为头节点。如果前驱不是头节点或者前驱是头节点但抢锁失败，则自旋或者被挂起
  - 当head节点释放锁后，会唤醒后继节点，后继节点被唤醒后会重复上一步的操作

### AQS中节点入队后的tryAcquire()会和新来的节点抢锁吗？(公平或非公平)

- 是要根据AQS子类具体的实现：在tryAcquire()是否会判断**队列中是否有等待线程**

### synchronized和ReentrantLock的区别？

- 两者实现的机制不一样，一个是依靠jvm来实现的，一个是依靠AQS(AbstractQueuedSynchronizer)来实现的。
- 前者是非公平锁，后者是可以提供公平锁机制。
- 使用方式不一样。前者可以自动释放。而后者必须手动调用释放锁。
- 后者更加灵活。支持可中断，尝试获取锁。

### Condition原理

![image-20250505162341409](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250505162341409.png)

- condition其实是基于ReentrantLock来实现的，它是属于共享模式。condition的创建是需要基于ReentrantLock来创建的，使用condition中的await和signal方法代替wait和notify方法
- 它的底层会有一个自己的阻塞队列，被称为条件队列（等待队列）。该队列里会存储所有在同一个ReentrantLock创建出来的`condition`中，调用了await的线程。
- 调用condition.await()一定是获取了锁的线程，也就是AQS同步队列的第一个节点，会将该节点的线程封装为condition的Node，并使用尾插法插入到condition的等待队列中，在await()方法中会释放线程的锁，在自旋判断节点是否放入同步队列(**阻塞在这里**)，在退出await()方法之前会自旋获得锁，也就是说**退出await()方法的线程是已经获得锁了**
- 当有线程调用某一个condition的`signal()` 方法时，会在该condition中的阻塞队列(等待队列)中拿出一个线程，放到lock的阻塞队列当中，等待获取锁然后执行。
- 在代码中，想要调用condition，就需要先调用lock.lock()，即先获取到锁，每次只有一个线程能获取到锁，当前获取到锁的线程，调用某一个condition，然后从阻塞队列中拿出一个最早进去队列的线程，将其丢到Lock的阻塞队列当中，等待获取锁然后执行逻辑。
- 这里唤醒的线程，就是调用了await的线程，然后会去执行对应的逻辑。

### ReentranLock和Condition是如何联系起来的？

其实ReentranLock的所有操作是转包给内部类Sync来实现的，同理Sync类继承了AQS类，而AQS中有一个内部类ConditionObject,该类实现了Condition接口，~~因此对于一个Condition实例，通过this可以联系到ReentranLock实例~~

### monitorenter和monitorexit是怎么起作用的

- 这两个指令是依靠操作系统的互斥量来实现的。只有一个线程能够进入该指令。并且他强制缓存失效，去读取最新的缓存。而且执行完monitorexit之后，会强制将缓存刷新到主存中。

### **ReentrantLock是怎么实现可重入锁的？**

- 可重入指的是对**同一个线程可重入**：同一个线程可以多次申请加锁，每次申请锁state+1
- 加锁时，有一个状态量state，如果为0，意味着可以加锁。将state改为1，如果重入，就将state的值继续加。但是释放锁时必须将其减为0才算释放成功。

### ReentrantLock可重入锁的意义是什么？

一个线程可能在外部方法中已经获得了锁，但在内部方法中还需要获得锁，如果没有可重入锁可能会导致死锁

，另外内部方法也能在别的地方也会被调用，因此也要进行加锁

### volatile关键字，怎么保证可见性和有序性？

- 首先，volatile修饰的关键字会禁止指令重排序，通过代码加入屏障。因此做到了有序性。
  - 写操作会加写屏障，会阻止该屏障上方的写操作，越过屏障到达volatile变量修饰的代码下边
  - 而读操作会加读屏障，会阻止该代码下方的读操作，越过屏障到达上方。
  - ![image-20240502181524411](https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20240502181524411.png)
- 其次，它会强制走主存。即变量值的读取以及写入，都会立即刷入主内存，保证了可见性
  - 这里，如果两个线程读取了volatile修饰的变量，其中一个线程修改了变量的值，volatile所设置的缓存一致性会确保使得另一个线程的本地内存失效，它需要先去主内存读取最新的值，然后再写入本地内存。
- 但是他并没有保证原子性，所以并不是线程安全的。但是对volatile修饰的变量进行赋值取值是原子性的(volatile a = 1; volaile b  = a)，复合操作(a++)不是原子性的，同时对于Long和Double是原子性的(JVM的可选实现)
- 使用技巧
  - 如果是写变量，让volatile修饰的变量放在最后，因为它可以阻止上方的写操作越过屏障
  - 如果是读变量，那么就放在最开始

### **并发的三大特性是什么？**

- 原子性，有序性，可见性。



### 有哪些类是基于AQS实现的？

- reentrantlock
- countdownlunch

### countdonwlatch了解吗？

- ~~主要作用就是让一定数量的线程完成后，主线成在继续执行。~~
- 或者说他是让多个线程都达到某一个状态后，再继续执行。
- CountDownLatch的作用是允许一个或多个线程等待其他线程完成操作。
- 底层是基于AQS来实现的，其实就是对应了AQS的非独占模式，state可以大于1，在这个场景state就对应了countdonwlunch的计数，每当有一个线程执行完成后，他其实会被阻塞，即调用await()等待。，直达countdonwlunch的计数为0，会调用`LockSupport.unpark()` 唤醒所有调用 `await()` 的线程
- 

```java
import java.util.concurrent.CountDownLatch;

public class CountDownLatchExample {
    public static void main(String[] args) throws InterruptedException {
        // 初始化计数器为 3（表示需要等待 3 个任务完成）
        CountDownLatch latch = new CountDownLatch(3);
        
        // 创建并启动 3 个子线程
        for (int i = 0; i < 3; i++) {
            new Thread(() -> {
                try {
                    // 模拟子线程执行任务
                    Thread.sleep(1000);
                    System.out.println(Thread.currentThread().getName() + " 完成任务");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    // 任务完成，计数器减 1
                    latch.countDown();
                }
            }).start();
        }
        
        System.out.println("主线程等待所有子任务完成...");
        // 主线程阻塞，直到计数器为 0
        latch.await();
        System.out.println("所有子任务已完成，主线程继续执行");
    }
}
```



### Cyclicbarrier了解吗

- 主要是用于让一组线程在到达某一个状态后，相互等待其他线程也到达该位置，然后在一起继续执行

- ```java
  import java.util.concurrent.CyclicBarrier;
  
  public class CyclicBarrierExample {
      public static void main(String[] args) {
          // 3个线程参与，最后一个到达的线程执行屏障动作
          CyclicBarrier barrier = new CyclicBarrier(3, () -> {
              System.out.println("所有线程已到达，执行屏障动作（数据汇总）...");
          });
  
          // 创建并启动3个线程
          for (int i = 0; i < 3; i++) {
              final int threadId = i;
              new Thread(() -> {
                  try {
                      System.out.println("线程" + threadId + "执行任务中...");
                      Thread.sleep((threadId + 1) * 1000); // 模拟不同耗时的任务
                      System.out.println("线程" + threadId + "到达屏障点，等待其他线程...");
                      
                      // 到达屏障点，等待其他线程
                      barrier.await();
                      
                      System.out.println("线程" + threadId + "继续执行后续操作");
                  } catch (Exception e) {
                      e.printStackTrace();
                  }
              }).start();
          }
      }
  }
  ```

  

### **不用锁怎么能实现线程安全？（从CAS角度考虑）**

- 题目后边已经给出答案了。

### synchronized的锁粗化、消除是怎样的？

- **锁消除**指的是在某些情况下，JVM 虚拟机如果检测不到某段代码被共享和竞争的可能性，就会将这段代码所属的同步锁消除掉，从而到底提高程序性能的目的。
- **锁粗化是指，将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁**。

### 并发编程的个人总结：

1. 判断代码块是否可能处于并发的情况：
   1. 代码块前后是否有加锁保护，如果有加锁，这不用担心线程安全问题
   2. 如果代码块没有加锁，其实**关注的就是共享资源(变量)的读和写问题**
2. 当变量仅仅是代码块的局部变量，那么每个线程在自己的栈中独一份，不用担心线程安全问题
3. 当变更是父线程(main线程)传给子线程的，并且没有使用voilatle修饰，那线程对它的操作对其他线程是不可见的，那么它的读和写都是需要注意线程安全的：线程会将数据读到自己的缓存来进行修改，但刷新待主存的时机不确定，所有导致其他线程读的可能是旧值，也可能是其他线程修改后的新值，
4. 共享变量使用了voilatle修饰：线程之间可见，那么线程修改后会立即刷新到主存，所以使用CAS去修改变量

上面有一些错误：

### AI给的黄金三步：

1. **判断是否有共享资源**：
   - 无共享资源（如局部基本类型变量和局部new的对象）→ 天然安全；
   - 有共享资源（如类成员变量、堆对象(比如多个线程操作同一实例的属性)）→ 进入下一步。
   - 虽然局部new的对象是在堆上(线程栈存放的只是他的引用)，但由于不同的线程执行时都会new一个新对象所以天然安全
2. **判断共享资源的操作是否为原子操作**：
   - 是原子操作（如 volatile 变量的读、CAS 修改）→ 需确保可见性（volatile）；
   - 非原子操作（如 i++、多步修改）→ 需用锁（synchronized/Lock）或原子类（AtomicInteger）保证原子性。
3. **判断是否有指令重排序风险**：
   - 有风险（如单例双重检查、多线程依赖变量初始化）→ 用 volatile 禁止重排序；
   - 无风险 → 无需额外处理

## 线程池和线程

### 线程间通信

- wait、notify
  - wait原理：当前线程调用了同步对象的wait实例方法后，该线程会放到同步对象相关联的ObjectMonitor中的WaitSet
  - notify原理：JVM将WaitSet中的第一个线程(notify)和全部线程(notifyAll)唤醒，放入EntryList,具备抢锁的资格
- 

### Java如何中断一个线程

- 一般通过调用 如下代码，来告诉当前线程，你要中断了，这个时候线程被设置了中断标志，**但是仍然可以继续运行**，

  - ```
    Thread thread = new Thread();
    thread.interrupt();//将线程的中断标志为设为true
    ```

  - 这个调用，是当前线程，调用了另一个线程实例的interrupt方法，告诉另一个线程你要中断了。

- 而interrupted()方法，则是Thread的静态方法，用于检查当前线程是否被中断，并清除中断标志(设为false)。
  
  - 它总是**检查调用这个方法的线程自己是否被中断**，并且**清除该线程的中断标志**。
  
- 停止线程可以使用stop方法(已被弃用，不建议)，还可以结合interrupted()+isintterrupted()优雅停止：

- ```java
  public class WorkerThread extends Thread {
      @Override
      public void run() {
          while (!Thread.currentThread().isInterrupted()) {
              try {
                  // 执行任务
                  System.out.println("Working...");
                  Thread.sleep(100); // 释放 CPU
              } catch (InterruptedException e) {
                  // 恢复中断状态并退出
                  Thread.currentThread().interrupt();
                  System.out.println("Cleaning up...");
                  break;
              }
          }
      }
  }
  
  // 使用示例
  WorkerThread thread = new WorkerThread();
  thread.start();
  // 一段时间后请求中断
  thread.interrupt();
  ```



### 线程的Join

- 现有线程A,B，join可将线程B合并到线程A中，A需等待线程B执行完之后再执行，也可以等待一定的时限

- ```java
  class A extends Thread{
      void run(){
          Thread B = new Thread("B");
          B.start();//
          B.join();//B线程执行完之后再执行下面的逻辑
          
      }
  }
  ```

  

### Java的守护线程

- 它们在后台运行，并且优先级较低。其主要作用是为其他线程提供服务或支持。当所有非守护线程（也称为用户线程）都执行完毕后，Java虚拟机（JVM）就会自动退出，即使还有守护线程在运行，JVM也不会等待它们结束。

### 线程池的拒绝策略有哪些？

- 直接丢弃任务，抛出异常
- 丢弃任务不抛出异常
- 交给主线程执行
- 从阻塞队列中丢弃一个最老的任务，然后加入该任务。

### 有哪几种线程池？缺点？优点？

- **总结：**FixedThreadPool和SingleThreadExecutor的**阻塞队列使用LinkedBlockingQueue**，导致任务队列长度为Integer.MAX_VALUE，容易OOM；CachedThreadPool 和ScheduledThreadPoolExecutor 的线程数为Integer.MAX_VALUE，容易OOM

- 它有一种创建只需要指定一个参数的线程池，该线程池采用无界的阻塞队列，**最大线程数和核心线程数一样**，优点是创建简单，缺点是不够灵活，且无界的阻塞队列(LinkedBlockingQueue)容易导致OOM。(固定线程池，FixedThreadPool)

- 带有缓存的线程池。CachedThreadPool 是一个可缓存线程池，优先重用空闲的线程池。可以无限放大，线程数可以随意增加，比较适合处理执行时间比较小的任务，线程数大于任务数会释放空闲资源。(线程数为Integer.MAX_VALUE，CachedThreadPool)

- 自己指定参数的线程池。优点是足够灵活，可以自己进行配置。

- 只有一个线程的线程池。优点是可以确保任务的顺序执行，缺点是性能可能相对较差。阻塞队列也是LinkedBlockingQueue（SingleThreadExecutor）

- ScheduledThreadPoolExecutor 定时调度线程池，延迟任务或者周期重复任务（ScheduledThreadPool），最大线程数也是设置为Integer.MAX_VALUE

- 不建议使用Executors 来快速创建快速创建线程池，**推荐使用自定义线程池ThreadPoolExecutor**：

  ```java
  private static final ExecutorService exec = Executors.newCachedThreadPool();//Executors快速创建线程池
  ```

  

  ```Java
  private static final ThreadPoolExecutor exec = new ThreadPoolExecutor(//自定义
              CORE_POOL_SIZE,
              MAX_POOL_SIZE,
              60L,
              TimeUnit.SECONDS,
              new LinkedBlockingQueue<>(1000)//设定阻塞队列大小，以免无界阻塞队列oom
      );
  ```

  

### 为什么要使用线程池？（从池化的优点出发）

- 因为线程的创建是一个非常消耗资源的操作。如果频繁创建和销毁，会对程序的性能造成影响。因此，采用这种池化的思想，去复用线程，节省线程创建的消耗。
- **Java 的线程在现代 JVM 实现中与操作系统线程之间是 1:1 绑定的**。这意味着每个 Java 线程都直接映射到一个操作系统级别的线程。Java 使用操作系统的原生线程管理机制来调度和管理线程，这一模型被称为 **1:1 线程模型**
  - jdk21引入的虚拟线程，其实就是 n : 1 的关系了，即多个虚拟线程可以映射到一个实际的操作系统线程当中。而且虚拟线程的创建成本很低，不建议采用创建虚拟线程的线程池。

- 这也就导致了线程的创建和销毁都是比较重量级的操作，所以说采用池化的思想可以减少资源损耗。

### 线程池的参数，以及含义

- 核心线程数
- 最大线程数
- 超过核心线程数线程的存活时间
- 时间单位
- 创建线程的工厂
- 阻塞队列类型
- 拒绝策略

### 线程池的创建以及**运行原理**？为什么要这么设计？

- 线程池运行有这么几个关键步骤，初始时线程池中线程数量为空，每当有一个任务到来，如果现有的线程数量小于核心线程数量，会创建线程，哪怕此时线程池中有空闲的核心线程，也会创建新的线程去执行。
- 如果此时线程数量达到了核心线程数，那么就会将新任务加入到阻塞队列。
- 这里需要注意，每个任务来之后都需要直接加入阻塞队列当中。因为核心线程是通过getTask去阻塞队列中获取任务的。
  - 也就是说，哪怕当前有空闲的核心线程，新来的任务并不会被该核心线程直接执行，而是先放入阻塞队列当中。
- 当阻塞队列满了之后，如果线程数小于最大线程数，那么就会创建一个新的线程去执行该任务。
- 超过核心线程数，小于最大线程数这部分线程，在超过keepalivetime设置的时间后就会被销毁。
- 当阻塞队列满，且达到最大线程数之后，会触发拒绝策略。
- 之所以在这么设计，是因为JDK默认的线程池，他适用的场景为CPU密集型的任务。如果一次性创建太多的线程，会导致频繁的线程切换，影响性能。
- ![image-20250318174530136](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250318174530136.png)

### 核心线程是否可以回收？

- 取决于我们是否设置了某一个参数。如果设置为true，则可以回收。否则不会回收。

### **线程池是怎么达到复用效果的？如何确定何时回收？**

- （while循环加计时器，详细看面试-线程池-worker线程管理部分）线程被封装为一个Worker
- 一般来说，线程池执行完一个任务后，就会被销毁。
- 而线程池则是利用了while死循环，让他一直从阻塞队列中获取任务。如果获取成功就执行。
- while 循环中会有另外一个参数，是和时间相关的，如果超时，也会结束while循环。
- 线程池内部会维护对应线程的引用，防止线程被GC回收。如果循环结束，那么不再维护引用，让GC回收就可以了。

### Future接口

⚫ V get()：获取异步任务执行的结果。注意，这个方法的调用是**阻塞性的**。如果 异步任务没有执行完成，异步结果获取线程（调用线程）会一直被阻塞，一直阻塞到到 异步任务执行完成，其异步结果返回给调用线程。  

⚫ V get(Long timeout , TimeUnit unit) ：设置时限，（调用线程）阻塞性的获取异 步任务执行的结果。该方法的调用也是阻塞性的，但是结果获取线程（调用线程）会有 一个阻塞时长限制，不会无限制的阻塞和等待，如果其阻塞时间超过设定的timeout时 间，该方法将抛出异常，调用线程可捕获此异常。  

⚫ boolean isDone()：获取异步任务的执行状态。如果任务执行结束，返回true。  

⚫ boolean isCancelled()：获取异步任务的取消状态。如果任务完成前被取消，则 返回true。 

 ⚫ boolean cancel(boolean mayInterruptRunning)：取消异步任务的执行。

### RunnableFuture 接口

该接口继承了Runnable接口和Future接口

### FutureTask类

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250505180014943.png" alt="image-20250505180014943" style="zoom: 33%;" />

- FutureTask类是对RunnableFuture接口的实现类
- 在FutureTask类中执行callable的call方法，并将执行结果保存到outcome中，可以使用get()方法取出outcome

### **有几种创建线程的方式？**

- 继承Thread类
- 实现Runnable 接口重写其中的run方法，在将实现示例传入new Thread(Runnable runnable)
- 实现Callable接口，将该实现类传入FutureTask，再将FutureTask实例传入new Thread(FutureTask ft)
- 而线程池的底层调度，也是调用start方法。

### callable 和 runnable的区别？

- 是否可以接收线程执行结果的返回值

### CompletableFuture了解吗？

- 提交一个任务，可以收集他的结果。

- 他其实只是一个调度器，并且它底层有一个线程池，forkjoin pool。

- 它可以拿来做任务编排，比如说 thenCompose 和 thenCombine这些，可以让一个任务的结果作为下一个任务的输入。

- 方法介绍：

- ```java
  //supplyAsync和runAsync  创建异步任务
  //suppltAsync有返回值
  CompletableFuture<Integer> completableFuture = CompletableFuture.supplyAsync(()->{
             System.out.println("有返回值");
             return 2;
          });
  //runAsync没有返回值
  CompletableFuture<Void> completableFuture1 = CompletableFuture.runAsync(() -> {
              System.out.println("无返回值");
          });
  
  
  //thenApply、thenAccept和theRun   回调方法
  //theApply 有入参 有返回值
  CompletableFuture<Integer> completableFuture = CompletableFuture.supplyAsync(()->{
             System.out.println("xzxxxxx");
             return 2;
          }).thenApply((ans)->{
              System.out.println("有返回值回调");
              return ans + 1;
          });
  //theAccept  有入参  无返回值
  CompletableFuture<Void> completableFuture1 = CompletableFuture.supplyAsync(() -> {
              System.out.println("有返回值");
              return 22;
          }).thenAccept((ans) -> {
              System.out.println("无返回值");
          });
  //theRun  无入参  无返回值
  CompletableFuture<Void> completableFuture1 = CompletableFuture.runAsync(() -> {
              System.out.println("有返回值");
          }).thenRun(() -> {
              System.out.println("无返回值");
          });
  
  
  
  //theCompose 串联组合任务
  
  CompletableFuture<Integer> completableFuture = CompletableFuture.supplyAsync(()->{
             System.out.println("有返回值");
             return 2;
          }).thenCompose(f -> CompletableFuture.supplyAsync(() ->{
              System.out.println("串联组合任务");
              return f + 1;
          }));
  //theCombine 并行组合任务
  CompletableFuture<Integer> completableFuture = CompletableFuture.supplyAsync(()->{
             System.out.println("有返回值");
             return 2;
          });
  CompletableFuture<Integer> completableFuture1 = CompletableFuture.supplyAsync(() -> {
              System.out.println("有返回值");
              return 22;
          });
          CompletableFuture<Integer> combine = completableFuture.thenCombine(completableFuture1, (ans1, ans2) -> {
              System.out.println("并行组合任务");
              return ans1 + ans2;
          });
  
  ```

  

### callable 和 future区别？

- 其实，callable主要是为了解决runnable无法获取到线程执行任务的结果。
- Callable接口代表一段可以调用并返回结果的代码，因为是异步执行的，所以说我们用future代表了异步执行的结果。
  - 也就是说，callable是提交任务的接口，而future则是该任务的结果。
  - **简单的FutrueTask收集结果是同步的，但是Callable依赖于FutureTask异步获取任务的结果**

### 怎么获取线程池每个线程的运行结果？

- Future 或者 CompletableFuture的get方法。

### fork join线程池了解吗？什么原理？

- 它是一个采用分治思想的线程池，1.7之后加入的。
- 主要是将一个任务分解为多个小任务，然后每个线程执行一部分，最后合并。
- 采用工作量窃取算法，一个空闲的线程，如果他的队列中没有任务，可以去获取其他队列队尾的任务去执行。

### threadLocal原理，为什么会造成内存泄漏？它们是怎么解决的？

- ```java
  public void set(T value) {//ThreadLocal类中的set方法
  	//1. 获取当前线程实例对象
      Thread t = Thread.currentThread();
  
  	//2. 通过当前线程实例获取到ThreadLocalMap对象
      ThreadLocalMap map = getMap(t);
  
      if (map != null)
  	   //3. 如果Map不为null,则以当前ThreadLocal实例为key,值为value进行存入
         map.set(this, value);
      else
  	  //4.map为null,则新建ThreadLocalMap并存入value
        createMap(t, value);
  }
  ```

  ```java
  ThreadLocalMap getMap(Thread t) {
      return t.ThreadLocals;//每个线程都有自己的本地变量ThreadLocalMap
  }
  ```

- 当你不再引用某个 `ThreadLocal` 对象（即没有强引用指向它）时，GC 会在下一次运行时回收该 `ThreadLocal` 对象。

  因为 `ThreadLocalMap` 中的 `key` 是 `WeakReference<ThreadLocal>`，当垃圾回收器回收 `ThreadLocal` 对象后，`ThreadLocalMap` 中的 `key` 就会变成一个**null 引用**，即弱引用失效。

- 每一个Thread中，会有一个ThreadLocalMap，它的key是一个ThreadLocal的this引用，vlue是存储的具体的值。

- ThreadLocal中，它会先获取到当前线程，然后拿它的ThreadLocalMap，之后把当前threadlocal的引用传进去，拿到value，返回。

- ThreadLocalMap中的key是一个ThreadLocal的弱引用，它会被GC回收，但是value却是一个强引用。

- 这里，其实ThreadLocalMap是存储在线程中的，如果线程一直存活，他是无法被回收的。但是key

- 解决办法就是在调用get ，set 以及remove时，它会清除key为null的value。

### ThreadLocalMap中的key为什么要设置为弱引用

- 首先，ThreadLocalMap是一个线程里的成员变量，如果线程不执行结束，那么它就会一直存在一个强引用，无法被回收。
- 那么在线程池中，每个线程都会被反复利用，去提交一些任务。此时不出现异常的话，线程永远不会结束。也就是说ThreadLocalMap是不会被回收的。
- 但是，每个线程执行完一次任务后，它可能会在ThreadLocalMap中存储本次任务的一些数据，如果key为强引用，**那么我们就无法判断整个Entry(key, value)是否还需要被使用，没办法去判断是否该回收Entry**。
- 但是如果是一个弱引用，每当线程执行完run方法时，如果ThreadLocal为弱引用，那么线程执行完run，线程虽然不会结束，然是ThreadLocal可以被回收，对应的Entry就变为了null，value。即被标记为不可用。（在线程运行的时候和ThreadLocalMap对ThreadLocal对象是弱引用，但是任务里面一般有对ThreadLocal对象的强引用，所以任务结束Key可回收）

<img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20240415105602146.png" alt="image-20240415105602146" style="zoom:67%;" />

### 为什么 threadlocal 底层实现是 thread 里面一个 map，map 的 key 是 threadlocal，而不是 threadlocal 里面有一个 map，map 的 key 是 thread

- 可能存在内存泄漏：线程生命周期结束后会回收其中中的map，这样对应的Threadlocal没有了引用，这样就能会GC，但是采用后者的方式，在线程生命周期结束后，由于Treadlocal保持着对线程的引用，使得线程无法被GC
- 其实这样设计，会有一定的并发性问题：后者方式会使得不同的线程去访问同一个map，造成并发问题
- 如果是一个Map，那么多个thread id的key，他们的hashcode可能会一样的，如果一样，不加锁就有可能导致多个key写入同一个槽当中。不加锁就会影响性能。



### 了解InheritableThreadLocal吗？

- InheritableThreadLocal是可以在父子线程之间传递数据的。
- 其设计的原理在于，每一个线程有一个ThreadLocalMap成员变量，~~也有一个InheritableThreadLocalMap的成员变量~~其实它是两个ThreadLocalMap，只不过起了一个其他的名字。在子线程创建时，会复制父线程的InheritableThreadLocalMap。因此可以传递。

### **线程池当中有一条空的核心线程，任务来了之后会怎么做**（详见面试题 java -> 线程池部分）

- 它会将其加入到阻塞队列当中，然后从阻塞队列中获取。
- 这里其实要讨论一下当前线程的数量，比如说是小于核心线程数，还是说位于核心线程数和最大线程数之间，还是等于最大线程数。

### 如果让你设计一个线程池，你会怎么设计？

- 第一个要考虑的问题就是，拿什么去存线程。我可能会用一个双端队列+map的形式去存
- 总体思想和Java线程池类似，不会有太大区别。
- 因为我需要在O1时间内判断现有的线程是否可以被使用，所以说可以采用每次获取队列头部线程，然后判断它的加锁状态，如果可以加锁，就说明没有被使用。然后将其移动到队列尾部。如果有一个线程执行完毕，然后释放锁，将其移动到队列头部。
- 之所以加锁，是为了判断线程是否空闲。线程池也是这么设计的。
- 另外，每个线程也会采用JDK那种，while循环的方式，去获取任务。这样才能方式线程执行完任务后被销毁。

### java 的线程生命周期

- 大致分为以下几个状态
- 首先是创建，即刚刚new 完一个线程，处于**初始状态**
- 然后是调用start方法。它处于可**运行状态**。
- 然后是cpu分配线程，处于**运行态**
- 如果发生i/o操作，则处于**休眠状态，或者说阻塞状态**
- 运行完处于结束。

### 线程池中的任务出现异常会怎么样？

- 线程池提交任务有两种方法，一种是执行Execute方法，该方式提交的任务拿不到返回结果。
  - 如果通过该方式，追溯源码可以看到，会把线程封装为worker，然后调用对应任务的run方法，出现异常则会往外抛出，而抛出的异常最终到达了线程的run方法，而线程在run时如果出现异常，线程就会结束。
  - 即出现异常会导致该线程被销毁。
- 一种是通过submit方法提交任务，这种方式可以拿到任务执行结果。
  - 这种方式是把Callable封装到futuretask中，然后执行。它调用的并不是run方法，而是call方法。出现异常时会被捕获，然后封装后交给outcome。
  - 出现异常后可以在外边捕获然后处理的。不会导致线程终止。
  
  使用TheadPoolExcutor创建的线程池也有这两个方法

```java
ExecutorService executor = Executors.newFixedThreadPool(1);
//executor.execute(Runnable a)
Future<?> future = executor.submit(() -> {
    if (true) throw new RuntimeException("模拟异常");
});

try {
    future.get(); // 触发 ExecutionException
} catch (ExecutionException e) {
    Throwable cause = e.getCause(); // 原始异常
    logger.error("任务执行异常", cause);
}
```



### JAVA四种引用

1. #### 强引用

   通过new关键字直接创建的对象默认持有强引用，将强引用显示的将强引用赋值为null后JVM就可以回收对象

2. #### 软引用

   使用SoftReference实现的是软引用，内存不足就会被回收

3. #### 弱引用

   使用WeakReference 来表示弱引用，只要垃圾回收开始工作，无论内存是否足够，都会被回收

4. #### 虚引用

   使用PhantomReference 类表示

## JVM

### OOM一定会让JVM退出吗？

- JVM退出的条件：：JVM 不存在非守护线程（前台线程），JVM就会退出
- 线程发生未处理的异常（未处理异常由默认异常处理器处理）**会导致线程结束**，而线程结束了， 如果还有非守护线程（前台线程），JVM也不会退出

### Java虚拟机栈的回收

- 虚拟机栈，是每个线程私有的，当一个线程运行某个方法时，对应的会有一个栈帧的创建，然后伴随着栈帧的入栈。如果运行结束，栈帧会出栈，此时回收栈帧就可以了
- 栈帧中包含了局部变量表，和一些指向堆内存的引用，包括说

### JVM远程调试的原理

**JVM 远程调试**的原理是基于 Java 虚拟机提供的 **Java Debug Wire Protocol (JDWP)**、**Java Debug Interface (JDI)** 以及 **Java Virtual Machine Tool Interface (JVMTI)** 实现的。这些组件一起协同工作，使开发者可以通过调试工具远程连接到运行中的 Java 应用程序，实时监控和控制它的执行。

- **JDWP** 是一种协议，定义了调试器（客户端）和被调试 JVM（服务端）之间通信的方式。它的作用是让调试器能够通过网络或本地的通信接口（通常是 TCP/IP）发送调试指令给 JVM，并获取调试信息（如断点、线程状态、变量值等）。
- **JDI** 是 Java 中为调试器编写的高级接口，调试器通过 JDI 向 JVM 发送调试命令。JDI 是 JDWP 的高级抽象，它为开发者提供了面向对象的编程接口，隐藏了 JDWP 的底层实现细节，开发者通过 JDI 可以设置断点、查看变量、控制线程等。
  - Idea的debug，应该就是通过JDI来实现的打断点，停止运行，查看对应属性。
  - 调试器通过 JDI 可以监控 JVM 的运行状态。它可以通过以下操作进行控制和调试：
    - **设置断点**：指定代码运行到某处时暂停。
    - **单步执行**：逐行调试程序的执行。
    - **查看/修改变量**：检查和修改 JVM 中的变量值。
    - **监控线程**：查看当前 JVM 的线程状态，控制线程的执行。

![image-20241013160616226](/Users/guojunhao/Library/Application Support/typora-user-images/image-20241013160616226.png)

### 静态绑定和动态绑定

- 这个其实就是编译时多态和运行时多态。
- 编译时就能确定调用的是哪个方法，就是静态绑定，而只有到运行时才能确定的，就是动态绑定。
- 方法的重载，也是多态的一种，在编译时就可以根据方法签名确定，就是静态绑定。
- 方法的重写，就是动态绑定，要根据运行时的实际类型来确定调用的是哪个方法。

- Java当中，jvm确定一个方法的唯一性是根据类名、方法名、以及**方法描述符**来确定的。
- 而方法描述符则是由**参数类型**和**返回类型**构成的
- 如果子类中有一个方法与父类同名，且参数、返回值一样，那么如果两个方法都是非静态的，那么子类相当于重写了父类的方法。如果都是静态的，那么相当于子类会隐藏父类的方法。
- 方法描述符虽然包含了返回值类型，但是类的重载依赖于**方法签名**，而方法签名只包括了**方法名和参数**

### 了解三色标记法嘛？

- 将所有的对象的颜色分为了三种，白，灰和黑。
- 黑色对象是已经被扫描，且引用的对象也被扫描了的对象。
- 灰色是与黑白相间隔的对象，表示自身被扫描，但是引用的对象还没扫描。
- 白色是未被扫描的对象。
- 一个黑色对象不能直接指向一个白色对象。

### 怎么判断一个对象是否可达呢？

- 这里有两种算法
- 可达性分析算法，从gcroots开始扫描，如果该对象可达，那么就是存活的对象，否则该对象被视为应该被销毁的对象。可达性分析算法的一种实现就是三色标记法。
- 引用计数法，该算法无法解决循环引用的问题。

### 什么是Java的直接内存？

- 这个直接内存，主要是指非堆内存，直接由操作系统来管理，不能够被垃圾回收器回收的内存。这种内存主要通过 `java.nio` 包中的 `ByteBuffer` 类来分配和使用。
- 它的一个最核心的作用就是提高I/O的效率。传统的I/O，在进行操作时都需要将数据从内核拷贝到**用户空间，即jvm的内存空间**，但是直接内存运行数据直接从内核态。
  - **当执行 I/O 操作时，直接内存与操作系统的内核缓冲区共享同一块内存区域**。数据从磁盘读取后可以直接存储在这块内存中，避免了从内核缓冲区到用户空间缓冲区的拷贝。

### 垃圾回收算法，各自的优缺点？

- 标记清除，一般用于老年代，优点就是算法简单，并且执行该算法时，**由于不需要移动对象，~~所以不需要暂停用户线程，~~**， 会STW(**如果不进行STW，那么进程在运行时引用会发生变化（会产生新的引用或去掉引用），在标记和清除过程就会造成漏标或者多标**)。但是也因此会产生浮动垃圾，以及内存碎片。
- 标记整理，该算法设计到对象的移动，需要暂停用户线程，而且算法实现起来有一定的复杂度。
- 标记复制，一般也用于新生代 ，同样需要暂停用户线程，而且需要浪费掉一半的空间。
- 分代回收算法（新生代），8:1:1的内存区域划分，在不同的分代区使用上面的回收方法(年轻代使用标记复制(存活的对象少), 老年代使用标记-整理)。

### 有几种垃圾回收器？

- 我比较了解的有CMS，G1和ZGC
- CMS是一个老年代垃圾收集器，他一般搭配Pare new一起使用

### 介绍一下CMS，G1，ZGC，有什么区别，**各自适用于什么场景**，优点？

cms垃圾回收器，会产生内存碎片，这种内存碎片如果不开启某些参数是无法处理的。有一个参数，允许经过多少次垃圾回收然后去整理内存。

- CMS（**Concurrent Mark Sweep**），**基于标记-清除算法**（三色标记法），最大并发标记清除垃圾收集器，它会占用过多的用户线程，导致吞吐量下降。而且采用标记清除算法，容易导致内存碎片。不适合用于大内存，对于追求较短停顿时间的，可以选择这个收集器。

  **CMS之所以会产生浮动垃圾，是因为在并发清理阶段，用户线程仍然在运行，这个阶段产生的垃圾需要等到下一次才能清理。**

  垃圾回收流程：

  - 初始标记，此时需要stw。扫描GC roots可以直接关联到的对象，标记存活对象。
  - 并发标记。此阶段耗时最长，但是可以与用户线程一起执行。是对「初始标记阶段」标记的对象进行整个引用链的扫描。并发标记的时候，引用可能发生变化，因此可能发生漏标（本应该回收的垃圾没有被回收）和多标（本不应该回收的垃圾被回收）了
  - CMS在并发标记阶段后还会有两个阶段，但是主要目的是为了让最终标记的时间缩短。
  - 最终标记，此阶段需要STW。是为了处理并发标记阶段用户线程产生的新垃圾，以及纠正错误
  - 清除阶段（并发标记）。此阶段不需要暂停用户线程。**这一步会产生浮动垃圾，不能够处理，只能等下一次回收的时候清理**(标记清除算法缺陷)

- G1，老年代和新生代不再物理上隔阂，把整个堆空间划分为大小一致的region，每块region可以是新生代，可以是eden，或者suvivor，也可以是老年代。还有一个专门分配大对象的空间。**它采用标记整理算法**（整体），不会导致内存碎片。适用于较大的内存空间，且停顿时间可控，尽最大努力达到用户规定的停顿时间。

  **而G1之所不会产生浮动垃圾，是因为它采用的是标记复制算法（局部），在最终清除以及移动对象时，需要暂停用户线程，此时并不会产生垃圾。**

  当需要分配对象到 Humongous 区域或者堆内存的空间占比超过 `-XX:G1HeapWastePercent` 设置的 InitiatingHeapOccupancyPercent 值时，G1 会触发一次 concurrent marking，它的作用就是计算老年代中有多少空间需要被回收，当发现垃圾的占比达到 `-XX:G1HeapWastePercent` 中所设置的 G1HeapWastePercent 比例时，在下次 Young GC 后会触发一次 Mixed GC。在Mixed GC时发现老年区空间还是不够，会触发Full GC。**也就是说，当Eden区的内存不够时触发Young GC,当老年代区内存不够时触发Mixed GC(回收年轻代和部分老年代),在Mixed GC时发现老年区空间还是不够，会触发Full GC(年轻代和老年代都回收)**

  前面讲 G1 垃圾收集器的时候提到过，Young GC 和 Mixed GC 均采用的是[复制算法](https://javabetter.cn/jvm/gc.html)，复制算法主要包括以下 3 个阶段：

  ①、标记阶段，从 GC Roots 开始，分析对象可达性，标记出活跃对象stw

  2 对象转移阶段，把活跃对象复制到新的内存地址上。stw

  ③、重定位阶段，因为转移导致对象地址发生了变化，在重定位阶段，所有指向对象旧地址的引用都要调整到对象新的地址上。

  垃圾回收流程：

  - 初始标记阶段，需要STW。
  - 并发标记阶段，此阶段可以与用户线程一起执行。
  - 最终标记阶段，该阶段需要暂停用户线程
  - 筛选回收阶段。此阶段会挑选回收价值最大的Region进行回收。因为是标记整理算法，所以也需要STW。

- ZGC采用了染色指针技术，而且它的Region的大小不再是像G1那样一成不变，而是可变大小。

  ![image-20240407165718755](https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20240407165718755.png)

![](https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20240407165811531.png)

- 注意，ZGC初始转移是为了转移GC ROOTs，也就是跟节点，所以该阶段需要stw。
- ZGC 的两个关键技术：指针染色和读屏障，不仅应用在并发转移阶段，还应用在并发标记阶段：将对象设置为已标记，传统的垃圾回收器需要进行一次内存访问，并将对象存活信息放在对象头中；而在ZGC中，只需要设置指针地址的第42-45位即可，并且因为是寄存器访问，所以速度比访问内存更快。
- 指针染色：设置对象指针地址的第42-45位为**已标记**，不用再去访问内存读取对象中的GC年龄
- 读屏障：在读堆对象时会触发，获取对象的最新地址(地址映射表)

### 符号引用和直接引用有什么区别？

- ~~符号引用时在代码编译完成之后，由于对象并没有被实例化，所以此时需要有一个引用，来指明~~
- 在类加载之前，不知道被编译的类中所引用的类、方法或者变量他们的引用地址在哪里，所以只能用符号引用来表示。
- 而直接引用是在类加载阶段，会将符号引用解析为直接引用，此时就指向了引用对象的Class对象。

### 什么是JVM的分代回收理论？

- jvm的分代回收理论主要基于两个假设：
  - 大部分对象都是短命，或者说很快就不再使用了。
  - 存活长时间的对象很有可能一直存活。
- 因此，jvm的堆内存通常就分为了3个区域：
  - 新生代(Eden, s1()form),s2(to))
  - 老年代
  - 永久代\元空间
- 新生代一般采用分代回收算法，基于标记复制
- **当Eden空间不够时，进行Minor GC：会将Eden中大部分的对象进行回收，不能够回收的放入s1,s1空间不够时放入s2，s1和s2是新生代和老年代之间的缓冲，16次Minor GC后会将新生代的对象移入老年代**
- 而老年代往往采用标记清除或者标记整理
- 分代回收的主要优势在于提高了垃圾回收的效率：

  - 通过频繁回收年轻代，快速释放大多数短命对象占用的内存。

  - 将较少的、生命周期长的对象放在老年代，减少了老年代的回收频率。

### 类加载机制，类加载方法

- 双亲委派机制。
- 即每个类加载器并不会直接加载该类，而是交由父类的类加载器来加载。
- 之所以这么设计，是因为判断类是否是同一个类，取决于加载该类的类加载器以及类的全限定名。
- 这里判断的是一个类是否被加载，防止类被重复加载。

### JDBC是怎么打破双亲委派的？

- 这里主要是通过利用spi机制来进行打破的。
- JDBC的驱动程序必须由**应用程序的类加载器**来加载，而不是由**顶层的类加载器加载**。这是因为：
  - 应用程序通常会从外部引入 JDBC 驱动包（如 `mysql-connector-java.jar`）。
  - 这些驱动程序可能需要访问应用程序的其他类和库，因此它们必须由应用程序的类加载器加载，而不是父加载器。
  - 如果 JDBC 驱动被父类加载器加载，它将无法访问应用程序级别的资源，这会导致问题。

- 上边的描述不准确
- JDBC的driver接口定义在JDK中，但是它的实现类是放在classpath下的。因为driver接口是jdk提供的，而具体的实现是由每一个数据库厂商来实现的。
- DriverManager类会加载每个Driver接口的实现类并管理它们，但是DriverManager类自身是 `jre/lib/rt.jar` 里的类，是由bootstrap classloader加载的
- 根据类加载机制，**某个类需要引用其它类的时候，虚拟机将会用这个类的classloader去加载被引用的类**
- boostrap classloader显然是无法加载到MySQL driver的，**因此只能在DriverManager里强行指定下层classloader来加载Driver实现类，而这就会打破双亲委派模型**（一句话，Driver Mannager通过线程上下文中保存的类加载器来加载JDBC(默认就是Application ClassLoader)）
  - **Bootstrap ClassLoader**（引导类加载器）：负责加载最基础的Java类库，例如`java.lang.*`、`java.util.*`等基础类，通常这些类库位于JRE的`jre/lib/rt.jar`中。它是由JVM自身实现的，用来加载JDK核心类。它不直接继承自`java.lang.ClassLoader`，而是由底层C++代码实现的，且它无法加载外部的用户类或第三方库。
  - **Extension ClassLoader**（扩展类加载器）：用于加载位于`jre/lib/ext`目录中的类库，负责JDK扩展部分的加载。
  - **Application ClassLoader**（系统类加载器）：负责加载用户类路径（即通过`-classpath`或`CLASSPATH`环境变量指定的路径下）的类。比如你的应用程序的类和第三方库（如MySQL的JDBC驱动）都由它加载。

以下是DriverManager的源码

```java
static {
    loadInitialDrivers();
    println("JDBC DriverManager initialized");
}

private static void loadInitialDrivers() {
    AccessController.doPrivileged(new PrivilegedAction<Void>() { // 1. AccessController，Java安全模型
        public Void run() {
          	// 2. 核心，ServiceLoader就是JDK提供的SPI的实现方式
            ServiceLoader<Driver> loadedDrivers = ServiceLoader.load(Driver.class); 
            Iterator<Driver> driversIterator = loadedDrivers.iterator();
            try{
                while(driversIterator.hasNext()) {
                    driversIterator.next(); // 3. 遍历的过程会触发每个Driver实现类的加载
                }
            } catch(Throwable t) {
              // Do nothing
            }
            return null;
        }
    });
}

在ServiceLoader.load()中有：
cl = Thread.currentThread().getContextClassLoader();//将Application ClassLoader设置到线程上下文类加载器里，这样启动类加载器就是用Application加载器去加载spi的具体实现
```

线程上下文类加载器的原理是将一个类加载器保存在线程私有数据里，跟线程绑定，然后在需要的时候取出来使用。`Java.lang.Thread` 中的`getContextClassLoader()`和 `setContextClassLoader(ClassLoader cl)`分别用来获取和设置线程的上下文类加载器。如果没有通过`setContextClassLoader(ClassLoader cl)`进行设置的话，线程将继承其父线程的上下文类加载器(默认是Application ClassLoader)

### 类加载过程

- 加载，即将编译好的字节码从文件读取到虚拟机当中。
- 链接
  - 该过程又分为3步
  - 验证，~~即验证加载的字节码文件是否有误，是否安全。~~ 确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全
  - **准备，**为静态资源申请空间，并设置为默认值
  - **解析**，将符号引用解析为直接引用。这里，仅仅是解析那些在编译时就可以确定的方法调用，多态这种的，是在实际调用时，在虚拟机栈中进行解析的。（在编译的时候虚拟机并不知道所引用类的地址，所以就用符号引用来代替， 直接引用指的是指向目标的指针或者偏移量,将这些符号引用转换为实际的内存地址，即直接引用）；生成虚方法表：子类会先继承父类的虚方法表，然后将重写方法的方法表覆盖对应父类方法，添加子类自己的需方法表
- 初始化，该过程就为类的静态字段初始化它真正的值。并且执行静态方法。这里也和单例模式中的饿汉式对应。静态变量的赋值在类加载时就会完成。所以饿汉式不存在线程安全问题。

### 类卸载过程

![image-20250331142256915](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250331142256915.png)

### 如何手动卸载类：

自定义的类加载可以卸载：

1. 获取类加载器
2. 获取已加载的类
3. 将Class对象设为null，再调用GC就可以卸载类

### new 一个对象的过程

- 首先会去判断类是否被加载了。如果没有被加载，就会去执行类加载的过程。（类加载检测）
- 之后，会现在堆空间的Eden区去申请一块内存空间，包括本类和父类的所有实例变量。（分配内存）
- 对所有实例变量赋默认值：将方法区内对实例变量的定义拷贝一份到堆区，然后赋默认值（赋初值）
- 设置对象头
- 执行初始化代码：初始化顺序是先初始化父类再初始化子类，初始化时先执行实例代码块然后是构造方法（初始化）
- 最后将实例的引用赋值给声明的变量

### jvm内存结构？

![image-20250319220524437](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250319220524437.png)

- 程序计数器，每个线程私有的空间，用于记录当前线程执行到哪个位置。通过程序计数器，来确定当前应该执行哪一条指令。
- java虚拟机栈，每个线程私有的。每当方法执行时，都会创建一个栈帧，并入栈。

  栈帧又包括以下几部分内容:

  - 局部变量表，用于存储线程执行方法时创建的私有变量，**对象的引用**(reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置)以及方法参数。
  - 操作数栈，用来存储方法执行中执行的各种操作。
  - 动态链接，**主要是为了将符号引用解析为实际的方法引用，为了支持动态绑定的特性。**
  - 方法返回地址
  - ![image-20250319220754293](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250319220754293.png)
- 元空间，方法区。存储运行时常量池(字面量、符号引用)，~~以及类编译后的一些成员变量~~ 一个类的类型信息、方法信息、字段信息等。gpt4给的最新说法，一个对象的Class对象是存储在元空间当中的。
- 本地方法栈。
- 堆，存放对象。字符串常量，静态变量。

### jmm，java内存模型？

- 主内存：主要存储的是Java**实例对象**，所有线程创建的实例对象都存放在主内存中， 不管该实例对象是成员变量还是方法中的本地变量(也称局部变量)，当然也包括了共享的类信息、 常量、静态变量。由于是共享数据区域，多条线程对同一个变量进行访问可能会发现线程安全问题。
- 工作内存：主要存储当前方法的所有本地变量信息(工作内存中存储着主内存中的变量副本)，每个线程只能访问自己的工作内存，即线程中的本地变量对其他线程是不可见的。注意基础类型会直接存储在线程私有栈中，**如果是引用对象，虚拟机栈中存储的是引用，实际值在堆中**
- Java 内存模型的规定：  
  - （1）所有变量存储在主内存中。  
  - （2）每个线程都有自己的工作内存，且对变量的操作都是在工作内存中进行。  
  - （3）不同线程之间无法直接访问彼此工作内存中的变量，要想访问只能通过主内存来传递。 

### **对象头里有哪些内容？**

- 锁标记位
- hashcode
- gc年龄
- 上边都是mark word中的内容
- 如果对象是数组，则还有一个记录数组大小
- klass_pointer

### 方法区、永久代和元空间的关系：

类似于接口和类的关系，方法区是一种虚拟机规范，永久代是JDK1.8之前的方法区的实现，而元空间是JDK1.8之后的方法区实现

### 方法区，或者说元空间主要存储了什么？

- ~~编译后的类型信息，包括成员变量~~，这前边的是对的。
- 编译后类的元数据，包括名称，修饰符，父类，接口，字段等。
- 静态变量
- 常量
- Class对象

### 为什么永久代被替换为元空间

- 整个永久代的大小受到JVM参数的限制，也就是说受到JVM内存大小的限制，**而元空间是利用本地内存，只受到本机内存的限制**
- 在永久代FullGC比较频繁

### 什么是双亲委派？为什么要采用双亲委派这种方式加载？

- 每个类加载器并不会直接加载该类，而是交由父类加载器去加载。

- 主要是因为比较对象是否为同一个对象时，需要依靠加载它的虚拟机以及全限定名来一起比较

### 哪些对象可以当作GCRoot

- 方法区中的静态属性和常量引用的对象
- 虚拟机栈和本地方法栈中引用的对象

### **资源被其他线程持有的时候，JVM是如何阻塞其他线程的？**

- 这个问题的答案，目前确实不知道。

### ClassLoader知道吗？

- 类加载器
- 可以自定义类加载器(通过继承Classloader)

### **怎么估算java中一个类对象占有的堆空间大小**（从对象的各个组成部分回答）

- 首先就是判断一下它当中有哪些成员属性，这里需要忽略静态属性的大小
- 方法是不和类放在一起的，存储在元空间中。
- 然后就是对象头的大小

### 垃圾回收算法为什么只用于堆

- 因为其他的部分都是线程私有的，在执行完任务后会随着线程的消亡而消失。就堆中存在的东西是一直存在的。

### spring中的bean会被垃圾回收器回收吗？

- 这里取决于bean是否仍然被spring 容器管理。
- 如果spring 容器仍然存活，那么它会有一个静态变量一直引用着其中的bean，保证它不会被垃圾回收器回收。
- 如果容器消亡，那么bean会被垃圾回收。

### synchronized和reentrantlock分别是怎么知道加锁的线程是谁呢？

- synchronized在轻量级锁，**mark word是会指向加锁的线程的锁记录**，该锁记录会复制一份mark word。
- 如果是偏向锁，则直接指向加锁线程。
- 如果是重量级锁，会指向一个C++的ObjectMonitor，这个类中会记录对应的信息。
- ~~而reentrantlock，则会有专门的成员变量来记录是哪个线程加的锁。释放锁时会进行比较。~~
- reentrantlock，加锁成功后，有一个**成员变量**`exclusiveOwnerThread`会保存持有该锁的线程，然后只需要对比释放锁的线程和保存的线程是否是同一个即可。

### java 中有哪几种指令重排序方法

1. 编译器优化的重排序。编译器在**不改变单线程程序语义**的前提下，可以重新安排语句的执行顺序。
2. 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在**数据依赖性**，处理器可以改变语句对应机器指令的执行顺序。
3. 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

### 为什么要有重排序

- 在没有违反程序语义（即，不改变单线程程序执行结果）的前提下，**指令重排序可以使CPU更有效地利用其资源**，例如，通过并行执行多条指令，或者避免因等待数据从内存加载而导致的CPU空闲。

### jvm压缩指针一般指的是什么？jvm是怎么实现的？

- 压缩指针是Java虚拟机（JVM）中的一种优化技术，用于**减少64位JVM中对象指针的大小**。
- 在没有压缩指针的64位JVM中，对象引用通常占用64位（8字节）的内存。
  - 增加了GC开销：64位对象引用需要占用更多的堆空间，留给其他数据的空间将会减少，从而加快了GC的发生，更频繁的进行GC。
  - 降低CPU缓存命中率：64位对象引用增大了，CPU能缓存的oop将会更少，从而降低了CPU缓存的效率。
- 操作系统，采用了8bit（比特）为一组，代表1byte（字节）,做到了2^32次方，也就是4字节，32位去表示4GB。它的每一位并不是指1bit，而是1byte（寻址的时候扩大就可以了）。
- java对象的指针地址就可以**不用存对象的真实的64位地址**了，而是可以存一个映射地址编号。这样4字节就可以表示出2^32个地址,而每一个地址对应的又是8byte（堆内存里采用8字节对齐的方式存储实际对象）的内存块。所以，再乘以8以后，一换算，就可以表示出32GB的内存空间
- 而Java的实现方式，就是在操作系统的基础上，又扩大了8倍。

### java 的引用句柄访问对象真实数据的过程？

- java有两种方式，直接指针或者使用句柄。

- 如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。

  <img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/image-20240425192721646.png" alt="image-20240425192721646" style="zoom:67%;" />

- 使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要修改。
- 使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销， 由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。
- **最关键的优化：多个引用可以指向同一个句柄。那么修改时只需要修改句柄即可。**但是直接引用在gc时，每一个指向对象的引用都需要修改。即要遍历所有的引用，找到指向该对象的引用，然后修改。

### 内存屏障的实现大概是怎么做的？它是怎么干涉排序的？

- 它是一种cpu的指令。
- 确保在一个指令执行load时，另一个指令不能插队。
- 一个指令在执行写操作时，另一个指令同样不能插队，并且刷新缓存。

### 记忆集和卡表分别是什么，什么关系？

- **由于Java对象之间存在引用关系**，可能有一些老年代的对象引用了年轻代的对象。在进行年轻代垃圾收集时，为了保证引用完整性，需要扫描整个老年代找出这些引用关系，这无疑会增加GC的时间。为了解决这个问题，垃圾收集器使用了记忆集。

  **记忆集记录了老年代中哪些对象引用了年轻代的对象**，这样在进行年轻代垃圾收集时，**只需要扫描记忆集中的对象而不是整个老年代。**

- 卡表是一种用于实现记忆集的数据结构。Java堆被划分为固定大小的区块（通常是512字节），每个区块通过卡表中的一项进行记录。卡表是一个字节数组，每个字节对应于堆中的一个区块。**如果区块中的对象发生了引用变化，那么对应的卡表项就会被标记**。
- **卡表用于追踪哪一块区域发生了引用变化，而记忆集则是记录了具体的对象间的引用关系。**
- 卡表是用于追踪新生代和老年代之间的引用关系而存在的，当新生代进行垃圾回收时，只需要找到卡表被标记为脏页的即可，无需扫描整个老年代。
- ~~而记忆集，则是g1垃圾收集器用于决定回收哪一块region的。~~ 这一块区域是一个优先级队列，不是记忆集。卡表是记忆集的一种具体实现。

### Java中的对象一定分配在堆上吗

- 并不一定。常规的对象创建都是在堆上创建的，但是如果虚拟机进行了逃逸分析，发现某个对象只在一个方法中使用，且不会逃逸出该方法，那么对象的创建就会在栈上。
  - 这种方法也被称为**标量替换**。他其实是将该对象分解为这个方法所使用的若干个成员变量。在栈帧上或者寄存器上创建对应的属性。
  - 也有可能是直接在栈上分配对象。
- 这种优化可以减少堆上垃圾回收的开销。

## I/O

### Java的堆外内存和直接内存是什么？

- 堆外内存和直接内存是相似的概念，堆外内存是一个更广泛的概念，Java语言的体现就是直接内存。
- 堆外内存一般指的是NIO中，通过ByteBuffer申请的内存，它不由JVM虚拟机的垃圾回收机制进行回收，~~与操作系统的内核台共享内存空间~~。
- **直接内存（Direct Memory）** 是一种堆外内存，它是通过 `ByteBuffer.allocateDirect()` 在操作系统的本地内存中分配的，而不是在JVM的堆内存中分配。**直接内存(堆外内存)的主要优势是能够避免Java堆内存和操作系统本地内存之间的频繁数据拷贝**。

### Java有哪些I/O模型，都是什么样的？

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20251026145544249.png" alt="image-20251026145544249" style="zoom:33%;" />

- NIO(Non Blocing IO)，同步非阻塞I/O，当数据没有准备好时，会不断调用read。
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250904161416217.png" alt="image-20250904161416217" style="zoom:33%;" />
- BIO(blocking IO)，同步阻塞I/O，最传统的I/O。每当一个请求到来，建立连接后处理请求，当请求中有I/O操作时，就要阻塞该线程，直到I/O完成才可以继续处理。
- ~~AIO，异步I/O，通过监听的机制，当I/O完成之后，操作系统会通知对应的线程。~~
- AIO(Asynchronous IO)，采用异步 I/O 模型，线程发起 I/O 请求后立即返回，当 I/O 操作完成时通过回调函数通知线程，进一步提高了并发处理能力，适用于高吞吐量场景。采用的是回调函数这种形式。
- I/O多路复用：事先将channel(Socket连接)和感兴趣的事件(读写事件等)注册到系统调用select/epoll一个Selector(一个线程)，Selector会不同轮询监听对应的channel，当某些事件发生时会唤醒阻塞的应用程序并返回给他可用的事件列表

### 什么是同步、异步、阻塞、非阻塞 I/O？

一篇写的不错的博客：https://www.cnblogs.com/loveer/p/11479249.html

假设这里有三个对象：发送方线程，接受方线程，I/O操作

同步或者不同步是对发送方线程和接受方线程来说

阻塞与非阻塞是对同一个线程来说的，在某个时刻，线程要么处于阻塞，要么处于非阻塞

- 同步：指的是处理请求，或者发起I/O时，必须等待该请求或者该I/O操作完成之后，才可以返回。**这里，其实更多的是指请求的，请求需要等待调用的方法执行完毕后，才可以继续执行其他的方法。**（发送方线程在发送请求后会等待接受方线程响应）
- 异步：指的是请求发出后，线程并不需要等待请求处理结束，而是直接返回，可以处理其他的请求。根据具体实现，来决定在IO或者请求完成后，是否有相应的回调。（发送方线程在发送请求后直接返回，不会等待接受方线程响应）
- 阻塞：阻塞指的是如果在请求的处理中，IO数据没有准备好，则对应的线程会一直等待，直到IO数据准备好，或者请求处理完成。这里指的更多的是I/O的返回。**也就是说，如果必须等待I/O结束才能返回，那么就是阻塞的。如果不需要等待I/O执行完毕，比如说发起I/O后就返回那就是非阻塞**（接受方线程发起I/O操作阻塞等待I/O结果）
- 非阻塞：调用方发出 I/O 请求后，如果数据未准备好，会立即返回而不等待，调用方可以继续执行其他操作。（接受方线程发起I/O后直接返回，不会等待，I/O接受后通过回调函数获取结果）

其实阻塞操作往往涉及到一个线程状态的变更，同步和阻塞是两个不同的概念，同步强调的是任务的顺序执行，一个接一个的，不能跳过。而阻塞强调的是一种状态，线程会因为调用该方法，在方法没有完成之前处于阻塞的状态。

GPT给的说法：

1. **同步（Synchronous）**：
   - 同步指的是程序按照预定顺序执行，一个任务完成后才能开始下一个任务。在同步操作中，当一个操作开始时，程序会等待这个操作完成后才继续执行下一个操作。这种方式保证了程序执行的顺序性和可预测性。
2. **异步（Asynchronous）**：
   - 异步是指程序执行过程中，不需要等待某个操作完成，而是可以继续执行后续操作。在异步操作中，任务可以并发执行，程序可以在等待某些耗时操作的同时继续执行其他任务。异步操作通常通过回调函数、事件驱动或者使用特定的语法和工具来实现。
3. **阻塞（Blocking）**：
   - 阻塞指的是调用一个操作后，当前线程被挂起，直到操作完成并返回结果。在阻塞式调用中，调用者必须等待调用的操作完成后才能继续执行下一步操作。
4. **非阻塞（Non-blocking）**：
   - 非阻塞指的是调用一个操作后，当前线程不会被挂起，而是立即返回。如果操作已经完成，则返回操作结果；如果操作尚未完成，则返回一个标记，告诉调用者可以稍后再来检查操作的状态。

**阻塞和同步的区别**：

- **阻塞**是一种执行模式，指调用一个操作后，调用者被挂起直到操作完成。
- **同步**是一种执行方式，指任务按照预定顺序依次执行，一个完成后才能执行下一个。

### 什么是字节流和字符流？有啥区别？

- 字节流可以处理图像，文件等。而字符流只适用于处理文本一类的数据。字符流经过编码可以转化为字节流。

### 什么是I/O流？

- 就是输入流和输出流

### 介绍一下NIO(new IO)

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250320140845938.png" alt="image-20250320140845938" style="zoom: 33%;" />

- 同步非阻塞I/O，之所以是同步又是非阻塞，是因为采用了I/O多路复用机制，且它还有channel，buffer，selector的概念。
- buffer；NIO 在读取数据时，它是直接读到缓冲区中的。在写入数据时，写入到缓冲区中。 使用 NIO 在读写数据时，都是通过缓冲区进行操作
- channel:它建立了与数据源（**如文件、网络套接字等**）之间的连接。我们可以利用它来读取和写入数据，就像打开了一条自来水管，让数据在 Channel 中自由流动。读操作的时候将 Channel 中的数据填充到 Buffer 中，而写操作时将 Buffer 中的数据写入到 Channel 中
- Selector 是基于事件驱动的 I/O 多路复用模型，主要运作原理是：通过 Selector **注册通道的事件**，Selector 会不断地轮询注册在其上的 Channel。当事件发生时，比如：某个 Channel 上面有新的 TCP 连接接入、读和写事件，这个 Channel 就处于就绪状态，会被 Selector 轮询出来。Selector 会将相关的 Channel 加入到就绪集合中。通过 SelectionKey 可以获取就绪 Channel 的集合，然后对这些就绪的 Channel 进行相应的 I/O 操作。
- SelectionKey代表了channel和selector的注册关系，每个 SelectionKey包含：注册的 Channel实例、所属的 Selector 实例、关注的事件集合（如 `OP_READ`、`OP_WRITE`）、当前就绪的事件集合。

### select/poll 、enpoll？

- 操作系统的I/O多路复用需要依赖的机制。
- 首先是select/poll，它的主要流程是所有建立链接的套接字或者文件描述符，需要全部拷贝到内核态，然后内核扫描整个套接字的集合，找到可读或者可写的，做好标记，返回给用户态。用户态需要再次遍历整个套接字，去处理对应的请求。
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250915163731630.png" alt="image-20250915163731630" style="zoom: 50%;" />
- 而enpoll，它是在内核中维护了一个红黑树，每次只需要拷贝一个套接字到内核中去，然后内核中还维护了一个可读或者可写的集合，可以直接返回给用户态。不需要遍历，且拷贝数据量小。 
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250915164449363.png" alt="image-20250915164449363" style="zoom:50%;" />
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250915164916444.png" alt="image-20250915164916444" style="zoom:50%;" />

### 什么是I/O多路复用？

- 只需要一个线程，去创建连接，即套接字或者说文件描述符。
- 然后利用操作系统的select/enpoll机制，每当这个套接字变得可读或者可写，就通知线程去处理对应请求。
- 一般来说会将可读或者可写的套接字加入到一个任务队列当中，有一个线程会依次执行队列中的任务。

> 非阻塞的 read，指的是在数据到达前，即数据还未到达网卡，或者到达网卡但还没有拷贝到内核缓冲区之前，这个阶段是非阻塞的。
>
> 当数据已到达内核缓冲区，此时调用 read 函数仍然是阻塞的，需要等待数据从内核缓冲区拷贝到用户缓冲区，才能返回。

### **为什么会出现零拷贝？什么是零拷贝？**

- 以最典型的 “服务器读取本地文件并通过 Socket 发送给客户端” 为例，传统 IO 流程（如 Java 的`FileInputStream`+`Socket`）会产生**4 次数据拷贝**和**2 次 CPU 用户态 / 内核态切换**:磁盘 → 内核缓冲区 → 用户缓冲区 → Socket 缓冲区 → 网卡
- 需要经历4次复制以及两次用户态和内核态的转换。
- 而零拷贝就是为了减少这种复制。
- 它只需要将数据从磁盘读入内核，然后建立一个内核到用户态的映射到同一块物理内存（直接内存，堆外内存的一部分），实现 “内存共享”—— 应用程序无需拷贝数据到用户缓冲区，直接操作内核缓冲区即可，并不需要真实拷贝，就可以将对应数据从内核缓冲区拷贝到socket缓冲区，然后写入网卡。
- 而更为具体的零拷贝，需要网卡支持一个功能，可以直接将数据从内核缓冲区写入网卡，无序复制到socket缓冲区。

### mmap(内存映射文件)

- mmap 是一种内存映射文件的方法，即将一个文件映射到进程的地址空间，实现文件磁盘地址和一段进程虚拟地址的映射
- 首先建立映射关系：系统会在内存中划出一块区域(既不是堆也不是栈)，并记录这块内存(虚拟地址)与文件的对应关系。此时文件内容并未全部加载到内存，而是按需读取。
- 按需读取：当程序通过虚拟地址访问内存中的某个地址时，如果发现对应的文件数据还未加载（触发缺页异常），系统才会从磁盘读取这部分数据到物理内存(不是物理磁盘地址)，在这个过程中会建立**虚拟地址和物理内存(内核空间)的映射关系**，在这之后进程就可以通过查询页表(页号+偏移量)得到物理内存地址，并进行访问
- 自动同步：修改内存中的内容后，系统会在合适的时机（如内存不足时）自动将改动写回文件。也可手动调用 `msync()` 强制同步

### NIO的reactor模型，多线程reactor模型？

- 类似于I/O多路复用，只不过多了几个概念，selector，acceptor，handler或者reactor。

# MySQL

### Mysql的存储引擎

- InnoDB：InnoDB是MySQL的默认存储引擎，具有ACID事务支持、行级锁、外键约束等特性。它适用于高并发的读写操作，支持较好的数据完整性和并发控制。
- MyISAM：MyISAM是MySQL的另一种常见的存储引擎，具有较低的存储空间和内存消耗，适用于大量读操作的场景。然而，MyISAM不支持事务、行级锁和外键约束，因此在并发写入和数据完整性方面有一定的限制
- Memory：Memory引擎将数据存储在内存中，适用于对性能要求较高的读操作，但是在服务器重启或崩溃时数据会丢失。它不支持事务、行级锁和外键约束。

### MySQL的update

- MySQL的update，在修改数据时，他其实先要查询数据，即先走select，如果对应的数据没有在buffer poll当中，那就要先加载数据。
- 然后，如果**update的数据有索引**，那么流程是先插入一条新的记录，然后删除之前的记录，因为索引被修改，它的位置也会不一样。
- 针对于没有索引的数据，因为不涉及位置的移动，直接原地修改就好了。
- 如果上边的是正确的，那么在针对于间隙锁，就可以锁住针对于主键的修改，但是锁不住针对于非主键的修改，仍可能出现幻读。
- 上边的不一定对，实测下，无论修改主键索引，还是修改无索引字段，都会被锁住，查询是select for update。
- mysql的select for update，where条件中如果没有索引，他就锁表了。肯定改不了

### MySQL两次查询时间差距较大什么原因？

- 第一次查询，可能对应的数据页以及索引页没有在内存当中，所以查询的时候需要先加载这些内容，而第二次重新执行该sql时，已经不需要从磁盘加载这些内容，或者说加载的比较少了，就会快很多。

- 天籁美誉这个项目，如下的sql实测，有较大差异，时间有些1s，有些0.6有些甚至10s，但是第二次查询就会在0.2s，0.3秒左右。

  - ```mysql
    select count(*) from sae_activity_student sas,
    sys_user su,
    sys_org so
    where so.`_pid` = '渝中区教委'
    and so.oid = su.oid 
    and su.uid = sas.uid
    ```

### int(10)中的10代表什么？

- 显示的宽度，注意字节数和10这个数字无关

### varchar(10)代码的是什么？

- 代表的是最大的字符数，不论编码格式，具体的字节数根据内容变化

### MySQL 8.0中的bin to uuid

- ~~这个其实是一个uuid的算法，它通过调整uuid时间戳所在的位数，保证了uuid是有序的。因为后生成的时间戳，一定大于前边的。~~

- **UUID_TO_BIN**和**BIN_TO_UUID**，是两个函数，将对应的uuid转化为二进制数据，或者将二进制数据转化为对应的uuid

- ```mysql
  insert into city_temp(`name`, parent_name, `number`, column_1, column_2, mark_id) 
  values("1", "1", 1, 1, 2, UUID_TO_BIN("00082da3-77ca-4a80-98f6-8117fdd19001", 1))
  
  show index from city_temp
  
  -- 可以走索引
  explain SELECT * 
  FROM city_temp 
  WHERE mark_id = UUID_TO_BIN('00082da3-77ca-4a80-98f6-8117fdd19001', 1);
  
  -- 无法走索引
  explain SELECT * 
  FROM city_temp 
  WHERE BIN_TO_UUID(mark_id, 1) = '00082da3-77ca-4a80-98f6-8117fdd19001';
  ```

- 注意上述的一种优化。

### 讲一讲你对于InnoDB的理解

- 首先，InnoDB是支持事物的，他可以保证数据库在崩溃或者故障下的数据的完整性。
- InnoDB支持行锁，提高了并发性
- MVCC多版本并发控制
- InnoDB支持崩溃自动恢复数据。也就是说重启时会根据三大日志（这里其实只用到了两个，redo log 和undo log），将数据恢复到一个正确的状态。但MyIsam无法自动恢复。

### InnoDB和MyISAM有什么区别？

- MyISAM不支持事物
- MyISAM只有表级的锁，而InnoDB有行锁。
- 有无崩溃自动恢复机制。是否支持外键。
- InnoDB使用表空间来管理数据。

### 什么是InnoDB的表空间？

- InnoDB 的表空间（Tablespace）是一个存储数据和索引的逻辑结构，它管理和组织 InnoDB 数据库中的表和索引的数据存储方式。

### MySQL的Oryder By 是怎么执行的

- 如果排序字段和查询字段存在索引且满足**排序字段放索引前缀，查询字段放索引后缀**，则可利用索引直接返回数据，不用文件排序
- 首先，初始化sorted buffer的大小，放入我们要查询的字段
- 它会先读取我们要排序的数据，将对应的数据加载到sorted buffer当中。这一步就是正常的select的过程
- 上一步当中，如果数据量过大，那么它会采用外部排序，即将数据存储到磁盘当中。
- 如果能够加载到内存，那么就对读取到的所有数据做一个快排。
- 然后做limit操作，返回给用户。
- 另外，如果查询的字段的大小超过了某个值，那么就只会放入我们要排序的字段和主键(rowid)，这种也叫rowid排序。但是这种排序后，需要回表查询(可以查聚簇索引)完整的数据给用户返回。

## 日志

### redo log是干什么的

- write-ahead-log，先写日志，再写磁盘。

- 它的一个作用就是保证数据库的持久性和一致性。像数据库进行更新操作时，为了讲究效率，一般将对应数据在缓存中，也就是buffer poll中修改后，然后将数据页标记为脏页，就结束了。**此时如果数据库断电，就会导致更新操作数据丢失。redo log 就是为了防止这部分数据丢失**。在内存中更新完之后，写日志，操作就算结束，不需要落盘也不用担心数据丢失。

- 上述的操作，也对，但是不准确。先将数据写入缓存确实是为了提高效率，但是redo log存在的意义，是为了保证事务的一致性。因为想要进行数据回滚，就必须先记录当前执行了哪些操作，才能真正的去操作对应的数据。

- 在redo log出现之前，想要保证事务就需要把整个binlog全部写入之后，才能去对数据进行落盘，效率太低了。所以出现了redo log。先写日志，其实写日志的同时可以操作缓存中的数据，并不需要将数据落盘了。

- 其实从另一个角度来说，**redo log的存在，确实提高了性能**。因为事务要保证持久性，我们有了redo log，事务提交后也不需要将数据落盘了。缓存中的数据掉电会丢失，但是可以根据redo log 恢复。

- 而且redo log的落盘是顺序落盘的，而数据的落盘是随机的（MySQL的数据要根据索引的位置来落盘），同样提高的性能。

- reod log是详细的记录了物理数据页数据的变化(如 “表 A 的 ID=1 行，col1 从 10 改为 20”)，与数据页地址绑定，可以根据redo log 将数据会滚到之前的状态。而binlog绝大多数情况下只记录了sql语句，而不会记录每一行的变化，没办法拿他来得到我们需要回滚多少数据。

### binlog 是干什么的

- 归档日志(二进制日志)。用于将数据恢复到某一个时刻。常常拿来做主备同步(主从复制)或者数据恢复(数据备份)。
- 它是MySQL的Server层日志， 记录了所有**数据库表结构变更和表数据修改**的日志，不会记录查询类的操作
- 他有两种格式，一种是row，一种是statement。
- 其中，row格式会记录每一行数据所做的变动。也就是说如果我们改了1000行，他就需要记录1000行。
- 而statement则是记录了我们所执行的sql语句。但是需要注意，如果语句中带有now等特殊的语句，可能会出现主从不一致等情况。
- 所以说一般采用混合的方式，MySQL自己判断当前需要用row格式还是statement格式。

### binlog的三种格式

- binlog有row、statement、mixed三种格式
- 其中row格式下，会详细记录每一行数据最终被修改成什么样了，不会有什么问题，但是占用的磁盘空间太大了。
- statement格式下，会记录SQL语句本身以及它的一些上下文，但是这种格式下主从同步可能会有问题，比如说记录了一些与时间相关的函数时。
- mixed就是混合的方式。由MySQL自己决定记录为什么格式。

### MySQL的大事务会有什么问题呢？

- 从binlog的角度去考虑，一个事物的binlog必须一次性写入，binlog是先写缓冲区，然后刷盘的，多个binlog不能穿插写入，这也就导致了只能将一个binlog写完后，再写第二个，大事务的binlog会写入很多，可能会阻塞后续binlog的写入。

### undo log是干什么的

- 回滚日志，用于确保MySQL事务的原子性
- 当InnoDB对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log ，比如插入，记录主键；删除，记录整行数据；更新，记录旧值
- 另外，隔离性也需要undo log 来保证。因为事务版本号不可见的，需要通过undo log回滚到可见版本。

### redo log 和 binlog 有什么区别？分别的作用

- 一个是InnoDB引擎特有的，一个是server层日志
- 一个用于归档，即将数据恢复到某一个时刻。（binlog）
- 一个用于确保crush-safe。根本作用是为了确保数据库异常掉电，重启后数据不丢失。确保数据库事务的持久性。(redolog)

### 二阶段提交，为什么要二阶段提交，不这样会有什么问题？任何地点中断会有什么问题？

![image-20250321153556283](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250321153556283.png)

- 两阶段提交是分布式事务中常用的方法。
- 从用户的角度来讲，这两个日志都是MySQL的日志。
- 但是从MySQL来讲，这两个日志一个是Server层日志，一个是引擎层日志，位于两个不同的区域。想要确保这两者的一致性，需要采用分布式协议。
- 具体来说，首先开启一个内部事务XA，先对redo log写完之后(同时将事务ID写入redo log)，并不提交事务，而是处于一个prepare状态，然后去写binlog日志(同时将事务ID写入到binlog)。当binlog写完之后，再去提交事务。
- **根据prepare状态的redo log中事务ID去找binlog是否有这样的事务ID，如果没找到，说明写完redo log，还没有写binlog，断电了，那么重启后回滚事务就可以了。**
- **如果找到了，说明binlog 也写完了，重启后提交事务就可以了。**
- binlog 都没写完，数据就不会存在，也就不存在一致性问题。

### 组提交，为什么要组提交？

- 因为数据库的事务需要确保一次性写入，而双1配置下就意味着只有一个事务写完之后，才可以写另外一个事务，且需要加锁来保证一次只有一个写入，性能很低。
- 组提交就是redo log的prepare阶段不再落盘。
- 而commit阶段又分为了3个小步骤：
  - 首先是redo log 积攒一批之后，一次性落盘，这一批事务的binlog 写page cache
  - 这一批binlog进行刷盘
  - 这一批事务commit。

- 这样就相当于将原先需要加锁一步完成的过程分为了三步，且需要三个粒度更小的锁，性能更好。 

### redo log 怎么保证事务的持久性的？

- 通过redo log来恢复对应的数据，先写缓存，然后写日志，依靠日志来恢复数据。

### **只使用binlog，不用redo log可以吗？**

- 不可以，除非每次写写完数据就直接刷磁盘。效率很低。
- 如果只用binlog，那么无法保证事务的持久性。
- 更新写入内存就返回的数据，异常重启就会丢失。
- 另一方面，binlog只是记录了执行的SQL，而redo log则是反映了内存数据页的变化。假设执行一个SQL，我们仅仅依靠binlog并不能知道它是否执行完毕了。

### redo log 刷盘时机？策略？

- 如果依靠自动的，MySQL后台有一个线程，每秒将Redo log buffer中的内容落盘。
- 另外有一个参数，可以设置。
- 为0，表示不会主动去刷盘，等待后台线程
- 为1，表示每次写入都会直接落盘
- 为2，会写入操作系统的page cache，什么时候落盘取决于操作系统。
- 另外，redo log 是循环写，如果空间不足了，也会刷盘。如果满了，则要暂停用户线程，先刷盘，再执行请求。

### binlog 什么时候写入磁盘？什么时候写binlog？

- binlog 刷盘时机也是有一个参数，
- 为0，表示每次都只写到page cache，不落盘
- 为1，表示每次都落盘
- 为N，表示积攒N个事务后再落盘。

## 索引

### 索引有哪些种类？

- 覆盖索引
- 主键索引
- 二级索引
- 聚簇索引和非聚簇索引

### 什么是覆盖索引？

- 这是一个相对的概念。取决于我们查询的数据。其中，主键索引一定是覆盖索引和聚簇索引。
- 回表：但是用非主键去查询时，会先查询这个非主键索引得到主键ID，然后再去查主键索引查询到想要的数据，这种需要查询两次索引就叫做回表。
- 比如说我们有一个联合索引abc，如果我们查询a，ab，abc这三者中任何数据，那么abc这个索引对于此次查询来说就是覆盖索引。因为索引列包含了所有要查询的数据，不需要回表。

### 聚簇索引与非聚簇索引？

- 这里的概念就是叶子节点是否存储真实的数据，如果存储则是聚簇索引，如果仅仅是存储指向主键的指针，那么就是非聚簇索引。

### 主键索引与非主键索引？

- 主键索引叶子节点存储真实的数据，而非主键索引叶子节点是指向主键索引的指针。它的查询需要回表。
- 如果走的是非主键索引，那么找到叶子结点之后，他就可以获取到对应数据在主键索引中的值，然后拿着这个值，即主键索引，去主键索引树中再查找一次。
  - 即，如果发生回表操作，那么就意味着要走两个索引树，主键索引和非主键索引都需要走一遍。

### B+树形式

- 首先，**B+树只有叶子结点才会存储真正的数据行。非叶结点，存储的都是指向下一层的索引记录**。且这个记录是有序的，也就是说非叶结点，一个数据页16kb的大小，存储的都是指向下一层的索引记录。

- 上边说的其实不太准确，非叶结点，存储的是索引的有序对，B+树是多叉树，这里边存储的其实就是对应的索引，但是没有对应的记录。

- 叶子结点，一个数据页也是16kb，里边都多条数据，然后在该结点内部，找到具体要查找的数据行。

- 每个叶子节点有两个指针，分别指向下一个叶子节点和上一个叶子节点(**叶子节点之间形成一个双向链表**)

- 根据建立的索引，其实没办法定位到具体的数据行，只能定位到数据所在的数据页，然后根据偏移量找到具体的数据。

  ![image-20250321161720366](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250321161720366.png)

### B+树结构，为什么不用b树和跳表、红黑树和二叉平衡树？

- b+数属于一种多叉平衡搜索树。它的叶子节点存储真实的数据，非叶节点仅仅存储指向下一层的指针。
- 由于MySQL需要持久化，也就是说很多数据需要从磁盘中读取。B+树的特性决定了它的高度在存储大量数据时也不会太高。有计算，三层就可以存储大约2000w数据。也就是说，读取任何一条数据，只需要三次磁盘I/O即可。
- 非叶结点，只存储指向下一层的指针，一个数据页好像是16k，也就是说存储16k的指针，肯定可以存很多。
- 而跳表，b树和红黑树，二叉平衡树他们的高度在存储相同数量的数据时，高度太高，需要太多次磁盘读取，影响性能。虽然可能1次I/O就读取到相应的数据。（**跳表实现更加简单，用于Redis（基于内存）的zset，B+树对I/O友好（多叉树使得高度变小，I/O次数减少），用书数据库的索引**）
- 对于有 N 个叶子节点的 B+Tree，其搜索复杂度为O(logdN)，其中 d 表示节点允许的最大子节点个数为 d 个

B+树和B树的区别：

- 在B+树中，数据都存储在叶子节点上，而非叶子节点只存储索引信息；而B树的非叶子节点既存储索引信息也存储部分数据。
- B+树的叶子节点使用链表相连，便于范围查询和顺序访问；B树的叶子节点没有链表连接
- B+树的查找性能更稳定，每次查找都需要查找到叶子节点；而B树的查找可能会在非叶子节点找到数据，性能相对不稳定。

### 怎么搜索到一条数据的

- 首先走索引，找到对应的记录所在的数据页。因为索引是建立在数据页上的。
- 然后，将数据页加载到内存当中。
- 在内存页中执行类似于二分查找的方式，根据偏移量找到对应数据。

### 为什么叶子节点要用双向链表链表？

- 方便范围查询。

### 联合索引？abc问题？

- 首先有一点我们要明确，联合索引是a全局有序，a相等b有序，b相等c有序。b和c从全局看是无序的。
- 其次，如果是覆盖索引，也就是说abc三个联合索引，如果说只查询bc，那么优化器可能会选择扫描全部的索引树，选择符合条件的，因为覆盖索引不需要回表。

- 这里的abc问题，首先遵循最左匹配原则。出现a一定会走索引。

- 联合索引，其实索引树上，非叶结点只有字段a，每次需要根据a找到叶子结点，然后才能看到字段b和c。

### 最左匹配，like、between，能否使用索引？

- 这里的问题和上边一样。考虑是否是覆盖索引
- 且遵循最左匹配原则。

### 索引失效的几种场景？

- 做/右模糊查询会使得索引失效

- ```sql
  WHERE name LIKE '%abc' --无效
  WHERE name LIKE 'abc%'          -- 可利用索引前缀
  ```

- 在查询条件中对索引列上加函数（包括隐式转化：字符串转为数字使用了CAST函数）

- 在查询条件中对索引列使用了表达式计算，比如使用了 != 号

- 如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列(`OR` 条件连接多个索引列，但其中部分列无索引。)

- 隐式得类型以及编码转换

- 联合索引没有遵循最左匹配原则

### 哪些字段适合建立索引？性别为什么不适合？

- 区分度比较高得
- 不合适。因为只有两种选择。

### 什么时候不需要建立索引

- where、Group by、Order by里用不到的字段（索引作用就是快速定位）
- 字段存在大量的重复字段（区分度不大），如性别
- 表数据太少
- 经常更新的字段不同创建索引，使得索引也会频繁修改

### 什么是索引下推？

- 所谓的下推是将server的职责交给**存储引擎层**，在索引遍历过程中直接过滤不满足条件的记录
- 早期版本的MySQL，假设我们有两个条件，a和b，a上有索引，那么走a索引找到对应数据之后，要取数据行，返回给server层，去判断b是否符合条件。
- 有了索引下推后，如果此时索引是a和b的联合索引，那么会在引擎层连同b一起判断了，不需要返回给server层。

### 索引上的NULL值问题

- 一般的设计当中，我们都会要求索引列为非空。即索引列不允许出现NULL值。
- 比如进行索引统计时，count 会省略值为NULL 的行。
- is null 是会走索引的。但是is not null 并不会走索引。这一点有点类似于 = 可以走索引，但是 ！= 不能走索引。联合索引(a, b)，若其中的a为null，则索引失效
- null 值是一个特殊的值，它不同于任何值，也就是说两个列的值都是null，但是他们进行比较的结果仍然为false。
- 判断null值需要用is null。
- **当出现联合索引时，如果联合索引中有值为NULL，那么就会导致该联合索引哪怕是唯一索引，也会出现重复的情况**。

### MySQL什么情况下会走错索引？

MySQL 中优化器的目的就是找到一个**最优的执行方案**，从而用最小的代价去执行语句。

优化器在选择索引时，主要会考虑如下的因素：

- 扫描的行数：扫描的行数越少，就证明访问磁盘数据的次数越少，消耗的 CPU 资源就越少。
- 有没有涉及到临时表
- 排序

针对于扫描行数的确定，采用的是采样统计，计算的并不是一个准确的值。**当预估行错误时，就有可能导致选择错误的索引。**

另一方面，假设两个索引a和b

```mysql
select * from Y where a between 1 and 1000 and b between 5000 and 100000 order by b limit 1;
```

其中如果走索引a，那么只需要扫描1000行，而b则需要5000-100000，按理说应该选择a，但是优化器会选择b。因为有排序，而索引b是有序的。

### 索引优化

- 前缀索引优化：对大字段进行前缀索引
- 覆盖索引：查询的字段在B+树的叶子节点能够直接找到（联合索引）
- 主键索引是自增的：B+树是有序的，主键自增插入效率更高
- 防止索引失效：非（模糊匹配，使用函数，表达式计算，or）

### 一条update是不是原子性的？

- 执行update的时候，会加行级别锁，保证了一个事务更新一条记录的时候，不会被其他事务干扰。
- 事务执行过程中，会生成undolog，如果事务执行失败，就可以通过undolog日志进行回滚。

### where字段、order字段个查询字段的联合索引顺序

- **等值 WHERE 字段 > 范围 WHERE 字段 > ORDER BY 排序字段 > SELECT 查询字段**

## 锁

### 行锁，间隙锁，临键锁分别是干什么的？

- 行锁锁一行数据。其他数据不能对其进行**修改**。
- 间隙锁锁数据的区间，防止其他事物进行**插入**，不包含修改。比如id(1,100)
- 临键锁不仅锁区间，连同扫描到的记录一起锁，防止其他事物更改。

### **插入意向锁**

- 当多个事务在同一区间（gap）插入位置不同的多条数据时，事务之间不需要互相等待
- MySQL在插入数据时，会先在对应位置加插入意向锁。
- 如果是唯一键出现冲突，则会加Next-key-lock

### 自增锁

- 自增主键在生成时，为了避免冲突，会加自增锁。

### MDL锁（元数据锁）

- 这里主要是发生表更改时，加的锁。它与读写锁这种是冲突的。
- 即如果有事物要更改表结构，那么此时是不能进行查询和修改的。
- 如果有事物正在执行查询或者修改，则无法进行表结构的调整。

### 什么情况下会加行锁？什么情况下加表锁？

- 一般情况下，执行update时，如果有索引则会加行锁。
- 如果不存在索引，那么就会加表锁。

### 记录锁

- 假设我们执行select for update 时就会锁住对应的记录。此时where条件必须为=，且必须是唯一索引或者主键，否则会退化为临键锁。
- 在执行select for update的时候，在可重复读的隔离界别，会加



### 一个SQL ，怎么分析加了哪些锁？

- 查找过程中访问到的对象才会加锁
- 加锁的基本单位是 Next-key Lock （临键锁）
- 唯一索引等值查询：（1）查询的记录存在：临键锁会退化成 Record Lock 记录锁。（2）查询的记录不存在：Next-key Lock 会 退化成间隙锁(比如查找id=22,间隙锁范围是(20,25)，20，25都存在)
- 唯一索引范围查询：比如 where id >= 20 and id < 22，对于存在的记录退化为记录锁，然后往后找到第一个存在的记录，退化为间隙锁,如果
- 非唯一索引等值查询：（1）查询的记录存在（id=16）：会加两种锁：临建锁（8，16]，间隙锁（16，32）。（2）查询的记录不存在：只有间隙锁（16，32）
- 非唯一索引范围查询：比如 where id >= 20 and id < 22，对于存在的记录不会退化为记录锁，会有临建锁(16,20],然后往后找到第一个存在的记录，也不会退化，有临建锁(16,32],，最后有临建锁(16,32)

### 对加锁的总结：

- 为什么唯一索引和非唯一索引的加锁机制不一样：**唯一索引的值不会重复，而非唯一索引的值可以重复**
- 等值查询：
  - 唯一索引：如果记录存在，由于唯一性，不会在记录两边有相同的记录插入，只需记录锁。如果记录不存在，那么在查询的同时最近的两边的范围内可能插入新数据(插入等值数据)，因此需要一个间隙锁。
  - 非唯一索引：如果记录存在，又有不唯一性，在保证记录锁的同时，要加间隙锁，保证记录两边没有相同的数据插入；如果记录不存在，只需间隙锁
- 范围查询：
  - 唯一索引：在范围内有数据，首先保证记录锁，如果范围查询的左/右边界的数据存在，那么间隙锁的范围就是查询的范围，因为唯一性，范围两边不怕有新数据插入；如果范围没有数据，就加间隙锁
  - 非唯一索引：在范围内有数据，对记录加记录锁，然后在加间隙锁；如果没有数据，不加记录锁只加间隙锁。
- 记录锁：保证记录不**被修改**；间隙锁：保证间隙内不会**被插入新纪录**

### select...for update在有索引和没索引的区别

- 有索引时会加临键锁：根据是否唯一索引和等值/范围查询来退化行锁或间隙锁
- 没有索引会加表锁

## 事务

> 事务提交不可回滚
>
> **事务**是指一组操作，它们被作为一个单一的逻辑单元来执行。在这个逻辑单元中，要么所有操作都成功完成并被提交到数据库中，要么所有操作都失败并被回滚，从而使数据库返回到执行事务之前的状态。
>
> MySQL采用先写日志，其实并不是为了追求性能，而是为了保证事务的持久性和一致性。

### mysql事务的四大特性是什么，怎么实现的？

- 隔离性 通过隔离级别+undo log，指的是不同事务在提交的时候，最终呈现出来的效果是串行的，隔离性是指当多个用户并发访问数据库时，比如操作同一张表时，数据库为每个用户开启的事务，不能被其他事务的操作干扰，多个并发事务要互相隔离。
- 一致性 其他三个特性一起保证的
- 原子性 undo log
- 持久性 redo log，持久性保证了一旦事务生效，就不会再因为任何原因而导致其修改的内容被撤销或丢失。

### 事务的隔离级别有哪些？分别存在什么问题？

- 读未提交，一个事务所做的修改，还没提交就可以被其他事务看到。脏读，幻读，不可重复读。
- 读提交，一个事务所做的修改，只有在提交了之后才可以被其他事务看到。问题：不可重复读，幻读。
  - 不可重复读的意思是说，两次读取，读取相同的数据，但是值不一样了，意在相同的数据。
  - 而幻读是指范围查询，两次查询后一次查到了第一次不存在的数据，主要是针对有新数据插入。
- 可重复读，一个事务开启之后，它的每一次读取数据应该都是一样的，存在幻读问题。解决办法：间隙锁或者next-key-lock
- 串行化：会对记录加上**读写锁**，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。性能太低。一个事务执行期间其他所有事务无法执行。
-  
- 脏读：一个事务读到了另一个事务未提交的数据
- 幻读：多次读符合条件的**记录数量**，前后两次查询读到的**记录数量不一样**
- 不可重复读：多次多同一个数据，两次读到的**数据不一样**

### RR 和RC哪个快？为什么？

- 不好说，具体场景具体分析。
- 两个都需要依赖一致性快照，一个是在事务开启时创建快照，一个是在语句执行前创建快照。
- 可重复读配合间隙锁和临键锁，重读的读取可以直接走缓存。 

### RR是靠什么来实现的？

- 同下

### RC（读提交）和可重复读是怎么实现的？

- MVCC，读题交是在每条**语句执行前生成一个Read View**,这样两次的SELECT使用的是不同的Read View,这样可能出现不可重复问题
- 而可重复读是在**开启事务时生成一个Read View**，且整个事务一直使用同一个Read View。
- 这里，每个事务开启时会有一个事务的版本号，这个版本号是全局递增的。
- 事务开启时，同时需要记录当前还处于活跃的事务，也就是说开启了但是未提交的事务。
- 最终数据是否可见，是取决于当前数据事务版本是否处于活跃事务号中，或者说是否处于可见范围之内。
- 如果当前数据事务版本号低于当前事务id，且不处于活跃事务集合中，那么就可见，否则不可见。

### 怎么开启一个事务？

- start transction，这个语句并不会立即开启一个事务，等到执行第一个语句时才开启。
- 加了with snatshop会立即开启。

### 怎么调整事务的隔离级别？

- SET GLOBAL transaction_isolation = 'READ-COMMITTED';

### **怎么理解数据库事务的一致性和分布式事务的一致性？还有数据一致性？**

- 这里要分清楚几个概念，数据库事务的一致性，更多的是指状态上的一致性，数据库的整体状态需要从一个一致性状态转变为另一个一致性状态，不能停留在中间的状态。多指正确性。
- 而分布式事务的一致性，和单体数据库的一致性一样，它讲究的是多个个体间状态的一致性。由于跨多个部分，所以一般都会采用两阶段提交或者三阶段提交。
- 数据一致性更多的是指统一数据，多个副本间的一致性。

### 什么是分布式事务？

- 分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。
- 例如在大型电商系统中，下单接口通常会扣减库存、减去优惠、生成订单 id, 而订单服务与库存、优惠、订单 id 都是不同的服务，下单接口的成功与否，不仅取决于本地的 db 操作，而且依赖第三方系统的结果，这时候分布式事务就保证这些操作要么全部成功，要么全部失败。
- 更多的是指不同数据库间事务的一致性。

### 幻读了解吗？怎么避免？

- 在一个事务中，针对于范围查询，两次查询到的数据不一致，主要是针对于第二次比第一次多。
- 使用间隙锁或者临键锁。
- 在执行过一次查询后，就锁住查询数据范围内的间隙，不让其他数据插入。
- 另外，临键锁不仅会锁间隙，还会锁行，禁止其他事务更新。

### 幻读会导致什么问题？

- **主从数据不一致**，这里涉及到binlog 的写入顺序问题。
- 另外就是语义方面的问题，假设执行了select for update，我意思要锁住所有满足条件的行，但是新插入的行却没有被锁住。
- 其实我们换一个角度去想，**binlog要求每次写入一个完整的事务**，也就是说**先提交的事务会先被写入**。
- 也就是说，先开启的事务并不一定会先写入binlog，如果出现幻读，那么就有可能导致第一个事务，在第二个或者第三个事务**开始前**的操作，影响到之前本不该修改的行。（**因为该修改操作先于后两个事务，所以修改的范围并不会受后两个事务修改的影响，但是写入binlog的顺序却晚于后两个事务，那么在从库执行时，就会影响到后两个事务修改的行。**所以，正确的做法是要禁止后两个事务提交被第一个事务锁住的行，也就是避免幻读。）

### 有了间隙锁一定能避免幻读吗？（这里注意分析，幻读语义）

- 看怎么理解幻读。如果说幻读仅仅是指新插入数据，那么间隙锁应该就够了。因为没法在范围内插入。
- 但是，间隙锁不锁数据行，这些数据行可能会被其他事务修改。
- 但是严格意义上来说，修改导致的数据不一致，是不能算作幻读的。
  - 这里，根本改不了。该数据需要先删除原来的数据，在插入新的数据，如果是非索引，则会直接锁表。
- 还有一种情况，就是说之前有一个数据不满足条件，另一个事务将其修改到满足条件，这种也不能算作幻读。

### 什么是脏读

- 读到其他事务未提交的结果。

### 读提交会有哪些问题？

- 读提交，一个事物所做的修改在提交后才可以被其他事物看到。
- 主要存在的问题就是不可重复读，以及幻读。

### 双1配置是什么意思？为什么要这样配置？

- 双1配置就是说每次事务提交时，都会将redo log 以及binlog 进行落盘。
- 之所以这么设计，一般都是用于对于数据一致性，或者说不允许丢失任何数据的情况下才会这么设计。
- 其他的配置都存在都是数据的可能。
- 比如说配置为0或者配置为2，或者N，在没真正落盘时，都可能会丢。

### 事务的持久性是靠什么保证的？（redo log）

- 主要是靠redo log 来保证的。因为数据库的写入或者修改，它只会把对应的数据写入缓存当中，然后写日志就返回。
- 这个行为也叫write ahead log。

### MVCC实现原理

- 生成规则：
  - 读题交：事务中每次对数据进行 SELECT ，都会生成一 个 ReadView
  - 可重复读：在一个事务中对一行数据第一次进行 SELECT  查询，会生成一个 ReadView，之后事务都将使用该 ReadView 进行数据的读取。

- Read View四个重要字段

- ![image-20250307152714095](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250307152714095.png)

- max_trx_id :这个并不是m_ids 的最大值，而是创建 Read View时当前数据库中应该给下一个事务的id值，也就是全局事务中最大的事务id值＋1;

- ![image-20250307152842139](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250307152842139.png)

- trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务id记录在trx_id 隐藏列里;

- roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到undo日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。

- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250506194006295.png" alt="image-20250506194006295" style="zoom: 33%;" />

- 一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况:
  ①如果记录的trx_id值**小于**Read View中的min_trx_id值，表示这个版本的记录是在创建Read View前**已经提交的事务生成的**，所以该版本的记录对当前**事务可见**。
  如果记录的trx_id值大于等于Read View中的max_trx_id值，表示这个版本的记录是在**创建ReadView后才启动的事务**生成的，所以该版本的记录对当前**事务不可见**。
  ·如果记录的trx_id值在Read View的min_trx_id和max_trx_id之间，需要判断trx_id是否在m_ids列表中:
  如果记录的trx_id**在m_ids列表中**，表示生成该版本记录的活跃事务依然活跃着（还没提交事务)，所以该版本的记录对当前**事务不可见**。
  如果记录的trx_id 不在m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。（如果是可重复读可能还是不可见）

- **对于不可见记录，当前事务可以通过回滚指针去寻找可见版本**
  
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250506202135107.png" alt="image-20250506202135107" style="zoom: 33%;" />
  
  

## 语句

### MySQL的Join是怎么执行的

- 这里需要看连接的字段是否有索引。
- 如果有索引，那么主表每读取一行，就会根据索引快速的匹配从表中满足条件的行。
- 如果没有索引，那么就需要将主表的数据全部加载到内存当中，然后扫描从表将所有的数据全部与主表进行匹配，相当于一个N^2的操作。

### Join的分类：

- 内连接：只返回两个表中**匹配的记录**，丢弃不匹配的记录
- 外连接：
  - 左连接：保留左表的所有记录，若右表没有使用null代替
  - 右连接：保留右表的所有记录，若左表没有使用null代替
  - 全连接：保留左右表的所有记录

### order by 的排序原理？在哪里排序？怎么优化？order by 语句是怎么执行的（详细见MySQL -> 执行流程 -> order by执行顺序）？

- Order by如果可以走索引，那么就可以不用排序。
- 另外，他有两种排序方式，取决于要排序的数据能否放入给定的排序缓存当中。
  - 全字段排序，即读取多少列的数据，全部拿来排序，排完序就可以直接返回。
  - 另一种排序方式就是只去需要排序的字段，排完后需要回表查询全部的数据。

- 如果上述两种方式都不够，那么排序就需要借助于外存来进行。

### **JDBC 中preparedStatement和Statement区别**

- prepareStatement可以防止sql注入，因为他对于单引号做了转译。
- prepareStatement似乎包含了预编译，执行效率要高。它是在Statement上进行了封装
- 而Statement更适合用于不带任何参数的，也就是固定的查新，不需要动态sql。

### select、from、where、group by、having、order by、limit执行顺序

- 首先是执行from，确定哪张表
- 然后执行where，判定对应条件。
- ~~然后执行select，选择对应列~~
- 然后执行group by
- 然后执行having
- 在这里才执行select，选择对应的列
- 然后执行order by
- 然后执行limit。

### group流程

- 查询全数据
- 进行分组，非为两种策略:1.排序分组  2.哈希分组
  - 排序分组：如果分组条件有索引，则利用索引进行排序然后分组
  - 哈希分组，如果分组条件没有索引，则进行哈希分组，流程为：
    - <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250705173646935.png" alt="image-20250705173646935" style="zoom: 33%;" />
    - 注意：如果内存占用大于了设置的值，那么就**会转磁盘**，可能会照成性能瓶颈
- 进行聚合函数

### MySQL的执行流程

- 首先会验证语法的正确性
- 首先，一条sql语句，会经过优化器的优化，选择合适的索引
- 如果是查询语句，那么就会先走索引，查找对应的数据页，并去看数据页是否在内存中，如果不在就读入内存。返回结果。
- 如果是修改语句，那么仍然要先去读取数据，然后把所做的修改在缓存中进行，然后写日志，然后返回。
- 这里还会根据索引的是否唯一性，选择是否启用change buffer，如果不是唯一索引，那么可以不读取数据页，直接在change buffer中记录要做的修改，等到下次真正读取数据的时候，再做合并。

### 一条查询语句的执行流程

1. 建立连接
2. 查询缓存
3. 查询分析：生成解析树
4. 查询优化：从解析树找到最优解，根据索引等生成执行计划
5. 查询执行：通过执行计划去调存储计划API
6. 执行查询
7. 返回结果

### 一条新增语句的执行流程

1. 建立连接
2. 写入缓存
3. 写日志(两阶段提交redolog和binlog)

### jdbc如何操作数据库的？

- 我能记得的
- 首先是Class.forName，来加载驱动。jdbc后边的版本，利用了spi去动态加载类，不需要写这个class.forName了。
- 创建一个DriverManager，然后建立连接
- 然后创建Prepare Statement
- 然后写sql，然后执行
- 然后拿结果。

## 缓存

这俩问题上边都写过，这里不在重复

- change buffer 有什么作用(https://blog.csdn.net/2301_79914109/article/details/148074690)
- Change Buffer是MySQL InnoDB存储引擎中的一个机制，用于暂存对**二级索引(非唯一索引)**的插入和更新操作的变更，而不立即执行这些操作，随后，当InnoDB进行合适的条件时(如页被读取或Flush操作)，会将这些变更写入到二级索引中。(对于普通索引，当数据页在内存中时，直接进行更新操作即可；当数据页不在内存中时，直接将更 新操作写入 change buffer 即可,当下次查询需要访问这个数据页时，再将数据页读入内存，然后执行 change  buffer 中 与这个页有关的操作，最后将查询结果返回)，redolog会记录数据页的变化和change buffer的变化
- 对于唯一索引（Unique Index），由于需要校验唯一性，必须先读取数据页确认是否已存在重复值，因此无法使用 Change Buffer
- buffer poll 是什么？有什么作用？

## 分库分表

### MySQL的分区表有了解吗？

- 分区表就是在引擎层进行分表，比如说我们有几个分区表，对应的就会有几个rdb文件。但是这些分区表始终只有一个ifm，即专门定义表结构的文件。
- 分区表的查询，只有查询携带了分区健才可以进行。否则还是要扫描所有的表。
- 由于MySQL的锁的设计，锁的是索引，如果存在多个rdb文件，也就会有多个索引树，就可以实现更高的并发，其实也就是物理上的多张表。

### ifm和rdb文件分别存的是什么？

- ifm就是一张表的信息，包含了表名，字段，结构等。
- rdb是引擎层的内容，包含了索引，数据等。

### 水平分库分表是什么样的？

- 水平分表，指的是将一个数据量很大的表，比如说8000w的表，拆分成多张数据量小一点的表。比如说4张2000w的表。
- 水平分库指的是在垂直分库之后，如果某一张表的数据或者访问量仍然很多，那么就要将这一张表单独的拆分到多个库中，每个库存储一部分数据，表结构不变。

### 垂直分库分表是什么样的？

- 垂直分表一般是按照列分表。即将原来的一个宽表分成多个表。比如说原表有9个列，我们每3个列拆成一张新表，但是每张表的数据量原先是多少行，新表仍然是多少行。
- 垂直分库指的是按照业务，将一个数据库中的多张表，分散到多个数据库当中，每个数据库服务一部分业务。
  - 比如说原先一个数据库，里边有30张表，可以按大类分为3个业务，那么垂直分库就是说将这30张表分到3个数据库当中，每个数据库存储10张表，服务于一个业务。

## 集群，主从

### MySQL主从怎么同步数据的？

- MySQL主库将自己的binlog 发送给从库。
- 从库接收到之后，将其加载为中转日志（rely log）
- 然后开始执行日志中的内容。
- 上述过程大致是正确的，不过少了一些东西
- 比如说主库和从库会专门建立一个长链接，用于发送binlog文件，以及后续的binlog内容。
- 从库会创建两个线程，一个用于与主库执行I/O操作，一个用于从中转日志中读取命令并执行。

### 主从同步的方案有哪些？

其实主要分为两种，**异步复制**和**半同步复制**

- 异步复制指的是，每当主库提交完事物之后，就立即给客户那边反馈已经执行成功，并不会等待该binlog同步到从库。这个时候就会出现从库丢失数据的风险。
- 半同步复制指的是，主库提交完事物后，会等待某一个从库接收到binlog之后，才会返回执行成功。这样会减少数据不一致以及数据丢失的风险。

### 主从延迟怎么解决？

- 一般来说，有几种方案
- 等待主库位点
- 强制走主库，这个是用的最多的。
- 还有，可以记录主库和从库之间的差，超过一定值后，主库拒绝请求，直到同步的差不多再继续。

### 主从怎么保证数据一致性？

- 这里提供一种思路，即强一致性。

- 可以修改返回时机，默认的情况下，主库这边日志写完之后，就给用户返回成功了。我们可以改为只有当日志同步到从库之后，再给用户返回成功。

- ```java
  import java.util.Scanner;
  
  // 注意类名必须为 Main, 不要有任何 package xxx 信息
  public class Main {
      public static int sum(int a, int b){
          return a + b;
      }
      public static void main(String[] args) {
          Scanner in = new Scanner(System.in);
          int T = in.nextInt();
          for(int v = 0; v < T; v++){
              int C = in.nextInt();
              int[] ops = new int[C];
              for(int i = 0; i < C; i++){
                  ops[i] = in.nextInt();
              }
              int M = in.nextInt();
              int N = in.nextInt();
              int[][] nums = new int[M][N];
              for(int i = 0; i < M; i++){
                  for(int j = 0; j < N; j++){
                      nums[i][j] = in.nextInt();
                  }
              }
  
              for(int op : ops){
                  move(nums, op);
              }
  
              for(int i = 0; i < M; i++){
                  for(int j = 0; j < N; j++){
                      System.out.print(nums[i][j]);
                      if(j < N - 1){
                          System.out.print(" ");
                      }
                  }
                  System.out.println();
              }
          }
      }
  
      public static void move(int[][] nums, int op){
          switch (op){
              case 0: moveUp(nums); break;
              case 1: moveLeft(nums); break;
              case 2: moveDown(nums); break;
              case 3: moveRight(nums); break;
          }
      }
  
      public static void moveUp(int[][] nums){
          int n = nums.length;
          int m = nums[0].length;
          int[] newNums = new int[n];
          for(int i = 0; i < m; i++){
              for(int j = 0; j < n; j++){
                  newNums[j] = nums[j][i];
              }
              moveOne(newNums);
              for(int j = 0; j < n; j++){
                  nums[j][i] = newNums[j];
              }
          }
      }
  
      public static void moveDown(int[][] nums){
          int n = nums.length;
          int m = nums[0].length;
          int[] newNums = new int[n];
          for(int i = 0; i < m; i++){
              for(int j = n - 1; j >= 0; j--){
                  newNums[n - 1 - j] = nums[j][i];
              }
              moveOne(newNums);
              for(int j = n - 1; j >= 0; j--){
                  nums[j][i] = newNums[n - 1 - j];
              }
          }
      }
  
      public static void moveLeft(int[][] nums){
          int n = nums.length;
          int m = nums[0].length;
          int[] newNums = new int[m];
          for(int i = 0; i < n; i++){
              for(int j = 0; j < m; j++){
                  newNums[j] = nums[i][j];
              }
              moveOne(newNums);
              for(int j = 0; j < m; j++){
                  nums[i][j] = newNums[j];
              }
          }
          
      }
      public static void moveRight(int[][] nums){
          int n = nums.length;
          int m = nums[0].length;
          int[] newNums = new int[m];
          for(int i = 0; i < n; i++){
              for(int j = m - 1; j >= 0; j--){
                  newNums[m - 1 - j] = nums[i][j];
              }
              moveOne(newNums);
              for(int j = m - 1; j >= 0; j--){
                  nums[i][j] = newNums[m - 1 - j];
              }
          }
          
      }
  
      public static void moveOne(int[] nums){
          int n = nums.length;
          int[] newNums = new int[n];
          int i = 0;
          for(int num : nums){
              if(num != 0){
                  if(i > 0 && num == newNums[i - 1]){
                      newNums[i - 1] = newNums[i - 1] * 2;
                  }else{
                      newNums[i] = num;
                      ++i;
                  }
              }
          }
      }
  
      public static void moveOne2(int[] nums) {
      // 第一次压缩
      int[] temp = new int[nums.length];
      int index = 0;
      for (int num : nums) {
          if (num != 0) temp[index++] = num;
      }
      
      // 合并相邻相同元素
      for (int i = 0; i < index - 1; i++) {
          if (temp[i] == temp[i + 1]) {
              temp[i] *= 2;
              temp[i + 1] = 0;
              i++; // 跳过已合并元素
          }
      }
      
      // 第二次压缩
      index = 0;
      Arrays.fill(nums, 0);
      for (int num : temp) {
          if (num != 0) nums[index++] = num;
      }
  }
  
      
  }
  
  
  public class StockTradingSimulation {
      public static void main(String[] args) {
          Scanner scanner = new Scanner(System.in);
          int N = scanner.nextInt();
          int M = scanner.nextInt();
          double K = scanner.nextDouble();
  
          double[][] prices = new double[N][M];
          for (int i = 0; i < N; i++) {
              for (int j = 0; j < M; j++) {
                  prices[i][j] = scanner.nextDouble();
              }
          }
  
          // dp[i][j] 表示第 i 天持有第 j 支股票的最大现金
          double[][] dp = new double[N][M + 1];
          // 初始时持有现金
          for (int j = 0; j < M; j++) {
              dp[0][j] = 0;
          }
          dp[0][M] = K;
  
          // 记录买卖情况
          int[][] transactions = new int[N][2];
          for (int i = 0; i < N; i++) {
              transactions[i][0] = -1;
              transactions[i][1] = -1;
          }
  
          for (int i = 1; i < N; i++) {
              // 第 i 天持有现金的情况
              dp[i][M] = dp[i - 1][M];
              for (int j = 0; j < M; j++) {
                  if (dp[i - 1][j] * prices[i - 1][j] / prices[i - 1][j] > dp[i][M]) {
                      dp[i][M] = dp[i - 1][j] * prices[i - 1][j] / prices[i - 1][j];
                      transactions[i][0] = j;
                      transactions[i][1] = -1;
                  }
              }
  
              // 第 i 天持有股票的情况
              for (int j = 0; j < M; j++) {
                  // 不交易
                  dp[i][j] = dp[i - 1][j];
                  // 从现金买入
                  if (dp[i - 1][M] / prices[i][j] > dp[i][j]) {
                      dp[i][j] = dp[i - 1][M] / prices[i][j];
                      transactions[i][0] = -1;
                      transactions[i][1] = j;
                  }
                  // 从其他股票换入
                  for (int k = 0; k < M; k++) {
                      if (k != j && dp[i - 1][k] * prices[i - 1][k] / prices[i][j] > dp[i][j]) {
                          dp[i][j] = dp[i - 1][k] * prices[i - 1][k] / prices[i][j];
                          transactions[i][0] = k;
                          transactions[i][1] = j;
                      }
                  }
              }
          }
  
          // 最后一天必须持有现金
          double maxCash = dp[N - 1][M];
          for (int j = 0; j < M; j++) {
              if (dp[N - 1][j] * prices[N - 1][j] > maxCash) {
                  maxCash = dp[N - 1][j] * prices[N - 1][j];
                  transactions[N - 1][0] = j;
                  transactions[N - 1][1] = -1;
              }
          }
  
          System.out.printf("%.4f\n", maxCash);
          for (int i = 0; i < N; i++) {
              System.out.println(transactions[i][0] + " " + transactions[i][1]);
          }
  
          scanner.close();
      }
  }    
  
  
  
  import java.util.Scanner;
  
  public class Main {
      public static void main(String[] args) {
          Scanner scanner = new Scanner(System.in);
          int N = scanner.nextInt(); // 天数
          int M = scanner.nextInt(); // 股票支数
          double K = scanner.nextDouble(); // 启动资金
  
          double[][] prices = new double[N][M];
          for (int i = 0; i < N; i++) {
              for (int j = 0; j < M; j++) {
                  prices[i][j] = scanner.nextDouble();
              }
          }
  
          double[] cash = new double[N + 1];
          cash[0] = K;
          int[][] operations = new int[N][2]; // 记录每天的操作，[卖出股票, 买入股票]，-1表示无操作
  
          for (int day = 0; day < N; day++) {
              double maxProfit = 0;
              int bestBuyStock = -1;
              int bestSellStock = -1;
  
              // 检查每支股票是否能带来收益
              for (int stock = 0; stock < M; stock++) {
                  double currentPrice = prices[day][stock];
                  double maxFuturePrice = currentPrice;
                  int maxFutureDay = day;
  
                  // 找到未来最高价
                  for (int futureDay = day + 1; futureDay < N; futureDay++) {
                      if (prices[futureDay][stock] > maxFuturePrice) {
                          maxFuturePrice = prices[futureDay][stock];
                          maxFutureDay = futureDay;
                      }
                  }
  
                  double profit = maxFuturePrice - currentPrice;
                  if (profit > maxProfit) {
                      maxProfit = profit;
                      bestBuyStock = stock + 1; // 股票编号从1开始
                      bestSellStock = stock + 1;
                  }
              }
  
              if (maxProfit > 0) {
                  // 买入该股票
                  cash[day + 1] = cash[day] - prices[maxFutureDay][bestBuyStock - 1];
                  operations[day][0] = -1; // 当天没有卖出操作
                  operations[day][1] = bestBuyStock;
              } else {
                  // 持有现金
                  cash[day + 1] = cash[day];
                  operations[maxFutureDay][0] = bestBuyStock;
                  operations[day][1] = -1;
              }
          }
  
          // 输出最终现金，保留4位小数
          System.out.printf("%.4f\n", cash[N]);
  
          // 输出每天的操作
          for (int i = 0; i < N; i++) {
              int sell = operations[i][0];
              int buy = operations[i][1];
              System.out.println(sell + " " + buy);
          }
      }
  }
  ```

  

## 数据库调优

**分析查询语句**：使用EXPLAIN命令分析SQL执行计划，找出慢查询的原因，比如是否使用了全表扫描，是否存在索引未被利用的情况等，并根据相应情况对索引进行适当修改

**创建或优化索引**：根据查询条件创建合适的索引，特别是经常用于WHERE子句的字段、Orderby 排序的字段、Join 连表查询的字典、 group by的字段，，并且如果查询中经常涉及多个字段，考虑创建联合索引，使用联合索引要符合最左匹配原则，不然会索引失效

**查询优化**：避免使用SELECT *，只查询真正需要的列；使用覆盖索引，即索引包含所有查询的字段

**优化数据库表**：如果单表的数据超过了千万级别，考虑是否需要将大表拆分为小表，

**使用缓存技术**：引入缓存层，如Redis，存储热点数据和频繁查询的结果

优化Order by:（1）参数优化： 调整 sort_buffer_size 参数的值；调整 max_length_for_sort_data 的值，值太小的话 MySQL 会采用 rowid 排序‘（2）联合索引：索引本身会保持有序，select name,age,city from user where city = '北京' order by age limit 5，联合索引(city, age),这样在city='北京'的情况下，age有序，这里还可以覆盖索引(city,age,name)

rowid 排序：只将待排序字段和主键id放入到sort buffer中

### 优化分页Limit:

- 对于主键索引，limit会很快
- SELECT * FROM 表名称 WHERE id_pk > (pageNum*10) LIMIT M:需要主键连续且没有缺失，否则可能漏掉数据
- 利用复合索引进行优化:如果对于有where 条件，又想走索引用limit的， 必须设计一个索引，将where 放第一位，limit用到的主键放第2位，而且只能select 主键！

# Redis

### Redis的结构都有哪些？底层都是怎么实现的？

![image-20250917161206224](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250917161206224.png)

- string类型，底层是SDS，简单动态字符串。如果字符串不是很长，且全是数字类型，~~会采用一个Integer类型吧。~~采用long类型就可以。
  - 简单动态字符串中，有一个字节数组，用于存储真实的元素
  - 还有一个用于指示字节数组用了多少了
  - 还有一个表示申请的字节数组的长度。
- List，底层采用quicklist。quicklist时采用压缩列表和双端链表来实现的。每一个压缩列表写满之后，会新建一个压缩列表。
- Set，底层通过~~压缩列表~~ intset 或者hashtable
- hash类型，底层通过压缩列表或者hashtable。当元素较多时就会转化为hashtable。
- zset(有序集合)。底层通过hash表+跳表的形式。跳表负责有序且查找元素的时间复杂度为o（logn），而哈希表方便我们快速获得某个元素。
  - 哈希表的作用，其实就是为了方便我们单独查询某一元素，可以做到o1的时间复杂度。
  - 而跳表则是为了我们遍历zset时，达到有序性。
- 这里其实还有一个ziplist，即压缩列表。他是前边一个元素会表明后边一个元素的大小。如果是hash类型，就是前边一个key，后边一个value。每一个节点会包含该节点的大小。

### SDS（simple dynamics tring)

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250917161943792.png" alt="image-20250917161943792" style="zoom:50%;" />![image-20250917162020081](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250917162020081.png)

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250917162056175.png" alt="image-20250917162056175" style="zoom:50%;" />



### redis 的zset存储什么内容？底层怎么实现的？

- zset存储时需要我们自己指定score。score可以重复，且有序。
- 底层通过跳表 加哈希表的形式来实现的

### redis如何做排行榜

- 使用zset为基础做排行榜
- 跳表里面有一个score字段，可以设置为排行榜分数
- key:主题 、score、value:user
- 例如 ： 点赞   100   user1

### redis做延时队列

适用sortedset，拿时间戳作为score，消息内容作为key调用 zadd来生产消息， 消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理

### redis做消息队列

使用list

### 跳表的工作原理？

- 类似于二分查找。通过多级索引，在logn的时间复杂度，定位到具体数据。跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的zskiplistLevel结构体类型的level数组。
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250324165721405.png" alt="image-20250324165721405" style="zoom: 80%;" />
- ![image-20250303161045881](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250303161045881.png)

![image-20250917162330185](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250917162330185.png)

### 跳表是如何设置层高的

跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。

### 为什么采用跳表？而不是B+树这些？

- 跳表的实现是最简单的。
- 跳表基于链表，配合多级索引加快查询，插入删除只需调整局部指针，而B+树插入删除需要调整平衡
- 而且redis是基于内存的，不牵扯到磁盘读写，所以说不需要考虑使用B+(I/O友好型)树来减少高度。

### Redis的ziplist

- 压缩列表表头有三个字段，zlbytes、zltail 和 zllen，分别表示列表长度，列表尾的偏移量以及列表中的entry个数。压缩列表尾还有一个 zlend，表示列表结束。
- 每个entry又有以下及部分：

  - **prev_len**，表示前一个 entry 的长度。prev_len 有两种取值情况：1 字节或 5 字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节，取5时表示大于255字节。
  - **len**：表示自身长度，4字节。
  - **encoding**：表示编码方式，1字节。
  - **content**：保存实际数据。
- 压缩列表会把列表中的元素挨个放进列表当中，**相当于使用连续内存**，并且利用entry中记录的元素大小来进行寻址，这样就节省了指针等其他结构的开销。类似于数组
- ![image-20250303162424378](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250303162424378.png)

### redis 的哈希算法

- redis的分片集群采用了CRC16算法。

### redis哈希扩容:

触发rehash后，给哈希2分配空间，将哈希1渐进式（哈希1数据可能太多）地复制到哈希2，再释放哈希1的空间，哈希2变为哈希1。

在这过程中，查找数据会先在哈希1上查找，然后再会到哈希2上查找

![image-20250324191449769](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250324191449769.png)



### redis 为什么这么快？

- 首先就是redis的数据结构，他是一个key，value类型的数据库，提供了多种数据类型，设计比较好，可以快速的获取到对应元素。
- 第二点就是说它是基于内存的，内存的访问速度要比磁盘的访问速度快。
- 第三就是他的I/O模型，采用了多路复用机制，~~使得一个线程可以处理多个命令~~。多路复用机制可以使得一个连接处理多个命令，减少建立连接的数量，提高性能。
- 第四，redis是单线程的，不需要为加锁、以及线程上下文切换这种额外的操作耗时。面对用户请求是单线程模式，但会有后台线程处理关闭文件，刷盘和释放内存等工作



### redis在哪些地方使用多线程

虽然redis在**接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端**这一过程是使用一个单线程(主线程)，在redis却不止一个线程在运行

- 处理关闭文件后台线程
- AOF 刷盘后台线程
- 异步释放 Redis 内存，也就是 lazyfree 线程

### redis的I/O复用

- 一个 socket 客户端与服务端连接时，会生成对应一个套接字描述符(套接字描述符是文件描述符的一种)，每一个 socket 网络连接其实都对应一个文件描述符。
- Redis 使用 I/O 多路复用程序 将客户端 socket 对应的 FD（类似于NIO的channel） 注册到监听列表 (一个队列)中，当客服端执行 read、write 等操作命令时，I/O 多路复用程序会**将命令封装成一个事件**，**并绑定到对应的 FD 上。**
- 文件事件处理器使用 I/O 多路复用模块(类似于NIO的selector)同时监控多个文件描述符（fd）的读写情况,当 accept、read、write 和 close 文件事件产生时，**文件事件处理器就会回调 FD 绑定的事件处理器进行处理相关命令操作。**

### redis实现原子性

- 执行一条命令本身就是原子
- 执行多条命令可以使用lua脚本将多个操作写到一个脚本中
- 亦可以使用事务，如果redis事务正常执行，没有发生任何错误，那么使用MULTI（开启事务）和EXEC（执行提交）配合使用，就可以保证多个操作都完成。

### Redis的事务

- redis有一个命令，MULTI会开启一个事务，执行这个命令后，接下来所有传给redis的操作命令，都不会被立即执行，而是放入一个事物队列当中。
- 当得到EXEC命令后，会开始执行事物队列中的命令。
- 它有一个监听的机制，会监听事物队列中的所有要被操作的key，如果这些key发生了变化，那么在执行EXEC命令时，会直接返回null，即不执行命令。
- 因为redis的命令是单线程执行的，所以一旦EXEC命令执行成功，那么它不可被中断。
- 但是Redis的事物没有提供回滚机制。也就是说如果中间有命令执行失败，并不会阻止其他命令执行，也不会回滚已经执行的命令

### redis的Watch机制是什么？  

Redis Watch 命令用于监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令 所改动，那么事务将被打断。注意使用multi 开始事务，exec 提交事务。 语法， redis Watch 命令基本语法如下： WATCH key [key …]

### 日志：RDB（Redis DataBase）和AOF(Append Only File)持久化

- 这是两种数据持久化的方式。
- RDB是内存快照，它存储的就是某一时刻redis中真实的数据，可以直接加载到内存当中。可以通过bgsave、save命令或者配置自动持久化来执行。
- 而AOF则记录的是Redis中执行过的每一条写命令。它属于后写日志。即先执行命令，再写日志。因为不想要每次都检查命令对不对。

### save和bgsave(RDB刷盘)

- save是同步保存，由于redis是单线程，因此在进行保存时会出现无法提供服务
- bgsave是异步保存，主线程会fork一个子线程去进行异步保存

### AOF的刷盘方式

- 同步刷盘：每执行一条写命令，Redis 都会**立即调用 `fsync`** 将命令写入磁盘
- 半同步刷盘：写命令先写入 OS Cache，Redis 后台线程**每 1 秒调用一次 `fsync`** 将 OS Cache 中的命令刷到磁盘
- 全异步刷盘：Redis 仅将写命令写入 OS Cache，**不主动调用 `fsync`**，刷盘时机完全由操作系统决定（操作系统通常默认 30 秒刷一次）

### Redis数据恢复优先级

- 有AOF优先使用AOF进行恢复
- 如果同时配置了AOP的RDB，启动只加载AOF进行加载AOF进行恢复
- 

### Redission了解嘛？

Redisson中用到了Redis的订阅/发布机制。

![redisson.png](https://img.javaedit.com/images/2022/11/07/60ad5420cc116aadf55965aa3527272f.png)

当线程2获取了锁但还没释放锁时，如果线程1去获取锁，会阻塞等待，直到线程2解锁，通过Redis的**发布订阅机制唤醒线程1**,再次去获取锁。

### **redis缓存更新策略**

- 这里，应该要答Redis 缓存与数据库之间的策略，即缓存模式。
- 旁路缓存。用户代码去负责更新缓存和数据库。
- 模式名记不清了，用户只更新缓存，然后等缓存过期时，将数据同步到数据库。
- 写操作写缓存，然后缓存去更新数据库。

### redis缓存淘汰策略

- 不淘汰，默认的，当运行内存超过最大设置内存时，不淘汰数据而是不继续提供服务，直接返回错误
- LRU淘汰策略：最近最少使用
- LFU淘汰策略：最近最少频率使用
- 在加了过期时间的数据中执行LRU
- 在加了过期时间的数据中执行LFU
- 随机淘汰
- 在加了过期时间的数据中随机淘汰。

### redis 为什么不立即删除过期数据？

- 如果想要立刻删除过期数据，那么就要为每个数据都设置一个定时器，然后当定时器时间为0时就出发事件删除数据。这样设计的话维护定时器的成本就太高了,浪费cpu时间。

### redis 过期数据删除策略？

**惰性删除+定期删除**

- 惰性删除。数据过期后并不会立即删除，而是用户读取到这些过期数据时再进行删除。优点就是不需要花太多cpu资源在数据删除上，缺点就是可能会占用部分内存空间。
- redis还会定期去抽取一批数据，删除其中的过期数据。
- 惰性删除+定期删除可能存在问题：删除没有成功(定期删除失败)并且后续没有再去请求这个key(没有进行惰性删除)，那么这个key会一直在内存中，这个时候就需要内存淘汰机制。(思考：如果使用消息队列的重试机制保证成功删除可以不)

### AOF重写

- 因为AOF记录的是每一条执行过的命令，但是这些命令只从过后可能某些数据已经不在了，而且记录太多会导致AOF文件过大，就设计了AOF重写。
- redis会**fork一个子进程**来进行AOF重写，重写时，会根据redis中现有的数据，生成一条一条的命令。
- 在重写时redis新执行的操作，会被写入**AOF重写缓冲区**当中，当AOF重写完成，会将这些命令追加到AOF文件。

### AOF重写导致主进程阻塞原因分析

配置原因，在AOF重写的时候依旧进行AOF刷盘，导致阻塞

### redis高并发和高可用

- 高并发：缓存预热、redis集群
- 高可用主从复制、哨兵机制、持久化

## redis集群

### RDB主从同步过程

完全同步：

完全同步发生在以下几种情况：

**初次同步**：当一个从服务器（slave）首次连接到主服务器（master）时，会进行一次完全同步

**从服务器数据丢失**：如果从服务器数据由于某种原因（如断电）丢失，它会请求进行完全同步。

**主服务器数据发生变化**：如果从服务器长时间未与主服务器同步，导致数据差异太大，也可能触发完全同步。

过程：

- 首先主库生成RDB文件
- 主从建立连接，将RDB文件发送给从库。
- 从库收到后，会先清除自己的库，然后开始加载RDB文件。
- 在生成RDB文件以及传输RDB文件的过程当中，redis主库是可以继续处理新的命令的，这些命令会被写入主从复制的缓冲区(replication backlog buffer)当中，最后一并发给从库，确保数据一致性。
- 这次全量同步完成后，后续的主从就会建立长链接，然后一条一条命令的进行传输。这些命令不仅会直接传输，还会写入复制积压缓冲区当中。

增量同步：

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250918155036271.png" alt="image-20250918155036271" style="zoom:50%;" />

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250918155109481.png" alt="image-20250918155109481" style="zoom:50%;" />

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250918155135983.png" alt="image-20250918155135983" style="zoom:50%;" />

- 从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1
- 主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；
- 然后主服务**将主从服务器断线期间**，所执行的写命令发送给从服务器，然后从服务器执行这些命令。

### 主从同步时写入新数据怎么办？

- 主从复制缓冲区。
- 另外还有一个缓冲区，主从复制积压缓冲区。这个缓冲区是**环形的缓冲区**，专门记录主从间命令，如果从库掉电，重连时就要从这里读取断连期间的数据。该缓冲区是循环写，如果已经有数据被覆盖(从库要读取的数据不存在)，那么就要重新进行全量复制。

### 什么是写时复制？redis哪些场景下用？

- 当redis生成RDB文件时，还需要能够继续接受新的请求。但是RDB是某一时刻的快照，为了不影响，就采用了写时复制技术。
- 修改操作会复制一份原先的数据，然后在数据副本上进行修改。当RDB生成完成后，数据副本就是最新的数据，清除原先的数据即可。这里是一般的写时复制技术，并不是redis里采用的。比如Java就是这种方式。
- 当没有写时复制时，子进程为了获取fork时候的内存庶数据(快照),朴素的办法是将内存的全部数据进行复制一份，**但这样会瞬间使内存增加两倍，可能OOM**
- 如果有写时复制后，当执行bgsave时，会fork一个子进程去执行读取内存写入RBD.db文件，子进程并不会完全拷贝父进程的数据，子进程和父进程共享物理内存，只是页表不同。如果父进程在RDB阶段修改数据，父进程会尝试直接修改内存，但此时内存页已经被标记为只读，操作系统会对修改内存页进行复制，父进程页表指向新的复制页，子进程页表指向不变。
- redis这边的写时复制似乎有些不一样，父进程如果需要修改数据，那么子进程才会进行拷贝，然后父进程的修改可以理解为对于执行RDB的子进程来说不可见。

### RBD和AOF混合策略

- RDB是一种内存快照，不易频繁生成，耗费资源。
- 而AOF是一种执行命令，写太多的话会导致文件过大，需要执行AOF重写，也会耗费资源。
- 所以Redis采用了一种折中的办法，就是两者结合。定期执行RDB快照，在两次RDB快照之间，使用AOF记录。

### 哨兵了解吗？

- 哨兵就是一种特殊的redis节点，不负责存储以及读取数据，仅仅负责主库下线，选择新的主库，**监听每个redis节点状态等。**
- 哨兵通过发送命令，监听每个节点的状态，包括主节点和从节点
- 当检测到master宕机，就会自动将从节点切换为主节点。在这期间会触发选主。

### 哨兵集群？

- 哨兵组成的集群。
- 因为如果只有一个哨兵节点，很难判断到底是因为主节点出问题，还是网络问题，还是哨兵节点出问题。
- 所以需要多个哨兵，降低误判的概率。

### 哨兵机制的选主节点算法：

- 主观下线：每个哨兵对redis节点进行是否下线的标记，此时节点不一定真正下线，还需更多哨兵确认
- 客观下线：超过一定数量的哨兵都标记节点下线，这节点客观下线
- 哨兵leader：一个哨兵确定某节点主观下线后会询问其他哨兵该节点是否认同下线，并请求其他哨兵投票自己为leader，但票数达到最低票数，则该哨兵成为leader
- 哨兵leader决定新主节点

### 哨兵和主节点怎么通信的？

- 发布订阅机制。哨兵订阅主节点，然后主节通过往对应频道发布消息，订阅消息的哨兵就可以知道。

### 讲讲Redis的发布订阅？

- pub/sub机制，~~redis 主节点往对应频道发消息~~。
- 主要有两种机制
  - 基于频道的发布订阅。这种是最简单的。订阅对应频道就可以从中获取消息。
  - 基于模式的。复杂一点的匹配机制。

### redis节点间怎么通信的？

- 有一种groips协议还是什么，主要思路就是类似于传谣言，每个节点把它现在知道的状况告知其他节点，就这样一直传，最终所有的节点就知道了其他节点的信息。
- redis采用的是去中心化，即不再

### Redis分片集群了解吗？

- redis对key进行hash进行数据和节点之间的映射
- 分片集群相当于对外看是一个redis，但是内部其实是多个redis。一共有16384个哈希槽，这些槽必须全部被分配完，才可以正常工作。相当于redis帮我们做好了代理层。
- 哈希槽映射到redis节点有两种方法：平均分配(16384 / 节点数)；手动分配
- 从客户端角度来看，只有一个redis节点，但是从内部看，会有多个节点，每个节点存储整体的一部分数据。

## 场景

### 布隆过滤器？假阳性？

- 只用来判断元素不存在
- 一个二进制数组，每当有一个数据来时，使用不同的hash算法计算hash值，然后将对应位的0改为1。
- 当要判断某个数据是否存在时，就计算它的哈希值，然后去对应位上判断，如果存在任意一位为0，说明**此数据一定不存在**。如果有所有位都为1，那么这个数据可能存在。

### 布隆过滤器删除节点怎么办？

- 一般的布隆过滤器，无法处理数据删除的问题。
- 我们可以设计一个比例，有多少数据发生过修改或者删除时，就重制布隆过滤器。
- 也可以使用计数布隆过滤器代替，即每次新增一个数据，对应的多个桶位+1

### 布隆过滤器更新数据怎么办

- 将跟新操作分为删除+新增

### 为什么删了一些数据后，内存占用率不变?

- 因为redis删除数据后，并不会立即将这部分内存交由操作系统管理，而是留给后续插入数据时使用。



### 有哪些原因会导致Redis查询变慢？

- 当数据量太多时，会有大量的哈希冲突，导致redis变慢。
- 另外，redis在执行rehash的时候，也会消耗一部分资源。
- 执行RDB或者AOF重写时，也会耗费一定的CPU资源，导致Redis变慢。
- 当物理机内存不够时，可能会有一部分的redis数据被换出内存，存入磁盘，导致这些数据读取时需要先从磁盘中进行读取。

### Redis的RedisObject了解吗？

- redis为了配合其他的一些特性，比如说内存淘汰策略，他一般使用LRU 或者LFU算法，那么就要统计每个key的访问次数。
- 所以说，Redis基于每一种基本数据结构，都使用RedisObject进行了封装，统计了类似于最后一次访问的时间、被引用的次数等。




### redisson怎么使用？看门狗机制？是否可重入？

- redisson是一把可重入锁
- 看门狗机制是一种自动续约机制，但是如果我们自己设置了锁的过期时间，那么看门狗机制就会失效。
- 防止的就是一个线程拿到锁，但是业务逻辑一直没有执行完成，锁自动释放了。在redisson被关闭之前，看门狗机制会一直给锁续期。
- 一般情况下来讲，分布式锁都需要设置一个过期时间，防止一个线程未释放锁导致整个服务不可用。
- tryLock()函数会设置锁时间，不会启动看门狗机制,可以设置获取锁的等待时间(异步)，lock()是阻塞式获取锁并且会启动看门狗机制，默认时间30秒，10后看门狗线程就会查看锁是否被释放，未被释放，加时到30秒



### redis 的set和list有什么区别？

- set的元素不可重复，且无序。
- 而list中的元素有序，且按插入顺序有序。

### **了解redis 的缓存模式吗？（Write-back，cache aside等）**

- 第一个问题，缓存更新策略那里写过。

### 什么是Redis 的缓存穿透、雪崩、击穿？

- 概念方面，可能记不太清，但是具体内容还是知道的
- 有一种情况，某个热点数据，突然过期了，这时候大量的请求越过缓存直接达到数据库上，这种情况是穿透或者击穿中的一种。
  - 解决方案，每次查询缓存不存在时，线程去获取分布式锁，只放一个请求去查询数据库，其他请求等待一段时间重新去缓存获取数据，可以有效降低数据库的压力。这种是强一致的解决办法。
  - 这种往往是因为删除了不该删的数据导致的，我们可以在删除数据时做校验。
  - 另一种方法就是，我们不阻塞请求，而是返回过期数据。这就要求我们不给热点数据设置过期时间，而是设置一个逻辑上的过期时间。当发现数据过期时，获取分布式锁，然后去查询最新的数据，然后写入。其他请求过来之后，发现数据过期，当尝试获取锁失败时，就说明当前有线程在处理这个过期数据，他只需要把过期数据返回就行了。这种处理办法要求能够接受短期的数据不一致。
  - 热点数据永不过期
- 另一种是雪崩，大量的缓存同时过期，导致查询落到了数据库上边。
  
  - 解决方案：均匀设置过期时间，我们可以给缓存设置过期时间时，加一个小的随机数，避免所有缓存同时失效。
  - 互斥锁：线程发现数据不在redis就加上互斥锁，只让一个线程去访问数据库并写入缓存，其他获取锁失败的进程重新访问缓存
  - 热点数据永不过期
  - 服务降级（暂停部分不重要的服务）和服务熔断（暂停访问db）
  
  ![image-20250304163439080](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250304163439080.png)
- 缓存穿透：另一种是有人恶意请求一个缓存和数据库都不存在的数据，导致数据库接收到大量的请求。
  - 解决办法，当数据库也不存在时，给缓存设置一个value为null的值，下次请求时就会走缓存返回null。
  - 使用布隆过滤器，可以过滤到大部分请求不存在数据的请求。

### redis中怎么保证缓存和数据库这种双写的一致性？

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250918213513364.png" alt="image-20250918213513364" style="zoom:50%;" />

- 分几种情况讨论吧。首先就是数据删除的场景
  - 这里，无非先删数据库，或者先删缓存。
  - 先删数据库，再删缓存，如果缓存中事先没有数据，则另一个线程去读取时，会把数据库的数据写入缓存，而删除数据的线程则会删除数据然后删缓存，如果在删除缓存之后另一个线程才写入缓存，那么这里就造成了一个长久的不一致。**读数据库-删数据库-删缓存-写入缓存**
  - 如果先删缓存，再删数据库，这样更容易造成不一致。比如说一个线程删了缓存，去删数据库之前，另一个线程读了缓存，发现不存在，就去读数据库，然后写缓存，而之前的线程又去删数据库，这就导致了不一致，缓存中存储了待删除的数据。**删缓存-读数据库-写缓存-删数据库**
  - 这里最好的解决办法就是给缓存增加过期时间，然后考虑是否可以接受读取到旧的数据。

**总的来说使用旁路缓存策略**

- 对于读操作，先访问缓存，未命中，访问db，再写回缓存
- 如果是更新缓存。
  - 阿里听到的方案是，**更新数据库后，删除缓存**。
  - 一般不会去更新缓存。都是直接删除缓存。
  - 如果缓存删除失败，则要考虑后续的问题，比如引入消息队列等等。引入消息队列的场景，就需要确保消息的可靠性。
  - 比如说该数据库，然后发一条消息，用于同步的删除对应的缓存，消息保证他的可靠性。

### redis+本地缓存+数据库的应用

以 “电商商品详情页” 为例，三层架构的协作流程如下：

1. **用户请求访问商品详情**：先查当前服务的本地缓存（如 Caffeine），若命中（如刚被其他用户访问过），直接返回，耗时 < 1ms；
2. **本地缓存未命中**：查 Redis 缓存（如商品 ID 为 key，存储商品基本信息 JSON），若命中，返回数据并同步更新本地缓存（下次同服务请求可命中），耗时～10ms；
3. **Redis 缓存未命中**：查数据库（MySQL 商品表），返回数据后，先写入 Redis（设置过期时间，如 10 分钟），再写入本地缓存（设置更短过期时间，如 1 分钟），耗时～100ms。

### redis和本地缓存(guava)如何保证数据一致性

- redis是中心化缓存，本地缓存是非中心化，在更新数据库后，无法让其他本地缓存删除缓存
- 解决方法：使用消息队列，在删除本地缓存后，异步删除reids缓存以及广播其他服务器删除本地缓存；本地缓存过期时间设短一点，使用redis兜底
- 关键记住两点：
  1. 写操作永远以数据库为基准，按 “数据库→Redis→本地缓存” 的顺序清除旧值，避免脏数据向上层扩散；
  2. 读操作，本地缓存->redis->数据库
  3. 本地缓存的同步依赖 “分布式通知”，Redis 的同步依赖 “删除 + 重试”，两者都需搭配过期时间兜底，确保即使同步失败，数据也能在短期内自动修正。
- 读操作时，数据可以加上版本号，来防止本地缓存的数据是旧数据，可以通过信任时间内不验证版本号直接返回结果+异步验证版本号(当前请求不验证，异步验证，保证了后续请求的版本号正确)

### 旁路缓存有什么问题？

- 在读：如果在A线程读取到mysql的之后在写到redis之前，b线程将mysql的数据进行更改了，此时A线程才将旧值写入到redis，这样造成了redis和mysql的数据不一致
- 解决方法：使用一个线程监听数据库binlog,然后去更新redis的数据

### 热Key如何处理

- 首先是对热Key的监控：可以在业务代码中调用redis时统计key的频次并且保存到本地缓存；使用reids的monitor监控；代理中进行统计；根据对业务的理解，识别出热key
- 在监控到热key后，可以**将热key打散到不同的服务器**

### big Key如何处理

- 使用scan(渐进式分批扫描)扫描key，建议在从服务器上进行扫描；或者使用开源工具进行扫描
- 对big key进行拆分

### redis处理亿级用户日活

- 使用reids的set
- 使用reids的hash
- 使用bitmap
- 使用hyperloglog

### redis怎么保证高并发和高可用的

- 首先是高并发
  - redis提供了分片集群。相当于把数据分片存储到不同的redis当中，以此提供更高的并发量。
  - 读写分离，在主从模式下，可以让主库去写，从库提供读，然后提高并发量。

- 高可用
  - redis提供了持久化机制。
  - 哨兵机制，提供了主从切换。
  - 集群模式。并提供故障转移机制。

### redis分布式锁实现原理？setnx？

- 这里首先要确定几点，也就是说分布式锁的设计要求。
  - 互斥性，即每次只有一个线程能够加锁成功。
  - 另外，释放锁时，要确保一定是加锁线程释放的。
  - 锁要有一个超时时间，避免加锁线程崩溃，没有及时释放锁，导致整个服务不可用。
  - 锁要有一定的加时机制。防止业务没执行完，就被释放了。
- redis实现的分布式锁有两种，一种是setnx，一种是java 提供的redission。
- setnx是基于SET命令的争抢锁机制。客户端可以使用SET resource_name lock_value NX PX milliseconds,如果设置成功，则认为客户端获得锁。客户端完成操作后，解锁的还需要先判断锁是不是自己，再进行删除，**这里涉及到 2 个操作，为了保证这两个操作的原子性，可以用 lua 脚本来实现**
- redission提供了比较全面的机制，比如说锁超时，锁续约，并且可以判断是谁加的锁。

### redis实现在一定时间内设置限制登录次数

- 使用zset

- key表示String+id(login:failures:{userId})，value表示uuid(保持唯一性)，score表示该用户某一次的登录时间戳

- redisTemplate+lua脚本

- 简述流程：1.生成key、value和score参数(时间参数) 2.通过范围删除指令删除窗口时间之外的记录 3.将当前失败的记录添加到该用户主题下  4.查询窗口时间内的失败次数

- ```java
  @Component
  public class SlidingWindowRateLimiter {
      private final RedisTemplate<String, String> redisTemplate;
      private final RedisScript<Boolean> rateLimitScript;
  
      // 限制周期（秒）
      private static final int WINDOW_SECONDS = 10;
      // 最大尝试次数
      private static final int MAX_ATTEMPTS = 3;
      // 存储前缀
      private static final String KEY_PREFIX = "login:limiter:";
  
      public SlidingWindowRateLimiter(RedisTemplate<String, String> redisTemplate) {
          this.redisTemplate = redisTemplate;
          this.rateLimitScript = createRateLimitScript();
      }
  
      /**
       * 判断是否允许登录
       * @param userId 用户ID
       * @return true表示被限制，false表示允许登录
       */
      public boolean isLoginAllowed(String userId) {
          String key = KEY_PREFIX + userId;
          long currentTime = System.currentTimeMillis();
          long windowStart = currentTime - (WINDOW_SECONDS * 1000);
          String uuid = UUID.randomUUID().toString();
  
          List<String> keys = Arrays.asList(key);
          List<String> args = Arrays.asList(
              String.valueOf(windowStart),
              String.valueOf(currentTime),
              uuid,
              String.valueOf(WINDOW_SECONDS),
              String.valueOf(MAX_ATTEMPTS)
          );
  
          return !redisTemplate.execute(rateLimitScript, keys, args.toArray());
      }
  
      /**
       * 获取剩余尝试次数
       */
      public int getRemainingAttempts(String userId) {
          String key = KEY_PREFIX + userId;
          long currentTime = System.currentTimeMillis();
          long windowStart = currentTime - (WINDOW_SECONDS * 1000);
  
          Long count = redisTemplate.opsForZSet().count(key, windowStart, currentTime);
          return Math.max(0, MAX_ATTEMPTS - count.intValue());
      }
  
      /**
       * 清除限流记录（登录成功时调用）
       */
      public void clearLimit(String userId) {
          String key = KEY_PREFIX + userId;
          redisTemplate.delete(key);
      }
  
      /**
       * 创建限流 Lua 脚本
       */
      private RedisScript<Boolean> createRateLimitScript() {
          String script = """
              local windowStart = tonumber(ARGV[1])
              local currentTime = tonumber(ARGV[2])
              local uuid = ARGV[3]
              local windowSeconds = tonumber(ARGV[4])
              local maxAttempts = tonumber(ARGV[5])
              
              -- 移除窗口外的记录
              redis.call('zremrangebyscore', KEYS[1], 0, windowStart)
              
              -- 添加当前登录尝试
              redis.call('zadd', KEYS[1], currentTime, uuid)
              
              -- 设置过期时间，避免冷用户数据长期存储
              redis.call('expire', KEYS[1], windowSeconds)
              
              -- 获取窗口内的尝试次数
              local count = redis.call('zcard', KEYS[1])
              
              -- 判断是否超过限制
              return count > maxAttempts
          """;
  
          return new DefaultRedisScript<>(script, Boolean.class) {
              @Override
              public RedisSerializer<?> getResultSerializer() {
                  return redisTemplate.getStringSerializer();
              }
          };
      }
  }
  ```

  

## redis优化

### 尽量使用短的key

降低内存，减少哈希表的算法执行时间;

### 使用批量操作减少网络传输

- 一个redis命令可以简化一下4步：发送命令；命令排队；命令执行；返回结果。可以称之为Round Trip Time（RTT，往返时间）
- 使用批量操作可以减少网络传输次数，进而有效减小网络开销，大幅减少 RTT

### 大key问题的缺点

- 内存占用过高
- 性能下降
- 阻塞其他操作。某些对大Key的操作可能会导致Redis实例阻塞
- 网络拥塞。每次获取大key产生的网络流量较大，可能造成机器或局域网的带宽被打满
- 主从同步延迟
- 数据倾斜

### 如何解决Redis大key的问题

- 对大Key进行拆分
- 对大Key进行清理。将不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。注意，要使用异步删除。
- 对过期数据进行定期清



# 计网

### http 协议响应码1-5开头都代表什么

- 1xx（信息响应），表示服务器已接收请求，需客户端继续操作或等待处理
- 2xx（成功响应），表示请求已被成功处理并返回结果
- 3xx（重定向），表示需客户端进一步操作以完成请求
- 4xx（客户端错误），表示请求存在语法或权限问题
- 5xx（服务器错误），表示服务器处理请求时发生内部错误

### http请求为什么是无状态的？

- 因为在每个 HTTP 请求之间，服务器不会自动保留有关前一个请求的任何信息。每次客户端发起 HTTP 请求时，服务器会将其视为一个全新的请求。
- 服务端并不会存储任何有关该请求的信息，同一个客户端的多次请求，服务端并不能区分出来，都会当作一个全新的请求。
- 一般的做法是http请求的客户端，自己在请求当中携带一部分的信息，用于证明自己的身份。

### http 和 https的区别，端口号？

- http和https的主要区别在于，https提供安全性保证，它的通信是经过加密的。
- 第二个区别在于默认端口号不同，http是80，https是443。

### tcp建立连接的三次握手和四次挥手

- 客户端发起建立连接的请求，生成一个序列号发送给服务端。
- 服务端收到后，给客户端返回一个ACK，值等于客户端序列号+1，同时生成自己的序列号，一并发送给客户端。
- 客户端收到后，给服务端发送ACK，值等于服务端的序列号+1，然后连接建立就算完成。而且这一次是可以携带正式数据的。
- 之所以要三次的原因如下：
  - 防止已经失效的一个请求去建立连接。最经典的一个回答。
  - 另一个原因是确认双方都有发送和接受消息的能力。因为TCP是全双工的，双方都可以发送和接受消息。需要确保两者都能顺利发送和接收。
  - 防止SYN洪水攻击。如果两次握手，那么服务器在接受到SYN后就会建立连接，分配资源。在SYN洪水攻击中，攻击者发送大量的SYN报文，但不发送最后的ACK报文，这会导致服务器分配大量的资源，最终可能导致资源耗尽。第三次握手可以防止这种攻击，因为只有在收到ACK报文后，服务器才会分配资源。
  - 假设只需要一次连接，即客户端直接发送数据，如果服务器正常还好，如果不正常，那么就会导致大量的数据涌入网络，造成浪费，还有可能导致网络拥堵。
  - 假设两次握手，那么会导致一个已经失效的连接请求，成功建立连接。假设客户端发起连接，这个请求拥堵了，然后他发起第二次，成功建立，处理完之后，之前拥堵的那个请求到达了服务端，那么服务端相应ack之后连接就建立了，这样其实会导致服务端这边有一个端口被占用，资源浪费。

### 四次挥手时，什么阶段会出现time_wait状态？

- **主动断开连接的一方**，在接收到对方发送断开连接的报文段后并响应ACK后，就会进入time_wait状态。
- 四次挥手的流程：
  - 假设客户端为主动断开连接的一方
  - 首先客户端会给服务端发送一个断开连接的请求，并生成序列号。
  - 服务端收到请求时，会给客户端返回一个ACK确认号。当客户端收到该序列号时，客户端到服务端的通信就断开了。
  - 服务端会给客户端再发送一个序列号，表示要断开服务端和客户端间的通信。
  - 客户端收到序列号时，会给服务端返回ACK，如果超过2个报文段最大存活时间还没有收到服务端的消息，就进入closed状态。

### 四次挥手等待时间时多少？为什么是这个时间？超时后会怎么样？

- 2MSL。2个报文的最大存活时间。
- 因为首先它需要将ACK返回给对方，这里需要1个最大存活时间。如果ACK没有返回给对方，那么对方会重发报文段，~~这个报文段到达又需要1个时延。也就是说2个时延内如果没有收到服务端重发的报文段，就可以认为响应的ACK已经到达服务端了~~。
- 上边的说法并不一定准确。其实一个报文的往返时延，或者说重发的超时时间，是远低于一个报文段的最大时间的。也就是说，在这2MSL之间，其实可以重试多次。
- 通过等待 2MSL，可以确保与当前连接相关的所有报文在网络中都被丢弃，从而避免这些旧的重复报文对新连接造成干扰。

### TCP的粘包问题

- 由于 TCP 是**面向字节流**的协议，而不是基于消息的协议，因此在接收端，多个数据包可能被拼接在一起，而客户端无法直接区分这些数据边界
- 原因：
  - **面向字节流**：TCP 并没有边界的概念，它只保证字节的顺序传输，因此在发送方传输的多个小数据包，在网络传输过程中可能会被合并或拆分。**（这一点是核心原因，TCP面向字节流，没有边界的概念）**
  - **流量控制和拥塞控制**：TCP 会动态调整发送数据的大小，以便更高效地利用网络带宽。因此，发送端可以将多个小的数据块合并成一个大的数据块进行传输，以减少开销。

- 解决办法：
  - 可以在每个消息的前面附加一个**固定长度的消息头**，该消息头包含该消息的长度信息，接收方可以根据这个长度来判断消息的边界。
  - 特殊分隔符

### TSL/SSL建立连接的4次握手？

- 这里的四次握手，一般都是涉及到https的加密。

  1. 客户端先向浏览器发起请求，本次请求携带了一个**随机数**，用于后续生成对话密钥。并携带**支持的协议版本**，支持的**加密方法**以及**压缩方法**。
  2. 服务端向客户端回应，并确认**加密的通信协议版本**，如果浏览器和服务端支持版本不一致，则取消加密。确认加密方法，并携带服务器证书，此次过程服务端也要生成一个随机数，发送给客户端。
  3. 客户端验证服务端的证书，如果受信任或者用户选择接受不信任的证书，浏览器生成一串密码，并用证书提供的公钥加密(服务器的私钥能够解开)。使用约定好的Hash计算握手消息，并用生成的随机数对消息加密。并将所有信息发送给服务端。
     - 第三步，这里用户会生成一串随机数，然后用证书中的公钥进行加密，发送给服务端。
  4. 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。使用密码加密一段握手消息，发送给浏览器。
     - 这一步，服务端一共会拿到3个随机数（首先是第一次握手客户端发送的，然后是第二次握手服务端发送给客户端的，然后是第三次握手中，客户端使用公钥加密的），并根据约定的算法，计算出最终的**会话秘钥**。
     - 会话密钥是由客户端随机数、服务端随机数和服务端密码生成的

### TCP的拥塞控制

- TCP连接在发送数据前，会先试探整个网络的拥塞情况，目的是为了避免恶性循环，发送数据丢失，然后尝试重传，导致整个网络崩溃。发送方通过**拥塞窗口**控制每次能发送的最大数据量（字节数），其值由网络拥塞程度动态决定
- 慢启动：拥塞窗口初始为1，每次增加两倍，直到慢启动阈值
- 拥塞避免：每个传输轮次结束后,拥塞窗口值只能线性加 1，直到出现拥塞(超时重传)，更新慢启动阈值为当前拥塞窗口的一半，拥塞窗口设为1，重新开始慢启动算法
- 快重传：重复收到重复的3次重复确认，不用等待超时重传结束，而是立即重传
- 快速恢复：一旦收到三次重复的确认，这表明只是个别的报文段丢失了，而不是发生了网络拥塞，则不进行慢启动，而是更新慢启动阈值为拥塞窗口的一半，拥塞窗口也更新为之前的一半
- ![image-20251015145132592](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20251015145132592.png)

### TCP的流量控制

- TCP的发送方和接收方都维护一个窗口，发送方只能发送窗口内的数据，而只有当收到接收方返回的ACK之后，窗口才可以移动。这样就可以避免发送方速度过快而导致接收方无法接收，导致资源浪费。
- 接收方只会接收窗口内的数据。窗口内的第一个需要表示了客户端期待接收到的序号。

### **TCP怎么保证可靠传输的？**

- 序列号与超时重传，这个是最关键的
- 流量控制
- 拥塞控制
- 校验和，校验数据包是否正确

### TCP怎么保证传输安全性

- TCP似乎无法保证传输的安全性，只能保证可靠性。
- 似乎是采用校验和，看数据包正否正确。

### TCP半连接

- 当客户端发起建立连接请求后，会发送数据包给服务端。
- 当服务端收到该请求后，就会将其放入半连接队列当中。并给客户端响应ACK。
- 这里可能会存在半连接队列满了，就导致服务端不能建立新的连接。
  - 解决办法，减少重传的ACK和序列号的次数，超过次数就断开连接。
  - 增大半连接队列大小。

### TCP的头结构

- 最关键的部分，发送数据时需要有一个序列号
- 另外接收数据时需要有一个确认号ACK。
- 源端口号
- 目的端口号
- 窗口大小，滑动窗口算法
- 校验和，校验数据包是否正确。

### TCP和UDP的区别

- UDP传输的基本单位是数据报，**UDP 是面向消息的**，每个 UDP 数据报都是一个独立的、具有明确边界的消息。

- TCP保证可靠传输，需要建立连接
- UDP尽最大努力传输，性能较好，传输数据时不需要提前建立连接。
- TCP提供了拥塞控制，流量控制等。UDP没有
- TCP保证数据的按序到达，而UDP不保证。

### http1.0，1.1，2.0和3.0有什么区别？

- http1.0只有短连接，而1.1开启了长连接，并且连接可以复用，且可以进行body的压缩。有更多的状态码。
  - 队头阻塞问题：但是http1.1的长连接，多个请求可以复用一个连接，但是会存在队头阻塞问题。因为它只能在一个请求完全处理完之后，才可以处理第二个。如果第一个请求被阻塞，那么后续请求都无法进行处理。
  - 1.1中还添加了缓存机制。
- http2.0使用了类似于多路复用的机制，解决了因为第一个请求阻塞而导致的队头阻塞问题。但是仍然会有队头阻塞问题，原因是因为TCP要提供可靠传输。如果前边的请求存在丢包问题，那么后续请求的数据包虽然到达了接收方，但是应用层却无法读取对应的数据。整体来看仍然存在，但是本质原因在于TCP的可靠性。
  - http2.0支持头部压缩
  - 并且支持了服务器推送，即客户端请求某些资源时，可以将其他资源一并推送给客户端。

- http3.0则采用了QUIC协议，该协议基于UDP来实现，并在应用层这里添加了可靠性的保证。它具有类似 TCP 的连接管理、拥塞窗口、流量控制的网络特性。
  - 3.0解决了队头阻塞问题。因为是基于UDP，它的可靠性是在应用层保证的，所以不存在一个请求重传导致其他请求到达的数据也无法读取。它有多个stream流，多个流之间不影响。但是如果一个流内的第一个请求丢失，会导致该流后续的请求无法处理。但不会影响其他的流。

### http1.1队头和2.0队头阻塞问题，阻塞原因的区别？

- 上题的答案已经写了

### 计算机网络的4层和5层结构，分别什么作用？

- 四层
  - 应用层：这一层主要的作用是建立用于与计算机网络之间的一个桥梁吧。使得应用程序可以通过网络传输数据。
    - 提供为应用软件提供服务的接口，用于与其他应用软件之间的通信。
  - 传输层：负责可靠的端到端的传输。包括数据包的发送和接收。
  - 网络层：~~负责数据在网络中的传输，路由算法等。~~这一层负责处理数据包的路由和转发，使得不同的网络间可以相互通信。
  - 网络接口层：这一层负责处理与网络硬件和驱动的交互，包括数据的发送和接收、错误检测和修复等。
  
- 五层
  - 应用层 
  - 传输层
  - 网络层
  - 数据链路层：负责点对点的网络寻址、错误侦测和纠错。当表头和表尾被附加至数据包后，就形成数据帧（Frame）。
  - 接口层：在物理网络上传送数据帧，它负责管理电脑通信设备和网络媒体之间的互通。

### 数据链路层和网络层的区别？

- 数据链路层是为了解决相邻节点间通信问题的。

### **逻辑地址怎么转换为物理地址**

- 地址转化协议ARP。
- APR会维护一个映射表，里边存储了IP地址和MAC地址的映射。
- 如果没有，那么就会广播一条消息，类似于我的ip地址是xxx，我要找IP地址为xxx的mac地址，只有对应ip地址的网络会接收该消息，然后发回给他mac地址。
- ip地址是一个虚拟的地址，我们想要真正的将一个数据传输给对方，就需要获取到MAC地址。通过ip地址可以找到对应地址属于哪个子网，而子网内需要由NAT转化，需要MAC地址。

### 输入url到显示页面，经历了哪些流程？

- 首先是将url转化为一个http或者https的请求
- 然后是DNS域名的解析，拿到对应的ip地址。
- 之后就是TCP的三次握手，建立连接。
- 封装ip数据格式
- 通过物理机的网卡发送数据
- 经历路由协议，到达服务器
- 服务器处理请求，返回响应
- 前端渲染页面，结束

### websocket了解吗？与http有什么区别？

- websocket是一种长连接，它是双向的，数据可以在两个方向流动，且具有实时性。
- 而http的话也是双向的，**属于半双工吧**，早期的还是基于短连接，http1.1之后加入了长连接以及多路复用。它属于请求-响应模式，客户端发起请求，等待服务端的响应。

### cookie 和session的区别？为什么会有这两个东西？cookie的跨域问题？

- http是无状态的，所以为了标记每次请求的状态，就产生了这两个东西。
- 其中cookie一般是存储在客户端这边，而session是存储在服务端这边。
- Cookie 默认是与创建它的域名相关联的。这意味着如果一个网站在 `example.com` 域名下创建了一个 Cookie，其他域名如 `anotherexample.com` 就无法访问这个 Cookie。
- 但是，可以通过设置 Cookie 的 `Domain` 属性来实现跨域共享 Cookie。例如，如果将 `Domain` 设置为 `.example.com`，那么所有 `example.com` 下的子域名都可以共享这个 Cookie。

### rpc框架和HTTP的区别？

- 首先是设计的应用场景不同
  - http是无状态的，属于请求-响应的模型的协议，主要用于web浏览器和web服务器之间的通信。
  - rpc主要是为了网络上的一个程序调用另一个程序，使得夸网络的调用像调用本地程序一样。RPC主要用于分布式系统中的服务之间的通信。主要用于服务间的调用。
- **RPC 主要是基于 TCP/UDP 协议的**，而 **HTTP 服务主要是基于 HTTP 协议的**。（这一点不一定正确）
  - 有些rpc框架，提供自定义协议来优化性能，比如说grpc使用http2协议。
- http的本质是服务端和浏览器之间通信的一种协议。
- 从效率方面来说，Http是文本协议，文本在网络上传输需要占用更多的带宽，而rpc框架则传输的是二进制协议数据，占用带宽低。
- 另一方面，rpc一般是有状态的，调用方与服务的提供方会建立一个长链接，多次请求服用这个链接。而http则需要多次建立连接。
- 可以简单理解，rpc有状态，服务调用方和服务提供方之间建立连接后，服务提供方会存储一部分信息，那么下次服务调用时就只需要携带会话id即可。

1. 通信协议不同：HTTP 使用文本协议，RPC 使用二进制协议。
2. 调用方式不同：HTTP 接口通过 URL 进行调用，RPC 接口通过函数调用进行调用。
3. 参数传递方式不同：HTTP 接口使用 URL 参数或者请求体进行参数传递，RPC 接口使用函数参数进行传递。
4. 接口描述方式不同：HTTP 接口使用 RESTful 架构描述接口，RPC 接口使用接口定义语言（IDL）描述接口。
5. 性能表现不同：RPC 接口通常比 HTTP 接口更快，因为它使用二进制协议进行通信，而且使用了一些性能优化技术，例如连接池、批处理等。此外，RPC 接口通常支持异步调用，可以更好地处理高并发场景。

### rpc和http是否是在同一层？

- 不一定。rpc是更高级的封装。它可以基于http，或者基于tcp甚至udp。不过好像都是在应用层。应该是一层。

### 讲一下TIME_WAIT，该状态有什么问题？如果存在大量的TIME_WAIT，怎么优化？

- 该状态会占用对应服务器的一个端口号。如果出现大量的time_wait状态，会导致对应服务器的端口号不够用，然后无法建立新的连接。对外显示的就是服务端不可用。

- `SO_REUSEADDR`设置为1在`TIME_WAIT`时允许套接字端口复用。
  - 当有一个有相同本地地址和端口的socket1处于TIME_WAIT状态时，而你启动的程序的socket2要占用该地址和端口，你的程序就要用到该选项。

- 缩减 time_wait 的时间
- 客户端，HTTP 请求的头部，connection 设置为 keep-alive，保持存活一段时间：现在的浏览器，一般都这么设计了

### UDP的广播和多播

广播：

- 广播指的是将数据包发送给同一网络下的所有主机。有几个使用场景：
  - DHCP（动态主机配置协议）服务器向网络中的所有设备广播分配IP地址的请求。
  - ARP（地址解析协议）用于在以太网网络中将IP地址解析为MAC地址，ARP请求通常是广播的。
  - 广播的缺点也很明显，其他不需要改数据的设备，也会收到改数据，导致一定的浪费。

多播：

- 多播是一种将数据包发送给特定一组接收者的方式，而不是网络中的所有设备。
- 比较适用于实时传输的场景，但是需要一定的配置。

# 操作系统

### 原子操作怎么实现

- 从软件层面来说，可以禁用中断，那么当前线程在执行过程中就无法响应中断，不会暂停执行。
- 另一个思路就是加锁。加锁虽然不保证不中断，但是其他线程拿不到锁，也无法执行，从另一个角度去保证了原子性。
- 另外就是硬件，去支持一个原子操作。像操作系统的锁，加锁和释放锁都是基于硬件的原子操作，先检查锁状态，如果锁空闲就加锁。

### 什么是CPU中断

- **CPU 中断**是指处理器在执行程序的过程中，由于某种**异步事件**或**异常情况**，需要暂时停止当前正在执行的指令序列，转而去处理这类事件或异常。中断事件处理完毕后，CPU 会返回之前被中断的程序继续执行。
- 可以分为以下几类：
  - **硬件中断（Hardware Interrupt）**：
    - 硬件中断是由外部设备（如键盘、鼠标、网络设备、硬盘等）发起的信号，通知 CPU 有事件需要处理。
    - 例如，当用户按下键盘时，键盘控制器会发送中断信号给 CPU，要求处理按键输入。
  - **软件中断（Software Interrupt）**：
    - 软件中断是由程序主动触发的，用于请求系统服务或操作系统内核的帮助。它通常通过一条专门的指令（如 `INT` 指令）发起。
    - 例如，操作系统中的系统调用就是通过软件中断来完成的，当用户程序想要执行 I/O 操作时，会触发软件中断，操作系统来处理这个请求。
  - **时钟中断（Timer Interrupt）**：
    - 时钟中断由系统时钟触发，定期打断 CPU 的工作，用于实现操作系统的任务调度和时间管理。典型的使用场景是操作系统中的任务切换，确保各个进程能公平地获得 CPU 资源。
  - **异常（Exception）**：
    - 异常是由处理器在执行程序时遇到错误或特殊情况（如除零错误、页错误、非法指令等）自动发出的中断信号。

### 系统调用的过程

- 首先用户根据操作系统提供 的接口，发起一个系统调用，并传递对应的**参数和调用号**
- 操作系统根据调用号找到对应的调用函数
- 将对应参数从用户态拷贝到内核态。
- 然后操作系统根据参数以及函数完成对应的处理
- 将结果返回给用户。

### 操作系统的锁实现原理

- 操作系统的锁主要依赖于这种互斥量

- 加锁的操作其实依赖于硬件的原子性操作，即执行过程中不允许被中断，主要依赖于TAS。

  - 是一个原子操作，意味着它同时完成两个步骤：
    1. **检测** 当前锁的状态（是否被其他线程持有）。
    2. **设置** 锁的状态为“已占用”。

  - 这个操作是**不可分割的**，因此不会有其他线程同时检测并获取到同一个锁。

### 进程和线程的区别？了解协程吗？

- 我们手机或者电脑运行的程序就是一个进程，进程间不共享内存，各自有自己的运行空间。
- 线程是最小的调度单位，一个进程有多个线程，一个进程内的不同线程共享该进程的内存空间。
- 线程上下文切换开销比较小，进程开销比较大。

### 什么是内核态？用户态？

- 用户态只能执行部分执行，而内核态可以执行全部的指令。
- ~~内核态主要运行操作系统的程序，操作硬件~~。内核态其实就是一个权限级别更高的形态，他可以运行一切指令。内核态具有访问所有础设备和内存的权限，可以执行任何CPU指令。
- ~~用户态往往运行用户软件~~。用户态的权限会低很多，往往只能运行一些比较简单的命令。用户态程序不能直接访问内存，不能执行某些特殊的指令，它想要执行这些内容时必须发起系统调用才可以。

### 进程间通信有哪几种方式？

- 管道，接收方必须一直等待才可以。
  - 匿名管道和有名管道
- 消息队列，A和B要发消息，A把消息直接放入对应得消息队列就可以返回，然后B需要时读取，消息队列是保存在内核中的一个消息链表。
  - 消息队列不适合进行大数据传输。
  - 另外，消息队列传输数据时涉及到内核台与用户态数据的拷贝。
- 共享内存，需要提前创建。创建方式也简单，申请一块内存，然后将两个进程得虚拟地址映射到同一个位置即可。
  - 共享内存方式需要**信号量**机制来保证数据的同步。
- 信号，接收方不在运行状态也行，操作系统内核会保存对应得消息。当接收方运行时会交由接收方。
- 去哪的二面，问了一个问题，你们使用的是哪种进程间通信的方式，其实RPC远程调用也属于进程间通信的一种方式，只不过两个进程并不在同一台机器上，而是跨网络的进程间通信。

### 匿名管道和有名管道的区别？

- 匿名管道用作父子进程或者兄弟进程间通信，~~半双工的~~单工的，一方发送另一方只能等待接收。如果想要双向通信，需要建立两个管道。
- 管道其实就是操作系统内核的一段缓存。从管道的一端写入数据，其实就是将数据缓存在内核当中，另一端读取数据，也就是从内核中读取该数据。
- 而有名管道是可以在任意两个进程间进行通信。

### LRU算法？LFU算法？

- 一个是最近最久未使用算法
  - 该算法需要把使用过的内存放到链表的最前端，然后换出内存时从链表的末尾开始。
- 一个是最近最少使用算法
  - 该算法需要维护一个计数器，每次换处时，就从计数器最少的内存页开始换处。

### select/poll enpoll了解吗？

- I/O多路复用那里写过了。

### 什么是零拷贝？

- java那里写过

### 什么是写时复制？

- java那里写过

### **死锁产生的几个条件？**

- 循环等待条件，~~两个进程都在等待对方释放某资源~~多个线程形成一种头尾相接的循环等待。
- 互斥条件，即存在共享资源不能同时访问。
- 不剥夺条件，即不能强制抢占其他进程所占有的数据。
- 请求与保持条件：请求某资源请求不到时也不释放已经获得的资源。

### **如何避免死锁？**

- 申请资源时一次请申请够全部资源
- 申请资源失败时，就要放弃自己已有的资源。
- 按序申请某一资源，释放资源时顺序相反。

### 操作系统的**内存模型**？

- 它的内存主要分为两种：
- 物理内存和虚拟内存。
- 物理内存就是真实的内存。
- 而虚拟内存就是一个抽象的概念，它是的每个进程认为它自己拥有一段连续的、完整的内存空间。虚拟内存与物理内存之间一般需要页表来进行映射。

### **内存管理**？

- 涉及的内容比较多，像虚拟内存管理，实际内存的分配，页面置换算法，共享内存等。

### 虚拟内存了解吗？

- 早期的应用程序，他们创建之后是直接跑在物理内存上的，这时候恶意程序就可能访问到其他程序的内存空间，影响系统稳定性。
- ~~为了解决这个问题，在每个程序运行时，都给他分配的一个虚拟内存空间，在他看来，只有它自己在运行。操作系统负责将它的这些虚拟地址映射为真实的地址。只要操作系统处理好这个映射，就可以保证不同应用程序之间内存的隔离。~~
- 虚拟内存是一种内存管理技术，它为每个进程提供了一个假象，使得每个进程都认为自己拥有连续的、完整的地址空间，这个地址空间通常远大于物理内存的实际大小。这种技术允许多个进程同时运行，而且每个进程都认为自己独占了全部的内存资源。
- 操作系统和计算机硬件共同维护一个映射表，将虚拟地址映射到物理地址。当一个进程需要访问内存时，它使用的是虚拟地址，这个虚拟地址会被自动转换为对应的物理地址。
- 该机制的实现需要依赖于分页或者分段。
- 每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页 (Page, 4KB)。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。

### MMU如何映射？

- MMU又称内存管理单元
- 它的映射过程主要依赖于页表或者段表。
- 页表现在一般来说都是多级页表。一级页表存储的都是二级页表的指针。
- 分页内存管理，一般虚拟内存会分为**页号和页内偏移量**，通过这两个来找到具体的物理地址。
- 如果是分段，那么就需要有一个段表，CPU产生的虚拟地址包括段号和段内偏移量，然后去段表中找到具体地址。

### 操作系统的**进程调度**算法

- 先来先服务算法
  - 就像它的名字，哪个作业先来，哪个作业先调度。但是如果现来的作业是一个长作业，会导致整体的响应速度变慢。因为会导致后续的短作业等待很长时间。
- 短作业优先算法
  - 哪个作业的运行时间短，先执行哪个。但是会导致长作业出现饥饿现象。
- 时间片轮转算法
  - 每个作业分配一个时间片，用完后就回到队尾，等待下一次分配。
- 多级反馈队列调度算法
  - 会有多个队列，高优先级队列中的作业先执行，如果没执行完则会被送往低优先级队列。
  - ~~低优先级队列中的任务会一次一次往高优先级队列中移动。~~
  - 新的进程会被放入到第一级队列（优先级最高的）的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
  - 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行
  - 优先级越高，时间片越短。
- 高响应比优先算法。

### CPU上下文切换时，哪些操作比较耗时？

- 首先，cpu需要保存当前进程的寄存器状态，包括通用寄存器和程序计数器等。并且要加载新进程的这些东西。

- 更新页表。每一个进程都有自己私有的页表。当发生进程上下文切换时，就需要将对应进程的页表加载。
- 根据进程的调度算法，选择一个合适的进程来执行。

### 线程或者进程的几种状态，怎么转换的？

- 分为以下几种状态
- **新建**。此时是线程或者进程刚刚被创建。在这个阶段，操作系统会分配改进程或者线程必备的资源。
- **就绪**。此时进程或者线程已经获得了除cpu意外的所有资源。其实这里对应了java中线程执行start。
- **运行**。获得了CPU资源。处于运行状态。
- **阻塞**。线程在等待I/O或者分配的cpu时间片用完了。
- **结束**。线程或者进程执行完毕，结束。

### **原子操作的原理，操作系统原子性，java原子性？**

- 操作系统原子性有两种实现办法：
  - 总线加锁。该方式是利用了CPU总线的lock信号，当一个处理器在总线上输出该信号时，其他处理器的请求会被阻塞住，那么该处理器可以独占共享内存。
  - 这种方式会使得其他处理器不仅不能处理当前处理器所需要的内存，连其他内存都无法访问。

- 缓存加锁。
  - 这种方式中，我们只需要同一时刻保证缓存中的原子性即可。

- 前两种方案都是通过加锁。还可以通过禁止中断，即执行指令时不允许中断来实现原子性。
- 硬件支持也可以确保原子性操作。
- java的原子性可以通过原子类，或者synchronized关键字。

### 操作系统的i/o过程？

- 

### 共享内存是怎么实现的？

- 将两个进程的虚拟内存映射到同一块物理内存即可。

### 什么是僵尸进程？什么是孤儿进程？

- 僵尸进程，父进程未结束，子进程结束了，但是未释放子进程占用的内存空间，导致子进程虽然结束但是占用资源没有释放。
- 孤儿进程，父进程已经结束，但是未关闭子进程。为了避免它占用资源，一般会把它的父进程设置为init进程的子进程。

### 软中断和硬中断的区别？

- 软中断一般并不会立即停止，需要经历一段流程，由操作系统的内核程序触发。
- 硬中断会立马终止。由硬件触发。

### 操作系统中的硬链接和软链接的区别是什么

- 硬链接：新建的文件是已经存在的文件的一个别名，当原文件删除时，新建的文件仍然可以使用。
  - 这里我觉得可以理解为深拷贝。因为深拷贝会真实的拷贝对象内部的对象，当原先的对象被释放时，深拷贝的对象仍然可以访问。
- 软链接：也称为符号链接，新建的文件以“路径”的形式来表示另一个文件，和Windows的快捷方式十分相似，新建的软链接可以指向不存在的文件
  - 这里可以理解为浅拷贝。
  - 浅拷贝只会拷贝对应对象成员属性的引用，指向同一个对象。当原对象释放时，就无法访问。

### 不同的进程之间地址空间独立的，同一个锁对象如何在不同的地址空间传递

- 我们可以将创建的锁对象，一般来说是一个信号量或者互斥量放到共享内存当中，每次只有一个可以获取成功，也就是加锁成功。

### 共享内存不同进程如何互斥的访问

- 使用互斥量或者信号量，使得每一个时刻只有一个进程可以访问共享内存中的数据。

### 操作系统有没有用到什么技术加快地址查询

- 首先，引入虚拟内存之后，每次访问都需要先访问页表，当出现多级页表时，那么就需要进行多次页表的访问，这样可能会影响速度。
- 所以引入了TLB，即快表。该内容是针对于页表的缓存。每次要进行地质转换时，先去快表中访问，如果快表中没有，再去真正的页表中查找。

### 一个操作系统，有很多小文件会有什么弊端

- 首先就是元数据管理开销。因为每个文件都需要维护一些信息，比如说创建时间，文件大小等。这会浪费空间。
- 另外，文件的存储分配的是固定大小的磁盘块，如果太多的小文件，那么可能会导致大量的空间浪费。内部碎片。
- 读的性能下降。因为每次读文件，要发生磁盘I/O，这些小文件可能分布在磁盘的各个位置，导致访问速度变慢。因为每次都是随机I/O。

### 分页和分段的区别

- 分页（Paging）：分页是将物理内存划分为相同大小的页（page）。同样，进程的地址空间也被划分为相同大小的页。操作系统维护一个页表，用于映射进程的虚拟页到物理页。因为每个页的大小相同，所以可以避免内存碎片的问题。
  - 分页的一个优点在于，**程序运行时用到哪页就为哪页分配内存**，没用到的就暂时留在磁盘。只有用到的页才会为其建立虚拟地址到实际内存地址的映射。
- 分段（Segmentation）：分段是将进程的地址空间划分为多个逻辑单位，称为段（segment）。每个段代表程序的一个逻辑结构，如函数或数据结构。操作系统维护一个段表，用于映射进程的虚拟段到物理内存。但是，因为每个段的大小不同，所以可能会导致内存碎片的问题。
  - 分段的一个缺点就在于，每次要将整个进程全部移除。因为一个进程会获得一个完整的段。
  - 分段时，每个进程获得的地址空间都是连续的。

> 这里的内存碎片指的是外部碎片。而分页由于每一页大小一样，可能会存在内部碎片。

### 多级页表了解吗？

- 在多级页表中，页表被组织成一个树形结构，只有被使用的虚拟地址才会在页表中有对应的条目。这样，多级页表可以有效地处理稀疏的虚拟地址空间，减少内存浪费。
- 32位的虚拟地址空间下：每个页面4KB，且每条页表项占4B：
- **一级页表**：进程需要1M个页表项（4GB / 4KB = 1M, 2^20个页表项），即页表（每个进程都有一个页表）占用4MB（1M * 4B = 4MB）的内存空间。一级页表覆盖了整个4GB虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。
- 一级页表映射4MB（2^22）、二级页表映射4KB，则需要1K个一级页表项（4GB / 4MB = 1K, 2^10个一级页表项）、每个一级页表项对应1K个二级页表项（4MB / 4KB = 1K），这样页表占用4.004MB（1K * 4B + 1K * 1K * 4B = 4.004MB）的内存空间。
- 我们从页表的性质来看，保存在主存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有1M个页表项来映射，而二级页表则最少只需要1K个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。

新说法

- 早期的设计当中，操作系统是采用单页表，但是单页表也就意味着要为每个进程分配一个单独的页表，然后完整的维护该进程的虚拟空间到实际空间的映射，造成一定的资源浪费。（这里每张页表都会存储完整的映射，哪怕实际只用了一点点）。（因为该进程的页表是单独的，所以说它有可能需要4GB的虚拟空间，所以页表大小需要提前确定）
- 多级页表的基本思想是将**单级页表拆分为多个级别**，**每个级别只需要存储实际使用的部分，从而节省内存**。
- 总结一下，对于一个内存地址转换，其实就是这样三个步骤：
  - 把虚拟内存地址，切分成页号和偏移量；
  - 根据页号，从页表里面，查询对应的物理页号；
  - 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

> 注意：多级页表的情况下，仍然是每个进程一个页表。只不过在单页表的情况下，想要完整的映射4GB的空间，就是需要4MB的页表项，2^20个，占用4MB内存。
>
> 但是多级页表，一级页表只需要1024个页表项，然后每个页表项指向4MB的页表，就可以表示4GB的内存空间。而一级页表只占用4kb的空间。
>
> 新算法：
>
> 假设，只有1级页表，每个页表项其实是4b，这个是固定的，每个页的大小为4kb。那么想要映射4GB的虚拟内存，就需要4GB / 4KB = x个页表项，那么页表大小就是 x * 4b = 4MB。
>
> 那如果是多级页表呢？
>
> 一级页表只需要1024个页表项，每个大小为4b，一级页表共4kb。这1024个项，每一项可以指向一个4kb的页，这4kb的页一共可以有4kb / 4b = 1024个数据页，每个数据页大小4kb，一共可以映射4mb的内存。
>
> 那么就相当于1级页表每一项可以映射4mb，1024 * 4mb = 4GB，完美。
>
> 上边这个算法，其实是3级页表。每次访问，需要先走1级页表，然后走2级页表，2级页表指向具体的数据页。

### 页面置换算法

- 先进先出算法。最先进入的页面最先淘汰。算法很简单，但是可能淘汰访问比较多的页。
- 最近最久未使用算法。即LRU算法。当发生缺页中断时，将最近最久没有使用的页面淘汰。
- 最不常用算法。即LFU算法。发生缺页中断时，将最近使用次数最少的页面淘汰。

### Linux的管道（｜）和重定向

- 管道用于将一个命令的输出作为另一个命令的输入。 比如说command1 | command2 | command3 ...，就是将command1的输出作为了command2的输入。

- 重定向用于将命令的输出保存到文件中或将文件内容作为命令的输入。

### Linux的用户组与用户的概念，怎么创建用户和用户组？

- 用户是linux中的一个实体，每个用户都有一个唯一的用户名和uid。
  - 创建用户使用useradd命令
  - -m自动创建用户主目录
  - -s 指定用户初始登陆shell 
  - -g 指定用户的初始组
  - -G 指定用户的附加组
- 而用户组中包含了多个用户，方便对这一组用户进行权限方面的管理。
  - 创建命令为groupadd

# 框架

## spring

### spring涉及到的设计模式

- 工厂模式：BeanFactory
- 单例设计模式：bean默认为单例，线程池、日志对象
- 模板模式：AQS钩子函数(tryAcquire,tryRelease), 
- 观察者模式:Spring 事件驱动模型
- 适配器：适配器设计模式将一个接口转换成客户希望的另一个接口，适配器模式使得接口不兼容的那些类可以一起工作，其别名为包装器。在Spring MVC中，DispatcherServlet根据请求信息调用HandlerMapping，解析请求对应的Handler，解析到对应的Handler（也就是我们常说的Controller控制器）后，开始由HandlerAdapter适配器处理
- 装饰器模式：
- 策略模式
- 代理模式：aop动态代理

### Spring容器的启动过程

1. 首先会在容器中注册后置处理器组件，比如*AnnotationAwareAspectJAutoProxyCreator对象*
2. 初始化**BeanFactory**：首先，Spring会通过用户提供的配置信息（例如XML文件或者注解）来初始化一个**BeanFactory**，这个BeanFactory是Spring容器的核心，它负责创建和管理所有的Bean
3. 读取配置生成并注册BeanDefinition：通过**BeanDefinitionReader**将注解、xml或者其他文件的配置元信息转换解析成**BeanDefinition**的形成在内存中存在，并将**BeanDefinition**注册到**BeanDefinitionRegistry**中，在BeanDefinitionRegistry中是以concurrenthashmap<id, **BeanDefinition**>来存储**BeanDefinition**的
4. 实例化 BeanFactory：根据 BeanDefinitionRegistry 中的 BeanDefinition 信息，Spring 实例化一个 BeanFactory，通常是 DefaultListableBeanFactory。BeanFactory 负责管理 Bean 的创建和依赖注入
5. 容器初始化后处理BeanFactoryPostProcessor ：BeanFactoryPostProcessor是容器启动阶段Spring提供的一个扩展点，在Spring已经把相关的bean信息注册到注册到beanDefinationRegistry后，再次对beanDefination进行一定程度上的修改与替换，或者自定义bean。也就是说在bean的实例化之前对BeanDefination进行修改
6. 实例化Bean，依赖注入，初始化bean

### Bean的注入单例和原型

- 单例就是全局一个Bean，如果Bean是有状态的，就可能会有线程安全问题。
- Prototype就是原型，每次都会创建一个新的bean出来，即每次使用都会创建一个新的bean出来。

### spring出现两个名字相同的bean会怎么样

- 在之前的spring，就是基于xml配置bean时，如果出现两个相同的bean，运行时会报错。具体报错是在解析xml，并将对应对象转化为BeanDefinition时。

- 而sping3.0之后，基于@Configuration注解来注入bean时，当多个bean的name一样，只会注入第一个bean，到第二个bean时并不会去处理。

  > 注意，以下两点都是基于上边在bean定义时的结果，然后进行使用时会报错。

- 如果使用@Autowired进行注入，因为创建bean的阶段，只会创建第一个，所以在注入时，会报错第二个找不到。

- 如果使用@Resource，根据指定name进行注入，那么IOC容器中只会存在第一个bean，它会将第一个bean赋值给第二个，然后发生类型不匹配的错误。

### spring事务失效的场景

- **由于spring的事务是通过AOP代理来实现的**，而AOP的代理有两种实现方式，JDK动态代理或者CGlig 动态代理。
- jdk动态代理要求被代理类实现了某个接口，而CGLib动态代理要求被代理类能够继承。如果这两者都不满足，那么事务就会失效。
- 另外，如果对应的类没有交由spring容器管理，而是我们自己调用对应的方法，事务也不会生效。
- 此外，数据库的事务是基于数据库连接来实现的，也就是说多个线程的情况下会有多个数据库连接，事务也会失效。
- 如果业务本身捕获了异常，那么事务也会失效。即事务本身无法捕获到异常，或者说捕获了范围外的异常。
- 同一个类下，其他方法调用事务方法是不会生效的：事务基于AOP，实际上是通过一个代理对象调用方法，而内部方法调用事务方法是调用的原类的方法，不会生效

### spring aop怎么实现的

- 基于动态代理来实现的。
- 默认是基于JDK 的动态代理，要求被代理类实现某个接口。
- ~~因为jdk的动态代理需要被代理类继承一个Proxy类，Java是单继承的，不能够基于继承来实现。如果不要求实现同一个接口，那么就无法知道被代理类中有哪些方法。~~
- 在Java中，~~**只有接口才能实现多态性**~~，接口和继承是实现多态的两种方式，而多态性是动态代理的基础。如果一个类没有实现接口，那么它的方法调用就变成了静态绑定，即直接调用该类的方法，而不是通过代理对象进行调用。
- 如果一个类没有实现接口，那么它的所有方法都是静态绑定的。在这种情况下，无法通过动态代理实现AOP的效果，因为无法在运行时改变目标方法的调用行为。
- 

### 动态代理？jdk，cglib？

- jdk的动态代理需要**代理类实现了某个接口**，因为生成的代理类本身就要继承Proxy类，java又是单继承的。
- 而cglib则是基于继承的。如果被代理类是final修饰的，则无法使用该方案进行代理

### 怎么解决循环依赖的？

- spring 是依赖于三级缓存来解决的。

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/53d01bd371dd245df9feb9d3d2a7fc6e.png#pic_center)

- Bean的生命周期：实例化(构造函数)、属性注入，初始化、销毁

- **在实例化之后，属性注入之前会将singletonFactory注入到三级缓存中**

- 但是并不是所有的循环依赖都可以解决。如果说对应的bean是非单例模式，那么每次创建bean都用不到缓存，也就无法利用三级缓存来解决了。

- **而且构造函数循环依赖，也无法通过三级缓存解决。**因为两个bean的创建，都需要对方的实例，才能创建。即创建A，要通过构造函数，构造函数要传入一个B，而创建B，也是要通过构造函数，要传入A。

- 如果采用构造函数的注入方式，构造器注入要求在对象创建时将所有依赖对象通过构造函数传递。如果循环依赖，先创建A就需要拿到A所有的成员属性，而其中有一个B，又需要拿到A的实例，所以无法注入。

### 三级缓存只有两级可以吗？

- 其实，如果仅仅是普通对象的循环依赖，二级缓存就可以了。

- 一级缓存中存储的是生成完整的对象，而二级缓存中存储的是半成品，2级缓存存储的是被初始化了，但是还未进行属性填充的对象，可以拿来当作属性的注入，如果bean有AOP,二级缓存会存入代理对象，同时从三级缓存的Beanfactory中获取bean，如果该bean有AOP增强，该Beanfactory就会对bean进行增强（如果没有循环依赖，正常的AOP是在Bean的初始化后进行增强）每次获取的代理对象都不样，因此需要二级缓存保存唯一的对象。

- 而三级缓存好像是存储工厂，它是为了应对那种特殊情况，比如说带有AOP这种循环依赖。

- 重点：在没有循环依赖的情况下，**普通AOP代理对象的生成依赖完整的实例对象**，但如果有循环依赖，原来的AOP会将复用二级缓存的代理实例，如果现在：

- ```java
  @Service
   publicclass TestService1 {
      @Autowired
      private TestService2 testService2;
      @Async
      public void test1() {
      }
   }
   @Service
   publicclass TestService2 {
      @Autowired
      private TestService1 testService1;
      public void test2() {
      }
   }
  ```

  TestService1本身又AOP代理，在它创建过程中循环依赖了TestService2，TestService2会在三级缓存中使用TestService1的beanFactory创建一个代理bean，但是由于这里的@Async还依赖TaskExecutor， TaskExecutor是在TestService1初始化创建的，这样造成了**(TestService1依赖TestService2 -> TestService1去创建TestService2->TestService2依赖TestService1 -> TestService2使用beanFactory创建TestService1的代理类-> TestService1的代理类依赖TaskExecutor->TaskExecutor依赖TestService1**)而放到二级缓存中，然后到TestService1依赖注入并初始化后，就会进行原本代理类的生成，这回导致二级缓存中的代理类和当前代理类不一致，会抛出异常

### IoC，AOP，DI，讲讲理解，分别是什么？

- IoC，控制翻转，它的实现依赖于DI，即依赖注入。说白了，就是将对象的创建，初始化，生命周期和对象间的关系都交给spring容器去管理。
- 假设，我们之前自己创建对象的时候，我们创建一个对象A，它依赖于一个对象B，那么我们必须先创建对象B，然后在创建A时将其作为参数传递给A。有了控制反转之后，我们并不需要关心对象A需要依赖什么，直接使用就行了。创建对象A以及注入它需要的属性都由spring 容器去管理了。
- 而AOP是面向切面编程，可以在不改变原先代码的情况下，在它的前或者后边填上一些新的业务逻辑。

### bean初始化流程？

流程大致如下：

1. ~~首先就是要获取到所有需要配置的bean，然后为每个Bean构建一个BeanDefinition，并设置BeanDefinition的属性，然后注册该BeanDefinition（应该是存在一个Map当中），注入到BeanDefinitionRegistry。（该阶段也是spring容器启动阶段所做的事）~~
2. ~~第一步只是注册了bean，接下来就该bean的实例化。实例化时设计到一个核心方法`refresh()`，这里有三个核心步骤，bean的实例化（执行完这一步之后，Bean 已经被创建了，但还不完整，因为属性还没有被注入。），以及属性的填充（这一步执行完后，Bean其实就已经完整了，注入方法包括：byName、byType 类型的自动装配，以及基于 @Autowired、@Value 注解的属性设值），~~

<img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/95dfa5f7f41ef8ca734982df36cb7d5c.png" alt="img" style="zoom:50%;" />

<img src="https://image-1314238346.cos.ap-chongqing.myqcloud.com/29161e0abda355013883595de2ef8dc4.png" alt="img" style="zoom:50%;" />

1. 加载bean的配置文件，比如说xml，或者通过类配置的bean，或者注解配置的bean。
2. 根据bean的属性，构建对应的BeanDefinition属性，包含了Bean的一些元数据。这个BeanDefinition会被注册到一个Map当中。
3. 在实例化bean之前，如果类有实现BeanPostProcessor 接口的postProcessBeforeInstantiation()（使用非标准方式创建bean，比如代理）**,那么我们会绕过默认的创建bean的流程，跳过初始化(除了postProcessAfterInitialization方法)**
4. 实例化bean。这一步是通过反射去创建一个bean，但是并不会对bean当中的属性进行注入。
5. 依赖注入，这一步其实就是处理bean之间的依赖关系，设置bean当中的具体属性。这一步主要是注入bean所需要的对象。
6. 调用Aware接口。如果我们实现了对应的aware接口，就会调用。`Aware` 接口的核心作用是让 Bean 能够访问和感知 Spring 容器的基础设施（比如ApplicationContext）
7. `BeanPostProcessor` 的 `postProcessBeforeInitialization`。这一步就是创建bean的一个前置方法，用于我们自定义创建bean，比如说@Autowire等注解以及切面编程就可以在这里实现
8. 初始化bean（包括@PostContruct、@PreDestroy注解标记的方法和在@Bean注解中init-method设置的方法）
9. `BeanPostProcessor` 的 `postProcessAfterInitialization`。这一步是初始化bean的一个后置方法。
10. 将初始化的bean放入容器当中，这时候就可以使用了，对应的是放入一级缓存，可以直接使用。

### Bean的实例化、依赖注入、初始化、有什么区别？

- 首先，bean的实例化，它是根据beanDefinition，利用反射来构建一个Bean的实例，此时Bean内不的成员属性还没有填充。
- 而依赖注入，则是注入该bean的成员属性。
- 而初始化，则是调用用户自定义的一些对于bean的初始化的方法。比如说用户实现了`InitializingBean`接口并实现了`afterPropertiesSet`。
  - 其实看下面那张图，不难发现整个bean的实例化过程其实是分了很多步骤的，显示bean的前置处理，然后才是上边提到的`InitializingBean`，然后是自定义内容，然后是后置处理，整个初始化的流程就结束了

### bean生命周期？

![img](https://image-1314238346.cos.ap-chongqing.myqcloud.com/1704860a4de235aa~tplv-t2oaga2asx-jj-mark:3024:0:0:0:q75.awebp)

### BeanPostProcessor的执行顺序

- 实现PriorityOrdered、Ordered、以及没有实现排序接口的优先级依次降低

### spring和springboot的区别？为什么要基于spring再封装出springboot？

springboot是基于spring封装的，内置了一些spring以及它的一些依赖，包括内置web容器。它采用约定大于配置的形式。简化开发。

- springboot 主要是为了简化spring 的配置。

- 内置了tomcat，启动更加简单。
- 它封装了spring各个兼容版本依赖库。

### @autowired和@resource的区别？

@Resource有两个属性name和type。Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不指定name也不指定type属性，这时将通过反射机制使用**byName自动注入策略**。

@Autowired只根据type进行注入，不会去匹配name。如果涉及到type无法辨别注入对象时，那需要依赖@Qualifier或@Primary注解一起来修饰。

> @Resource默认是按照name进行注入的，可以指定按照name还是按照类型。
>
> 而@Autowired只能根据type进行注入。

### @autowired的原理

- 首先明确是@autowired是用来进行**依赖注入**的，再bean的生命周期中，**普通的BeanPostProcessor**是在bean的依赖注入后执行的
- 但`AutowiredAnnotationBeanPostProcessor`是在依赖注入前执行

### Bean生命周期中的aware接口是干嘛的

- aware接口本身并不具备任何功能性，即单纯实现aware接口没有什么作用。
- 它是用来标注的，指示 bean 是具有被 Spring 容器通知的能力，通知的方式是采用回调的方式。Aware 接口是一个空接口，具体的实现由各个子接口决定，**仅实现Aware接口，不会提供任何默认功能，需要明确的指定实现哪个子接口**。
- 当一个 Bean 实现了某个 Aware 接口，Spring 容器在创建这个 Bean 的时候，会自动检测到这个 Bean 是否实现了 Aware 接口，如果实现了，Spring 就会在适当的时候调用 Aware 接口中的方法，从而向 Bean 提供所需要的资源。

> Aware 接口的主要作用就是以一种非侵入的方式，让 Bean 在创建时能够获取到更多的信息或者资源。通过实现特定的 Aware 接口，Bean 可以在创建时获取到例如 Spring 容器（通过 BeanFactoryAware 或 ApplicationContextAware）、资源加载器（通过 ResourceLoaderAware）、Bean 的名字（通过 BeanNameAware）等信息
>
> ```java
> @Component
> public class MyAwareBean implements BeanNameAware, ApplicationContextAware, ResourceLoaderAware {
> 
>     private String beanName;
>     private ApplicationContext applicationContext;
>     private ResourceLoader resourceLoader;
> 
>     // BeanNameAware 实现
>     @Override
>     public void setBeanName(String name) {
>         this.beanName = name;
>         System.out.println("BeanName 设置为: " + beanName);
>     }
> 
>     // ApplicationContextAware 实现
>     @Override
>     public void setApplicationContext(ApplicationContext context) throws BeansException {
>         this.applicationContext = context;
>         System.out.println("ApplicationContext 已注入");
>     }
> 
>     // ResourceLoaderAware 实现
>     @Override
>     public void setResourceLoader(ResourceLoader loader) {
>         this.resourceLoader = loader;
>         System.out.println("ResourceLoader 已注入");
>     }
> 
>     // 使用注入的资源
>     public void doSomething() {
>         // 使用 BeanName
>         System.out.println("当前 Bean 名称: " + beanName);
> 
>         // 使用 ApplicationContext 获取其他 Bean
>         UserService userService = applicationContext.getBean(UserService.class);
>         userService.sayHello();
> 
>         // 使用 ResourceLoader 加载资源
>         try {
>             var resource = resourceLoader.getResource("classpath:config.properties");
>             System.out.println("加载资源: " + resource.getURL());
>         } catch (Exception e) {
>             e.printStackTrace();
>         }
>     }
> }
> 
> 
> //解释(重要)：
> //我们的类实现了Aware接口中的setXxxx()方法，那么在bean生命周期的Aware阶段会对bean类型进行判断并调用对应的setXxxx()方法，注入对应的资源
> //
> ```
>
> 

### 用注解声明式事务，默认采用的是什么事务管理器

- 默认的应该和我们使用的数据库驱动有关吧。

- JPA的话使用的是`JpaTransactionManager`

- JDBC的话使用的是`DataSourceTransactionManager`

- spring的配置文件中也可以进行配置。

  ```xml
  <bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
      <property name="dataSource" ref="dataSource" />
  </bean>
  
  <tx:annotation-driven transaction-manager="transactionManager" />
  ```

### Spring事务的流程(AOP的流程)

- 1.AOP 动态代理装配流程：advice=接入点+通知(@pointcut+@aroud)
- ![image-20250923165800888](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250923165800888.png)
- 2.AOP 动态代理执行流程
- ![image-20250923170013466](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250923170013466.png)
- 3.事务执行流程
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250923170214462.png" alt="image-20250923170214462" style="zoom: 50%;" />
- 

### Spring事务流程AI版

- ### **阶段一：Spring 容器启动初始化（启动时）**

  #### 1. 解析事务配置

  - Spring 启动时，扫描并解析事务相关配置：
    - 若使用`@EnableTransactionManagement`注解，会通过`TransactionManagementConfigurationSelector`导入事务管理的核心配置类（`ProxyTransactionManagementConfiguration`）。
    - 若使用 XML 配置，则解析`<tx:annotation-driven/>`等标签，注册对应的 Bean 定义。

  #### 2. 注册核心事务组件

  - **`TransactionAttributeSource`**：注册`AnnotationTransactionAttributeSource`实例，用于后续从`@Transactional`注解中提取事务属性（传播行为、隔离级别等）。
  - **`TransactionInterceptor`**：注册事务拦截器实例，注入`TransactionManager`（如`DataSourceTransactionManager`）和`TransactionAttributeSource`依赖。
  - **`BeanFactoryTransactionAttributeSourceAdvisor`**：注册事务通知器，将`TransactionInterceptor`（Advice）与事务切入点（`TransactionAttributeSourcePointcut`）关联，用于匹配需要事务增强的方法。

  #### 3. 生成代理对象

  - Spring 容器初始化 Bean 时，`AbstractAutoProxyCreator`（AOP 自动代理创建器）会检查 Bean 的方法是否被事务切入点匹配（即是否有`@Transactional`注解）。
  - 若匹配，通过 JDK 动态代理或 CGLIB 生成代理对象，代理对象会拦截目标方法的调用，转发给`TransactionInterceptor`处理。

  ### **阶段二：业务方法调用（运行时）**

  #### 4. 代理对象拦截方法调用

  - 当业务代码调用被`@Transactional`标注的方法时，实际调用的是代理对象的方法，代理对象将调用转发给`TransactionInterceptor`的`invoke`方法。

  #### 5. 提取事务属性

  - ```
    TransactionInterceptor
    ```

    通过

    ```
    TransactionAttributeSource
    ```

    获取目标方法的

    ```
    TransactionAttribute
    ```

    ：

    - `AnnotationTransactionAttributeSource`扫描目标方法和类上的`@Transactional`注解，解析出传播行为、隔离级别、超时时间等属性，封装为`TransactionAttribute`对象。
    - 若没有事务配置，`TransactionAttribute`为`null`，直接执行目标方法（无事务）。

  #### 6. 确定事务管理器

  - `TransactionInterceptor`根据`TransactionAttribute`（或默认配置）确定使用的`PlatformTransactionManager`（如`DataSourceTransactionManager`）。

  ### **阶段三：事务执行（运行时）**

  #### 7. 开启事务

  - ```
    TransactionManager
    ```

    根据

    ```
    TransactionAttribute
    ```

    开启事务：

    - 从`DataSource`获取数据库连接（`Connection`），并将`autoCommit`设为`false`（禁用自动提交）。
    - 根据隔离级别设置连接的隔离级别（如`conn.setTransactionIsolation(TransactionDefinition.ISOLATION_READ_COMMITTED)`）。
    - 创建`TransactionStatus`对象，记录事务状态（是否为新事务、是否标记回滚等），并通过`ThreadLocal`将连接绑定到当前线程（确保同一事务内使用同一连接）。

  #### 8. 执行目标方法

  - `TransactionInterceptor`调用`invocation.proceed()`，执行目标业务方法（如 Service 层的`createOrder()`）。
  - 方法内的所有数据库操作（如 MyBatis 的`insert`、JDBC 的`update`）均使用步骤 7 中绑定的连接，操作暂未提交到数据库。

  #### 9. 事务提交或回滚

  - **无异常**：若目标方法正常执行（或仅抛出`noRollbackFor`配置的异常），`TransactionManager`调用连接的`commit()`方法，提交所有操作，持久化到数据库。
  - **有异常**：若目标方法抛出`rollbackFor`配置的异常（如`RuntimeException`），`TransactionManager`调用连接的`rollback()`方法，撤销所有操作。

  #### 10. 清理资源

  - 无论提交或回滚，都会释放数据库连接（归还到连接池），并从`ThreadLocal`中移除线程绑定的连接，避免资源泄漏。



### InvocationHandler和TransactionInterceptor关系是什么

- 事实上，我们知道在我们自己去实现一个动态代理时会去实现一个InvocationHandler接口，代理对象执行增强方法时会调用InvocationHanlder的invoke方法，那么在Invoke方法中又会将拦截链传给ReflectiveMethodInvocation实例，并调用proceed方法

- ```java
  // Spring内部的JDK代理处理器（简化版）
  class JdkDynamicAopProxy implements InvocationHandler {
      // 持有Spring AOP的拦截器链（包含TransactionInterceptor）
      private List<Object> interceptors;
      // 持有原始目标对象（如OrderService）
      private Object target;
  
      @Override
      public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
          // 1. 创建Spring AOP的方法调用器（封装代理、目标对象、方法、参数、拦截器链）
          MethodInvocation invocation = new ReflectiveMethodInvocation(
              proxy, target, method, args, interceptors
          );
          // 2. 执行拦截器链（核心：将JDK代理的invoke，转发给Spring的拦截器链）
          return invocation.proceed();
      }
  }
  
  ```

- proceed()其实是去递归执行(责任链)，去执行拦截链

- ```java
  public class ReflectiveMethodInvocation implements MethodInvocation {
      private int currentInterceptorIndex = -1; // 当前执行到的通知索引
      private List<Object> interceptorsAndDynamicMethodMatchers; // 通知链
      private Method method; // 目标方法
      private Object target; // 目标对象
  
      @Override
      public Object proceed() throws Throwable {
          // 1. 若所有通知都执行完，调用目标方法
          if (currentInterceptorIndex == interceptorsAndDynamicMethodMatchers.size() - 1) {
              return method.invoke(target, arguments); // 执行原始业务逻辑
          }
  
          // 2. 获取下一个要执行的通知（Interceptor）
          Object interceptor = interceptorsAndDynamicMethodMatchers.get(++currentInterceptorIndex);
  
          // 3. 执行通知逻辑（以Around通知为例）
          if (interceptor instanceof MethodInterceptor) {
              MethodInterceptor mi = (MethodInterceptor) interceptor;
              // 调用通知的invoke方法，将自身（MethodInvocation）传入
              return mi.invoke(this); 
          } else {
              // 其他类型通知（如Before/After）的处理逻辑
              return proceed();
          }
      }
  }
  ```

### 拦截链到底是什么？是Adivisor还是Interceptor

- **拦截链（Interceptor Chain）是由`Interceptor`（拦截器）组成的**，但这些`Interceptor`来源于`Advisor`（通知器）中的`Advice`（通知）

### 拦截链（Interceptor Chain）的构成过程

拦截链的形成是 “从`Advisor`中提取`Advice`，再将`Advice`转换为`Interceptor`” 的过程，具体步骤如下：

1. **收集匹配的`Advisor`**当为目标 Bean 生成代理对象时，Spring 会遍历容器中所有`Advisor`，通过`Pointcut`匹配筛选出与目标方法相关的`Advisor`（例如`BeanFactoryTransactionAttributeSourceAdvisor`若匹配，则被选中）。
2. **将`Advisor`中的`Advice`转换为`Interceptor`**每个`Advisor`都包含一个`Advice`，Spring 会将`Advice`统一包装为`MethodInterceptor`（拦截器接口），例如：
   - `TransactionInterceptor`本身就是`MethodInterceptor`的实现类，可直接作为拦截器；
   - `@Before`注解的`Advice`会被包装为`MethodBeforeAdviceInterceptor`（实现`MethodInterceptor`）；
   - `@After`注解的`Advice`会被包装为`AfterAdviceInterceptor`（实现`MethodInterceptor`）。
3. **组成拦截链**所有转换后的`MethodInterceptor`按优先级排序，形成 “拦截链”（`List<MethodInterceptor>`）

### TransactionInterceptor和BeanFactoryTransactionAttributeSourceAdvisor都会注入TransactionAttributeSource依赖吗

- `TransactionInterceptor`才知道如何控制事务（开启、提交、回滚的规则）；
- `BeanFactoryTransactionAttributeSourceAdvisor`才知道哪些方法需要被事务增强（通过切入点匹配）。

### AOP如果定义了多个切入点表达式，怎么保证执行的顺序

- 有一个属性，order，它可以指定对应的值，该值越小，优先级越高。我们可以根据我们想要的顺序来给值。

### 事务

事务传播：

**`TransactionDefinition.PROPAGATION_REQUIRED`**：（一个事务，事务合并）

![image-20250302220516431](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250302220516431.png)

**`TransactionDefinition.PROPAGATION_REQUIRES_NEW`**（独立事务）

![image-20250302220754379](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250302220754379.png)

但是内部方法抛出一个**未被捕获**的异常满足回滚的规则，那么外部和内部方法都会回滚，因为内部方法抛出的异常被外部方法的事务检测到了

**`TransactionDefinition.PROPAGATION_NESTED`**（嵌套事务）

内层被调用方法回滚与否，不会影响外层调用方法。而外层调用方法出异常回滚，也会回滚内层被调用方法（嵌套事务）。外层调用方法提交时内层调用方法才提交

**`TransactionDefinition.PROPAGATION_MANDATORY`**

![image-20250302223208880](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250302223208880.png)

### SpringMVC 请求处理流程

1. **请求到达 DispatcherServlet**：前端控制器接收请求。
2. **HandlerMapping 映射**：根据请求 URL 找到对应的 Handler（Controller 方法）。
3. **HandlerAdapter 适配**：调用 Handler 前的准备工作（如参数绑定）。
4. **执行 Handler**：调用目标 Controller 方法，返回 ModelAndView。
5. **ViewResolver 解析**：将逻辑视图名解析为物理视图（如 JSP）。
6. **渲染视图**：将模型数据填充到视图，返回响应。

## springboot

### springboot 的自动配置原理？

- 这里首先得益于@SpringBootApplication注解，它里边还有几个注解，@EnableAutoConfiguration就是关键。
- @EnableAutoConfiguration这个注解告诉 Spring Boot 基于类路径中的 jar 依赖、定义的 beans 和各种属性设置来“猜测”并配置 beans。Spring Boot 会自动配置那些你没有显式配置的组件。

### springboot快速启动的原理？

- 自动配置
- 引入不同的Starter，可以快速集成常用的框架和库，极大地提高了开发效率
- 默认集成了多种内嵌服务器（Tomcat）
- 约定优于配置

### Springboot中starter的作用是什么

- Spring Boot Starter 是一组预定义的依赖项集合，它们**可以帮助开发者快速集成各种功能模块，例如Web 应用程序、数据库访问、消息队列等**。 这些Starter 可以减少开发者的配置工作。
- 当添加了对应的starter，springboot 会自动配置相关的bean和默认配置。

### 有哪些注解可以用来声明一个bean

- **@Component**：这是最基本的注解，用于定义一个 Bean。Spring 会自动扫描并加载带有 @Component 注解的类。
- **@Service**：这是 @Component 的特化形式，用于标记提供业务逻辑的类。虽然它本质上和 @Component 是一样的，但使用 @Service 可以更清晰地表明类的用途。
- **@Repository**：这也是 @Component 的特化形式，用于标记数据访问组件，即 DAO 组件。
- **@Controller**：这也是 @Component 的特化形式，用于标记控制器组件，在 Spring MVC 中使用。
- **@Configuration**：用于定义配置类，可替代 XML 配置文件。配置类可以包含带有 @Bean 注解的方法，这些方法会被 Spring 容器调用并注册返回的对象为 Spring Bean。
- **@Bean**：这个注解用于标记一个方法，该方法返回一个需要注册为 Spring Bean 的对象。这个注解通常用在 @Configuration 注解的类中。

### @bean和@component注解有什么区别

- component是一个最基本的注解，可以定义一个bean。其他的注解都是基于它的。只不过带有了一些约定的含义。
- @bean就是用于标记一个方法，该方法通常返回一个需要注册为bean的对象。该注解需要在@Configuration标记的类中使用。

### Springboot加载配置有哪些方式？

- SpringBoot 项目在启用时，首先会默认加载**bootstrap.properties**或者**bootstrap.yml**这两个配置文件(这两个优先级最高);接着会加载**application.properties**或**application.yml**;
- 如果何配置了spring.profiles这个变量，同时还会加载对应的application-{profile}.properties或者application-{profile}.yml文件
- **命令行参数**：你可以在启动 Spring Boot 应用时通过命令行参数的方式来提供配置信息。
- **@Configuration 类**也可以做一些配置信息。

### springboot中的bean是线程安全的吗

- spring 容器中的bean，本身并不是线程安全的。因为容器没有提供对应的保证。
- 但是如果bean的作用域为**prototype**，即每次都会创建一个新的bean，那么就不存在线程安全问题。
  - 默认的作用域是单例，即singleton，所有线程共用一个bean，肯定不安全。

- 另外，无状态的bean是线程安全的。
- 有状态就是有数据存储功能，无状态就是不会保存数据。

### springboot是怎么简化配置的？(自动装配)

- Starter简化了这些繁琐的配置，遵循Spring Boot“约定大约配置”的理念，在我们不主动进行配置时给予默认的属性，而且很多情况下这些属性都不需要更改。**如何实现的呢？**

- SpringApplication这个类，也就是启动类上有一个@SpringApplication的注解，该注解是由@SpringBootConfiguration, @EnableAutoConfiguration, @ComponentScan这三个注解组合而成。

- 在@EnableAutoConfiguration中有个注解@Import可以看到该注解导入了一个AutoConfigurationImportSelector的类。

- ```java
  @Import({AutoConfigurationImportSelector.class})
  ```

- AutoConfigurationImportSelector类有实现ImportSelector类及其类中的selectImports方法

- ```java
  public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered {
  
  }
  public interface DeferredImportSelector extends ImportSelector {
  
  }
  
  public interface ImportSelector {
      String[] selectImports(AnnotationMetadata var1);
  }
  ```

- 在selectImports方法中有：

- ```java
  public String[] selectImports(AnnotationMetadata annotationMetadata) {
          if (!this.isEnabled(annotationMetadata)) {
              return NO_IMPORTS;
          } else {
              AutoConfigurationEntry autoConfigurationEntry = this.getAutoConfigurationEntry(annotationMetadata);//核心方法，按需加载META-INFO/spring-factories的自动装配类
              return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());
          }
      }
  
  //this.getAutoConfigurationEntry()方法
  protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) {
      //判断是否开启了自动装配，默认开启
          if (!this.isEnabled(annotationMetadata)) {
              return EMPTY_ENTRY;
          } else {
              //用于获取EnableAutoConfiguration注解中的 exclude 和 excludeName。
              AnnotationAttributes attributes = this.getAttributes(annotationMetadata);
              //获取spring-factories的自动装配类
              List<String> configurations = this.getCandidateConfigurations(annotationMetadata, attributes);
              //去重，通过LinekHashSet
              configurations = this.removeDuplicates(configurations);
              //去除注解上的exclude
              Set<String> exclusions = this.getExclusions(annotationMetadata, attributes);
              this.checkExcludedClasses(configurations, exclusions);
              configurations.removeAll(exclusions);
              //根据自动配置类上的条件注解进行过滤：@ConditionalOnBean，@ConditionalOnClass
              configurations = this.getConfigurationClassFilter().filter(configurations);
              this.fireAutoConfigurationImportEvents(configurations, exclusions);
              return new AutoConfigurationEntry(configurations, exclusions);
          }
      }
  
  ```

- 深入去看源码会发现，spring会从包的类"META-INF/spring.factories"中读取需要自动配置的类，从而实现springboot的自动配置。

- springboot 会有一个autoconfigure包，里边有一个spring.factories的文件，里面配置了很多默认加载的类，就按默认的配置。

- 如果里边没有，那么可能要第三方包自己去提供这个spring.factories。比如Mybatis。

> 用自己的话来说，就是@EnableAutoConfiguration注解中，有一个方法selectImport，它会扫描所有jar包下的META/INF下的spring.factories文件。这些都是提前写死的。这也就是为什么约定大于配置。优先采用默认的方式进行加载。springboot 自己有一个autoconfigure包，里边的spring.factories配置了特别多的内容。如果没有配置，则需要对应包自己提供。
>
> 对应的包下面有很多已经进行了默认配置的@Configuration类。
>
> 通过该方式拿到需要自动注入的类，然后去对应的路径去看是否有对应的包，如果有就进行注入，如果没有就不管。@Configuration注解将对应的bean注入容器。
>
> 这是一种spi机制。springboot自动装配和属于一方，具体的接口实现者属于另一方。



### Spring Stater自定义实现

1. 自定义配置类

   ```java
   @Configuration
   public class ThreadPoolAutoConfiguration {
       @Bean
       @ConditionalOnClass(ThreadPoolExecutor.class)
       public ThreadPoolExecutor myTheadPool(){
           return new ThreadPoolExecutor(10, 10, 10, TimeUnit.SECONDS, new ArrayBlockingQueue<>(10));
       }
   }
   ```

   

2. 在resources新建META-INF/spring.factories文件

   ```java
   org.springframework.autconfigure.EnableAutoConfigration = /
   org.example.ThreadPoolAutoConfiguration
   ```

   

## Spring Cloud

### **什么是正向代理和反向代理？**

- 正向代理是代理服务器代替系统内部来访问外部网络的过程，反向代理是外部请求访问系统时通过代理服务器转发到内部服务器的过程

### Spring gateway原理(断言、路由、过滤器)

- 请求到达gateway服务端后，内部的netty会将请求包装成一个serverwebExchange
- 然后再通过dispatcherHandler，遍历所有的路由，然后匹配路由的断言，找到第一个符合条件的路由，返回一个对应的filterwebHandler
- 然后再通过filterwabHandler去进行一系列的filter操作，例如一些：认证和授权
- filter需要有实现了GlobalFilter 以及 GatewayFilter

### Nginx和Gateway

- Nginx是通过域名(IP)或者请求资源路径进行负载均衡和转发:

- **Nginx通过域名负载均衡或转发**，换句话说：此时，**Nginx是在域名的层次上进行负载均衡**

- ```java
  # 监听 80 端口，处理 HTTP 请求
  server {
      listen 80;
      # 匹配域名 api.example.com
      server_name api.example.com;
  
      # 所有请求转发到后端 API 服务集群
      location / {
          proxy_pass http://api_servers; # 转发到 upstream 定义的集群
          proxy_set_header Host $host; # 传递原始 Host 头
      }
  }
  
  server {
      listen 80;
      # 匹配域名 static.example.com
      server_name static.example.com;
  
      # 静态资源目录（直接返回服务器上的文件）
      location / {
          root /usr/share/nginx/static; # 静态资源存放路径
          index index.html;
      }
  }
  
  # 定义后端 API 服务集群（供上面的 proxy_pass 使用）
  upstream api_servers {
      server 192.168.1.10:8080;
      server 192.168.1.11:8080;
  }
  ```

- Nginx通过请求资源路径进行负载均衡和转发:

- ```java
  server {
      listen 80;
      server_name example.com;
  
      # 路径以 /api/ 开头的请求，转发到 API 服务
      location /api/ {
          proxy_pass http://api_cluster;
      }
  
      # 路径以 /admin/ 开头的请求，转发到管理后台服务
      location /admin/ {
          proxy_pass http://admin_server:8081;
      }
  
      # 其他所有路径，返回静态资源
      location / {
          root /usr/share/nginx/html;
          index index.html;
      }
  }
  # 1. 定义 API 服务集群（上游服务器）
  upstream api_cluster {
      # 集群节点列表（IP:端口 或 域名:端口）
      server 192.168.1.100:8080;  # 节点1
      server 192.168.1.101:8080;  # 节点2
      server 192.168.1.102:8080;  # 节点3
  
      # 可选：配置负载均衡策略（默认是轮询）
      # weight=2 表示权重，数值越大被分配的请求越多
      # server 192.168.1.100:8080 weight=2;
      
      # 可选：IP哈希（同一客户端IP始终转发到同一节点，解决会话保持问题）
      # ip_hash;
      
      # 可选：健康检查（超时/失败后标记节点为不可用）
      keepalive 32;  # 长连接保持数量
      max_fails 3;   # 最大失败次数
      fail_timeout 30s;  # 失败后标记为不可用的时间
  }
  ```

- Gateway支持动态路由,根据路由规则将请求转发到同名微服务的不同服务机

- Nginx是传输层，Gateway是应用层

### Feigh的原理

- feigh=ribbon(负载均衡)+hystrix(服务熔断)
- 开发者通过**注解**定义一个接口，声明需要调用的远程服务的信息
- 当 Spring 容器启动时，Feign 会扫描带有 `@FeignClient` 注解的接口。为每个接口创建一个**动态代理对象**（通过 JDK 动态代理实现）。这个代理对象会被注入到 Spring 容器中，开发者可以像使用普通 Bean 一样注入并调用其方法
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250924161953622.png" alt="image-20250924161953622" style="zoom:50%;" />
- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250924162034777.png" alt="image-20250924162034777" style="zoom: 50%;" />

### Ribbon有哪些负载均衡策略

- 轮询
- 响应时间权重策略：先使用轮询的方式获取每个服务的响应时间，响应时间越小，权重越大，然后给服务赋值一个权重
- 随机策略
- 最小连接数策略：遍历服务提供者列表，选取连接数最小的服务实例。ribbon内部会对每个实例维护他的连接数(正在处理的请求数)计数器，比如，给了一个实例一个请求，计数器加一；完成一个请求，计数器减一。
- 区域敏感策略

### RPC的零呼损

分为rpc客户端和rpc服务端

- rpc客户端：重试
- rpc服务端：优雅启停
- 优雅启动：：在没有提供服务之前先不将自己注册到注册中心，还包括JVM的预热
- 优雅停止：下线前通知注册中心，注册中心将服务从列表中除去，然后隔一段时间再关闭服务

### JVM预热

原因：java采用即时编译的方式：将class文件编译成机器码

- 流量预热：通过限流的方式将小部分流量转发给刚启动的服务，以进行预热
- 使用测试工具遍历访问接口

### 分布式事务

概念：一个业务操作跨多个微服务的服务和数据，分布式事务就是这一系列操作一起成功或者一起失败

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250511160813250.png" alt="image-20250511160813250" style="zoom:50%;" />

CAP理论：C表示一致性；不同用户看到的数据是一样的；A表示可用性：表示总有数据副本可以访问；P表示容错性：表示允许网络故障。在CAP理论中，**一致性和可用性是相冲突的**：一致性需要不访问未同步完成的节点，失去部分的可用性；可用性允许所有节点数据都可以访问，但数据可能不一致

base理论：基本可用、软状态和最终一致性。基本可用：在出现故障时，保证核心可用，允许丢失部分可用性；

软状态：允许系统中数据存在中间状态，也就是在同步不同的服务的数据时允许有时延；最终一致性：在经过一段时间同步后，最终达到一致的状态



#### XA协议(刚性事务/cp)

强一致性：2pc、3pc

#### 两阶段提交：

- 第一阶段：提交事务请求。
  - 1. 事务询问。**协调者向所有参与者发送事务内容，询问是否可以执行提交操作**，并开始等待各参与者 进行响应； 
    2. 执行事务。**各参与者节点，执行事务操作，但并不提交**，并将Undo和Redo操作计入本机事务日志； 
    3. **各参与者向协调者反馈事务问询的响应**。成功执行返回Yes，否则返回No。
- 第二阶段：执行事务提交，或者执行中断事务。
  - 所有参与者reply Yes，那么执行事务提交。
  - 事情总会出现意外，当存在某一参与者向协调者发送No响应，或者等待超时。协调者只要无法收到所 有参与者的Yes响应，就会中断事务。（协调者发生回滚请求）

#### 三阶段提交：

3PC 协议将 2PC 协议的准备阶段一分为二，从而形成了三个阶段

- 第一阶段：CanCommit
  - 1. 事务询问。协调者向所有参与者发送包含事务内容的canCommit的请求，询问是否可以执行事务提交，并等待应答；
  -  2. 各参与者反馈事务询问。正常情况下，如果参与者认为可以顺利执行事务，则返回Yes，否则返回 No。
- 第二阶段：PreCommit
  - 在本阶段，协调者会根据上一阶段的反馈情况来决定是否可以执行事务的PreCommit操作。有以下两种 可能： 执行事务预提交或者中断事务
- 第三阶段：Do Commit
  - 在这个阶段，会真正的进行事务提交，同样存在两种可能。执行提交或者回滚事务，如果参与者无法及时收到来自协调者的信息，**他会默认执行commit**

#### 3pc相对于2pc提升了什么

- 3pc中的事务管理者和事务参与者都有设置等待时间，2pc只有事务管理者有设置等待时间
- 3pc的事务参与者的等待时间内没有收到事务管理者的指令，**会自己判断是否进行事务提交**，而不是事务挂起
- 但是由于3pc中事务参与者在等待时间过后可能自己决定是否提交事务，**这可能导致数据的不一致**

#### 柔性事务(base理论/ap)

- 补偿型和通知型
- 补偿型:TCC、Saga
- 通知型：MQ事务消息、最大努力通知型

#### 通知型异步

主流使用MQ通知其他事务参与者自己的事务的执行状态:解耦、异步；适合实时性要求低的场景

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250511205753522.png" alt="image-20250511205753522" style="zoom: 33%;" />



- #### 异步确保型(适合内部系统)

- 由两种方案都使用mq来进行投递消息，消费方要编写监听器来监听队列来进行消息。~~消费可能会重复消费问题，消费端需要有幂等性方案~~，因而适合内部系统

  - ##### MQ事务消息方案[RocektMQ怎么处理分布式事务？](#RocektMQ怎么处理分布式事务？)
    
    - RocketMQ的事务半消息
  - ##### 本地消息表方案
    
    - 业务数据和本地消息表在同一服务上
    - <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250511214518267.png" alt="image-20250511214518267" style="zoom:25%;" />
    - 思考：由谁去更新消息表的状态？答：可能是消费者在执行玩本地事务后主动发送消息到mq然后更新消息状态；同时兜底方案：使用定时任务线程，其在定时扫描消息表将未投递的消息再次投递到mq中，并更新消息状态
    - **这张图有错误**：不能让消费者去更新消息表，因为消息表是属于生产者的，应该有生产者或者定时任务去更新消息表

- #### 最大努力通知型(适合外部系统)

  - 半消息方案：
    - <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250927144128427.png" alt="image-20250927144128427" style="zoom:50%;" />
    - 和异步通知的半消息方案区别是：由于第三方系统不会提供消费消息的逻辑，这部分代码由调用方系统来写，提供多档次时间的重试机制来保证数据的通知、幂等性
  - 本地消息方案：
    - <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250927144925564.png" alt="image-20250927144925564" style="zoom:50%;" />
    - 同理


#### 补偿型

##### TCC

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250512133649558.png" alt="image-20250512133649558" style="zoom:33%;" />

try-confirm-cancel

- try:调用 Try 接口，尝试执行业务，完成所有业务检查，预留业务资源
- confirm: 对业务系统做确认提交，确认执行业务操作，不做其他业务检查，只使用Try阶段预留的业务资源。也就是只要try成功，confirm一定成功，但要注意幂等性
- cancel：在业务执行错误，需要回滚的状态下执行业务取消，释放预留资源。
- Try  阶段失败可以 Cancel ，如果 Confirm  和 Cancel  阶段失败了怎么办？：TCC 中会添加事务日志，如果 Confirm 或者 Cancel 阶段出错，**则会进行重试**，所以这两个阶段需要支持幂等；**如果重试失败，则需要人工介入进行恢复和处理等**。

##### Saga

SAGA模型的核心思想是，通过某种方案，将分布式事务转化为本地事务，从而降低问题的复杂性

解决方案：

- 半消息模式：RocketMQ
- 本地消息表

#### Seata

##### AT模式(增强版2pc)

- 第一阶段：将业务数据和redo long和undolog在一个本地事务中提交，释放本地资源和连接资源
- 第二阶段：根据事务管理器的通知提交或者回滚
- 提交：删除回滚日志
- 回滚：根据回滚日志进行回滚

##### TCC模式

- 和前面的TCC一致

##### saga模式

##### XA模式



## Mybatis

# 消息队列

### 让你自己设计一个延迟队列，你要怎么设计？

### 怎么保证消息不重复？

- 这里可以从两个角度去考虑
- 首先是发送端，如果想要从发送端去确保消息不重复，可能会有一点难度。因为首先根据业务场景，去确定到底是要确保消息可靠优先，还是吞吐量优先。如果对于一致性要求特别高，这边可以在发送端就通过**类似于消息表的形式**，去确定是否发送过该消息。重复就不再发送。但是消息的消费端仍然需要做幂等处理。因为可能存在消息发出去，但是ACK丢了这种情况。
- 消息消费端的话，做**幂等**接口，判断消息消费过就丢弃。或者说采用数据库唯一键的形式。这种可能需要根据业务场景来设定。比如说消息消费时需要插入某个表，这张表有某个唯一键。那么我们就可以根据事物的特性，当发生唯一键冲突时，就进行回滚，然后告诉消息队列该消息消费完成，防止消息队列重试。**使用redis的setnx的原子性来实现幂等性也是可以的**

### 怎么保证消息不丢失？

- 思路和上边的类似，发送端发送之后，接到ACK再确认发送成功。
- 消费端执行完业务逻辑之后，再提交消费位点。

### 消息的顺序消费

- 生产者使用多线程发送消息；消息不在同一分区或者队列中；消息被不同的消费线程消费
- 同一个生产者的消息保持顺序性(订单生成、支付),实现队列选择方法，使用hash，对同一个订单选择同一个队列，这样就保持了他的顺序性

### 美团博客：消息队列设计精要

**其实我们可以把消息队列当作一个服务，即存储和转发消息的服务。**

- 首先，消息队列的设计，主要目的是为了解耦。如果不用消息队列，那么也可以使用RPC，直接调用下游的接口，等待下游的响应。而消息队列从某种角度来说，将一次RPC变为了两次RPC，即一次是发送消息的RPC调用，另一次是推送消息的RPC调用。
- 最终一致性
  - 消息队列更适合去达到一个最终的一致性，即在分布式事务中，通过消息队列来通知下游系统，如果下游事务处理失败，则配合定时任务重试，直到成功即可。
- 广播、单播
  - 即该条消息到底是发送给一个消费者，还是发送给所有的消费者，这里还有消费者组的概念，往往一个消费者组中有一个人消费了对应的消息即可。
- 错峰解耦
  - 消息队列的**Broker（服务端）**其实需要有一定的存储以及判断对应消费者消费的能力。这里其实也需要做一些负载均衡，在单播的消息消费时，一条消息只需要发送给一个消费者即可，这种可以利用最原始的轮训的负载均衡算法。
  - 消息的服务端起时还需要有存储消息的能力，即持久化消息的能力，如果不追求吞吐量，那么DB是最可靠的选择，其次就是分布式的kv集群，然后就是文件系统，但是他们的吞吐量是反过来的。
  - 这么做的目的，其实主要是为了协调消息生产者和消息的消费者速度不匹配的问题。所以消息队列要有类似于限流，以及控制推送速率的功能。
  - 消息队列的Broker可以搭建集群，这种情况下比较复杂，而且基本上只有集群环境下的消息队列才会出现丢失消息的情况。

- 可靠投递
  - 想要实现可靠投递，这种需要做一些限制。比如说消息的发送者，发送消息之前先做一次落地，即存储在DB中（本地消息表），然后再发送给服务端。**服务端这边将消息落地后，再返回给客户端发送成功。**
  - 支持广播的消息队列，**需要针对于每一个待发送的endpoint做一个状态的持久化**，然后再发送。即他需要针对于多个队列，有多个不同的消息消费位点，要单独持久化每一个。
  - 针对于每一次消费失败的问题，配合定时任务或者其他方案重试，直到成功即可。

- 消费确认
  - 允许消息的消费者响应ack，即告知broker该消息是否消费成功，然后做进一步的处理。也可以拿到消息就返回，也可以消费完再返回。

- 重复消费和顺序消费

  - 如果想要保证完全的顺序消费，是有一定的条件的
    1. 允许消息丢失
    2. 发送方到broker再到消费方，都是单点单线程。

  - 上述条件几乎无法满足，所以一般的消息队列，都只能保证单broker的消息顺序消费，如果想要多broker顺序消费，那么可能需要消费者手动去保证消息的顺序性。
  - 一个主流的消息队列，**应该是不丢消息的前提下，尽量减少重复消息，不保证消息的投递顺序。**

- 幂等

  - 这里主要涉及到两个问题：
    1. 如何鉴别消息重复，并幂等的处理重复消息。
    2. 一个消息队列如何尽量减少重复消息的投递。

  - 针对于第一个问题，一个简单的处理办法就是**每一条消息都有一个版本号**。
  - 或者可以搞一个递增的版本号。即第一条消息是1，后边是2，3。如果低于当前版本号，则拒绝消费，如果高于，则可以消费。这个需要消息的生产者携带版本号，并且消费者存储对应的版本号。如果乱序则要存储对应的消息，然后等待正确版本到来后再消费。
  - **状态机：**业务方只需要自己维护一个状态机，定义各种状态的流转关系。例如，”下线”状态只允许接收”上线”消息，“上线”状态只能接收“下线消息”，如果上线收到上线消息，或者下线收到下线消息，在消息不丢失和上游业务正确的前提下。

- 事务

  - 这里我个人觉得对于消息队列不是很重要的一点。而针对于带有消息队列的分布式事务，解决方案往往有以下两种
    1. 分布式事务的2阶段或者3阶段提交
    2. 本地事务，然后本地落地，重试补偿。

  - 这里的第二种方案，一般是业务落地和消息落地的事务，而不能是夹杂着rpc的事务，这是大忌。

### rabbitmq的事务消息了解吗

在RabbitMQ中，事务是通过AMQP协议的事务模型来实现的。这个模型提供了三个基本的操作：`tx.select`、`tx.commit`和`tx.rollback`。

1. **tx.select**：这个操作用于开启一个新的事务。在调用`tx.select`后，所有的`basic.publish`和`basic.ack`操作都会被加入到当前的事务中。
2. **tx.commit**：这个操作用于提交当前的事务。当调用`tx.commit`后，所有在当前事务中的操作都会被执行，并且如果所有的操作都成功，那么这个事务就会被提交。
3. **tx.rollback**：这个操作用于回滚当前的事务。当调用`tx.rollback`后，所有在当前事务中的操作都会被取消。

这个事务模型可以保证在一个事务中的所有操作要么全部成功，要么全部失败，从而保证了消息的一致性。

然而，需要注意的是，RabbitMQ的事务模型有一定的性能开销。**因为在一个事务中，所有的操作都需要在事务提交后才能被执行，这就意味着RabbitMQ需要在内存中保存所有的操作，直到事务被提交。**这就可能导致大量的内存消耗，特别是在处理大量消息的时候。

因此，如果你需要处理大量的消息，并且需要保证消息的一致性，那么你可能需要考虑使用其他的方法，例如使用`publisher confirms`和`consumer acks`来保证消息的一致性，这两种方法都比使用事务有更好的性能。

上述是RabbitMQ的事务消息

而rocketMQ的事物消息，是这样的：他会先发送消息到对应的队列，但是未标记该消息，该消息处于不能消费的状态。可以根据后续的一些逻辑，然后提交该消息，之后这条消息才处于可以被消费的状态。

### 死信队列知道吗？

- 当消息在一个队列中变成死信 (`dead message`) 之后，它能被重新发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列
- 导致的死信的几种原因：消息被拒、消息TTL过期、队列满了，无法再添加
- 使用死信队列可以模拟出延迟队列的功能

## RabbitMQ

### 工作原理

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250617100328962.png" alt="image-20250617100328962" style="zoom:33%;" />

- channel表示网络信道
- exchange：根据分发规则和绑定键将消息分发各queue，**不具备消息存储能力**，常用类型有direct, topic, fanout, headers
- queue:消息队列

### 交换机类型

- ### Direct Exchange

- ### Fanout Exchange

- ### Topic Exchange

- ### Headers Exchange：不依赖 `Routing Key`，而是基于消息的 `headers` 属性（键值对）进行路由，支持更复杂的匹配规则。

### 消息持久化和queue持久化

- 消息持久化：在broker中将**消息**存储在磁盘里面
- 队列持久化：如果断开和rabbitmq的连接，queue会被删除，queue里面的消息也会被删除，即便消息设置过持久化，因此可以对消息进行持久化

### 发布确认高级

有时候交换机没有对消息投递成功，这时候我们希望收到消息或者进行回调处理

#### 开启发布确认

配置文件：**spring.rabbitmq.publisher-confirm-type=correlated** ，其中correlated模式是交换机收到消息会进行回调

#### Mandatory参数

当消息不可路由时，交换机会将消息丢弃，这对于生产者是无感的，设置Mandatory可以将消息返回给生产者

```java
@PostConstruct
	private void init() {
		rabbitTemplate.setConfirmCallback(this);
		/**
		 * true：
		 * 交换机无法将消息进行路由时，会将该消息返回给生产者
		 * false：
		 * 如果发现消息无法进行路由，则直接丢弃
		 */
		rabbitTemplate.setMandatory(true);
		//设置回退消息交给谁处理
		rabbitTemplate.setReturnCallback(this);
	}
```

#### 备份交换机

普通交换机会将无法路由或者不存在队列的消息发送给备份交换，备份交换机一般是fanout类型

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250617134710976.png" alt="image-20250617134710976" style="zoom: 33%;" />

```java
//声明确认 Exchange 交换机的备份交换机,   将普通交换机和备份交换机(BACKUP_EXCHANGE_NAME)进行绑定
	@Bean("confirmExchange")
	public DirectExchange confirmExchange(){
		ExchangeBuilder exchangeBuilder =
		ExchangeBuilder.directExchange(CONFIRM_EXCHANGE_NAME)
		.durable(true)
		//设置该交换机的备份交换机
		.withArgument("alternate-exchange", BACKUP_EXCHANGE_NAME);
		return (DirectExchange)exchangeBuilder.build();
	}
```



## RocketMQ

### Rocket延时消息的底层原理

![image-20250328154033168](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250328154033168.png)

### RocektMQ怎么处理分布式事务？

例如：假设 **A** 给 **B** 转 **100块钱**，同时它们不是同一个服务上，现在目标是就是 **A** 减100块钱，**B** 加100块钱。

![image-20250328154521666](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250328154521666.png)

- 半消息：保存在brock服务端，但是消费者不能消除该消息，只有发送方commit消费者才能消费，或者发送方rollback后brock服务端删除该消息

- 事务回查：broker会定期扫描半消息列表，对长时间没有收到生产者的commit或rollback的消息，进行事务回查状态，也就是**向生产者的事务回查接口**(生产者自己实现)询问对应本地事务的执行状态

- 如果最后b服务失败如何处理：rocketmq有消息重试机制，如果重试还是失败，那么多半是b服务代码出现问题，**需要将异常记录下来，然后人工处理**

  

### 什么是本地事务

服务和数据库在同一服务器上的一系列事务

### RocketMQ如何保持顺序消息

- RocketMQ采用了局部顺序一致性的机制，实现了单个队列中的消息严格有序。也就是说，如果想要保证顺序消费，必须**将一组消息发送到同一个队列中**，然后再由消费者进行注意消费。
- 在 Producer（生产者） 把一批需要保证顺序的消息发送到同一个 MessageQueue
- Consumer（消费者） 则通过加锁的机制来保证消息消费的顺序性(或者是单线程)
- Broker 端通过对 MessageQueue 进行加锁，保证同一个 MessageQueue 只能被同一个 Consumer 进行消费

### 消息不被重复消费

幂等性:

- 在生产者端，对请求进行唯一ID标识
- 在消费者端，对消息进行唯一ID标识
- 数据库版本号+CAS

### 消息积压问题

- 增加消费者
- 服务降级



## Kaffa

<img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250328203936525.png" alt="image-20250328203936525" style="zoom:67%;" />

### kafka为什么这么快

![image-20250328200924902](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250328200924902.png)

### kafka的模型介绍一下，kafka是推送还是拉取

kafka采用拉取模型，由消费者自己记录消费状态，每个消费者互相独立地顺序拉取每个分区的消息

![image-20250328203603539](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250328203603539.png)

这里的每个消费者是不属于同一个消费者组，**不同消费者组意味着不同的消费逻辑**，**不同的消费组有相互独立的offset**



### kafka如何保证顺序消费

- topic中只有一个分区(不推荐,违背kaffa的并发设计初衷)
- 将需要顺序消费的消息发送到同一个分区，通过设置发送分区参数以及key，同一key的消费会被发送到同一分区

### kafka如何保证消息不丢失

#### 生产者消息丢失

kaffa的send()是异步方法，但get()是同步阻塞的，因此通过get()去获取调用结果不推荐

```java
SendResult<String, Object> sendResult = kafkaTemplate.send(topic, o).get();
if (sendResult.getRecordMetadata() != null) {
  logger.info("生产者成功发送消息到" + sendResult.getProducerRecord().topic() + "-> " + sendRe
              sult.getProducerRecord().value().toString());
}
```

通过回调函数方法：

```java
        ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, o);
        future.addCallback(result -> logger.info("生产者成功发送消息到topic:{} partition:{}的消息", result.getRecordMetadata().topic(), result.getRecordMetadata().partition()),
                ex -> logger.error("生产者发送消失败，原因：{}", ex.getMessage()));//可以自定义线程池
```

#### 消费者消息丢失

消费者默认在拉取到消息就会自动提交offset，如果在消费的过程中该消费者宕机就会丢失消息

- 可以改为消费完消息后手动提交，**但会有重复消费的缺点**

#### kafka丢失消息

kaffa对分区引入了多副本机制，生产者和消费者只与 leader 副本交互，我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。**如果在某一时刻follower还没有同步到leader中的消息，leader就宕机了，这样就造成了消息的丢失**

- 设置**acks=all**，所有副本接受成功才算发送成功
- **设置 replication.factor >= 3**，每个分区至少有三个副本，注意这里是为每个分区分配三个副本，并不是每个分区必须写入三个副本才算写入成功
- **设置 min.insync.replicas > 1**，这样配置代表消息至少要被写入到 **2 个副本才算是被成功发送**
- replication.factor  = min.insync.replicas + 1，这样设置即使是一个Broker 宕机了，还能满足min.insync.replicas的设置

### kafka如何保证消息不被重复消费

由于已经消费的消息没有被提交offset

- 幂等性

### kafka的重试机制



## Zookeeper

### 底层数据结构

ZooKeeper 在内存中维护了一棵**类似文件系统的树形结构**

### 四种类型节点

- 持久性节点：不主动删除就不会被删除
- 临时性节点：会话结束删除
- 持久性顺序节点：在基础类型上在节点名后会带有序号
- 临时性顺序节点：同上

### watch机制

- 作用：监听节点及节点数据的变化，并响应
- 流程：
  - 客户端向zookeeper服务器注册，包括临时节点的创建，通过特定 API（如`getData()`、`getChildren()`、`exists()`）对目标节点注册 Watch，同时指定需要监听的事件类型（如节点数据变化、子节点变化等）。
  - 服务端检测变化的节点或数据，并将变化的通知通过客户端与服务器的长连接（TCP）异步发送给客户端
  - 客户端监听到变化的消息，通过回调函数进一步进行变化处理
- 注册的数据结构：zookeeper会在内存中维护一个WatchManager(本质为哈希表),key为节点path，value为Set<Watch>:保存的是注册到给节点的watch列表
- 特性：
  - 一次性：watch只生效一次，zookeeper会根据节点path将该watch从watch哈希表中删除。故而一次性
  - 回调串行：客户端的回调是串行执行
  - 异步性：服务端发送通知事件是异步发送，也就是只能保存最终一致性
  - 会话结束后watch会失效，客户端重连后需要重新注册所有的必要watch

### zookeper实现分布式锁的原理

- 首先创建一个持久节点作为父节点，表示该分布式锁的主题
- 每一个抢锁的线程在父节点下创建临时顺序节点(带编号)，并规定：序号最小的节点表示获取到锁的线程。每个线程在创建自己的节点后，判断自己是否是最小序号节点。如果是，则获得锁；如果不是，则向前一个节点注册一个watch，并等待通知。
- 每一个获得锁的线程在释放锁时，会删除自己的节点，同时删除动作会触发后续节点的watch，以通知后续线程去获取锁

### zookeeper实现服务注册和发现

- 创建持久父节点
- 服务上线：向父节点注册临时子节点，并向父节点注册watch,监听子节点变化
- 服务下线：删除临时子节点，触发watch，通知其他服务，可用服务列表变化

## RPC

### Resttemplate

- SpringBoot提供的一种RPC的方式
- 封装了底层 **HTTP 通信细节**（如 URL 构造、参数设置、响应解析），但仍需要开发者手动控制请求的各个环节（如指定 URL、处理参数绑定、解析响应结果）

## Fegin

- 集成了rabbion(负载均衡)和hystrix(熔断和降级)

- 底层基于动态代理，默认的InvocationHandler实现类是FeginInvocationHandler,集成了hystrix后就是HystrixInvocationHandler，这些InvocationHandler中有一个Map<Method, MethodHandler>，保存的是反射Method对象和对应的MethodHandler

- ![image-20251023144236168](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20251023144236168.png)

- MethodHandler：和动态代理的InvocationHandler接口没有关系，是Fegin自定义的接口，**主要的作用是完成请求的封装发送和响应的解码**

- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20251023144250924.png" alt="image-20251023144250924" style="zoom:33%;" />

- MethodHandler中的fegin.Client是真正去发起http请求的，默认的使用HttpUrlConnection,但也可以使用OkHttp，LoadBalancerFeigin(Rabbion的负载均衡)等

- <img src="C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20251023145428210.png" alt="image-20251023145428210" style="zoom: 33%;" />

- **整个fegin客户端代理类生成的流程：**

- ```java
  1. Spring 容器启动
     ↓
  2. 解析 @EnableFeignClients 注解（该注解导入 FeignClientsRegistrar.class）
     ↓
  3. FeignClientsRegistrar 执行核心逻辑：
     a. 扫描指定包下所有带 @FeignClient 注解的接口（默认扫描当前包及子包，可通过 @EnableFeignClients(basePackages = "...") 自定义）
     b. 对每个 @FeignClient 接口，提取注解属性（服务名 name、URL、局部配置类 configuration、fallback 等）
     c. 为每个接口注册「FeignClientFactoryBean 类型的 Bean 定义」到 Spring 容器（即告诉 Spring：这个接口的实例由 FeignClientFactoryBean 负责创建）
     ↓
  4. Spring 容器初始化 Bean（触发 FeignClientFactoryBean 工作）：
     a. Spring 读取 FeignClientFactoryBean 的 Bean 定义(BeanDefinition)，实例化 FeignClientFactoryBean（本身是 Spring 管理的 Bean）
     b. FeignClientFactoryBean 初始化（实现了 ApplicationContextAware，获取 Spring 上下文；实现了 InitializingBean，校验必要属性如接口类型）
     ↓
  5. FeignClientFactoryBean 生成 Feign 代理对象（FactoryBean 核心逻辑）：
     a. 从 Spring 容器获取 FeignContext（Feign 的配置上下文，隔离不同 Feign 客户端的配置）
     b. 整合配置：从 FeignContext 中读取「全局配置」（feign.client.config.default）和「接口局部配置」（@FeignClient(configuration = ...)），组装 Feign.Builder（配置编码器、解码器、拦截器、超时时间、底层 HTTP 客户端如 OkHttp 等）
     c. 解析服务地址：若 @FeignClient 指定了 URL 则直接使用；若未指定则通过服务发现（如 Eureka、Nacos）根据服务名 name 解析真实地址
     d. 创建 Target 对象（封装接口类型、服务名、真实地址，作为 Feign 代理的目标标识）
     e. 生成动态代理：通过 Feign.Builder.target(target) 生成 JDK 动态代理对象（因为 @FeignClient 是接口，基于 JDK 代理实现）
     ↓
  6. Spring 缓存代理对象（若 FeignClientFactoryBean 的 isSingleton() 返回 true，默认单例，容器缓存代理实例）
     ↓
  7. 依赖注入：其他 Bean（如 Service 层）注入 @FeignClient 接口时，Spring 实际注入的是 FeignClientFactoryBean 生成的代理对象
     ↓
  8. 业务调用：开发者调用 @FeignClient 接口方法 → 代理对象拦截方法调用 → 转换为 HTTP 请求（基于 Feign 底层组件如 OkHttp 发起）→ 接收响应并解析返回
   
  ```

- 细化上述流程的第5步，getObject中使用了builder建造者的**target()方法去创建代理对象**，而在target方法中使用了build()方法创建一个 **ReflectiveFeign**（反射式 Feign）实例，然后调用该实例的 newInstance()方法创建远程接口最终的 JDK 动态代理实例。反射Feign代码：

- ```java
  public class ReflectiveFeign extends Feign { 
      //方法解析器 
      private final ParseHandlersByName targetToHandlersByName; 
      //调用处理器工厂 
      private final InvocationHandlerFactory factory; 
      ... 
      //创建RPC客户端动态代理实例 
      public <T> T newInstance(Target<T> target) { 
          //方法解析: 方法名和方法处理器的映射 
          Map<String, MethodHandler> nameToHandler = 
          targetToHandlersByName.apply(target); 
          //方法反射对象和方法处理器的映射 
          Map<Method, MethodHandler> methodToHandler = new LinkedHashMap<Method, 
          MethodHandler>(); 
          ... 
          //创建一个InvocationHandler调用处理器,其实例中保存Map<Method, MethodHandler> 
          InvocationHandler handler = factory.create(target, methodToHandler); 
          //最后调用JDK的Proxy.newProxyInstance创建代理对象 
          T  
          proxy = (T) Proxy.newProxyInstance( 
          target.type().getClassLoader(), new Class<?>[]{target.type()}, handler); 
          ... 
          //返回代理对象 
          return proxy; 
  	} 
  }
  ```
```java
  

#### HystrixFeign

HystrixInvocationHandler替换默认FeginInvocationHandler，代码有：
  package feign.hystrix; 
  //省略import 
  final class HystrixInvocationHandler implements InvocationHandler { 
  ... 
  //...  Map映射：Key为RPC方法的反射实例，value为方法处理器 
  private final Map<Method, MethodHandler> dispatch;  
  ... 
   
  public Object invoke(Object proxy, final Method method, final Object[] 
  args) throws Throwable { 
          //创建一个HystrixCommand命令，对同步方法调用器进行封装 
          HystrixCommand<Object> hystrixCommand = 
               new HystrixCommand<Object> 
                   ( (Setter)this.setterMethodMap.get(method) )  
  { 
                      protected Object run() throws Exception { 
                          try { //获取method对应的MethodHandler去真正处理请求
  SynchronousMethodHandler handler=HystrixInvocationHandler.this.dispatch.get(method)； 
                              return handler.invoke(args); 
                          } catch (Exception var2) { 
                              throw var2; 
                          } catch (Throwable var3) { 
                              throw (Error)var3; 
                          } 
                      } 
                      protected Object getFallback() { 
                          //省略HystrixCommand的异常回调 
                      } 
                  }; 
   
           //根据method的返回值类型，或返回hystrixCommand，或直接执行 
           if (this.isReturnsHystrixCommand(method)) { 
             return hystrixCommand; 
           } else if (this.isReturnsObservable(method)) { 
             return hystrixCommand.toObservable(); 
           } else if (this.isReturnsSingle(method)) { 
              return hystrixCommand.toObservable().toSingle(); 
           } else { 
            //直接执行 
            return this.isReturnsCompletable(method) ?  
           hystrixCommand.toObservable().toCompletable() : 
  hystrixCommand.execute(); 
           } 
           ... 
  } 
```

- ![image-20251024181104247](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20251024181104247.png)

- HystrixFegin.Builder

- 在Hystrx自定义的创建者中的build方法中在**创建代理对象是替换默认FegininvocationHandler为hystrixInvocationHandler**

- ```java
  package feign.hystrix; 
  //省略import 
  public final class HystrixFeign { 
      public HystrixFeign() { 
      } 
      //创建一个新的HystrixFeign.Builder实例 
      public static HystrixFeign.Builder builder() { 
          return new HystrixFeign.Builder(); 
  } 
      //HystrixFeign的建造者类 
      //继承了Feign默认的建造者，重写了build()方法 
      public static final class Builder extends feign.Feign.Builder { 
          public Feign build() { 
              return this.build((FallbackFactory)null); 
          } 
   
          //重载的build方法替换了基类的invocationHandlerFactory 
          //然后调用基类的build()方法建造一个ReflectiveFeign（反射式Feign）的实例 
          Feign build(final FallbackFactory<?> nullableFallbackFactory) { 
              super.invocationHandlerFactory(new InvocationHandlerFactory() { 
              //实现InvocationHandlerFactory的create方法 
              public InvocationHandler create(Target target, Map<Method, 
  MethodHandler> dispatch) 
              { 
                  //返回的是HystrixInvocationHandler 在这里进行替换！！！
                  return new HystrixInvocationHandler( 
  target, dispatch, Builder.this.setterFactory, nullableFallbackFactory); 
                  } 
              }); 
              super.contract(new HystrixDelegatingContract(this.contract)); 
              return super.build(); 
          } 
      } 
  } 
  ```

  

# 其他

### 为什么选择MongoDB

- 它是一个动态的数据结构，对于数据结构的变动来说成本很低。
- 其实它想添加一个字段，随便添加，JSON里多一个字段，根本不用改数据库那边的结构。
- 它是一个文档型数据库，半结构。
- 我们的场景允许用户自定义表单，针对于一个CRF表单，他们的字段个数是不一样的，所以很适合用这种结构。
- 主要是针对于TOB的，动态数据结构。

### 你知道什么是倒排索引吗？

- 用于在全文搜索中提供快速的文本搜索能力。倒排索引的主要思想是，对于每一个唯一的词项，都有一个包含它的文档列表。这样，当我们搜索一个词项时，Elasticsearch可以直接查找包含这个词项的所有文档，而不需要扫描每一个文档。
- 说白了，它是建立了关键词与文章的这种映射，当我们按照某一个关键词进行搜索时，就可以根据这个关键词快速的拿到对应文章的列表，然后返回即可。
- 我们就不再需要扫描每一篇文章的内容，去判断它是否包含对应的关键字。

### 分布式系统里边怎么追踪一个请求的链路呢？

### 如果调用第三方接口发生了超时，怎么保证领奖和对方转账的一致性？

业务场景为：买彩票，中奖然后领奖。其中领奖需要发起一个第三方接口的调用（支付宝或者微信），然后扣减公司钱包中的库存，然后增加用户的余额。

这里的问题就是，调用支付宝接口超时，怎么去保证**领奖成功和对方收到转账一致性呢**

> 注意，第三方接口没办法通过TCC，或者事务形消息去保证最终的一致性。因为对方不会去配合，一般都会采用本地消息表的形式。

**然后，发起远程调用跟写本地消息表，顺序是怎样的？**

两种顺序，第一种发起网络调用，再写本地消息表。

这里，网络请求是不受本地事务控制的，也就是说发出去后，对于操作无法回滚。如果刚发出去，机器就挂了，但是还没写本地消息表，就会导致不一致。

另外一种方案，就是先写本地消息表，然后再发起网络调用。这里其实也会产生不一致，就比如说刚写完本地消息表，就挂了，网络请求没有发。

> 这里要注意，不一致的原因是本地消息表是在事务中的，他失败了是要回滚的

这里的一种解决思路：采用两阶段提交这种思想。即先写本地消息表，但是本地消息表的状态处于prepare状态。然后发起网络调用，成功后改本地消息表的状态。这样，当我们扫描到一个处于prepare状态的本地消息时，就知道该消息没有被消费。这种重试对于服务的提供方来说就是重复调用，所以说我们要带唯一键，去确保幂等。

### 单体系统的问题出在哪里？

- 其实针对于一个单体系统，它的所有调用都是进程内调用，不需要考虑跨网络的进程间调用。
- 获得了进程内调用的简单、高效等好处的同时，也意味着如果任何一部分代码出现了缺陷，过度消耗了进程空间内的资源，所造成的影响也是全局性的、难以隔离的。
- 同样，由于所有代码都共享着同一个进程空间，不能隔离，也就无法（其实还是有办法的，譬如使用 OSGi 这种运行时模块化框架，但是很别扭、很复杂）做到单独停止、更新、升级某一部分代码，因为不可能有“停掉半个进程，重启 1/4 个程序”这样不合逻辑的操作，所以从可维护性来说，单体系统也是不占优势的。

### Maven依赖冲突

- 首先，相同jar不同版本，根据依赖的路径长短来决定引入哪个依赖。

  ```xml
  依赖链路一：A -> B -> C -> X(1.0)
  依赖链路二：F -> D -> X(2.0)
  ```

  该示例中，会优先使用链路2的x。

- 在依赖路径长度相等的前提下，在POM中依赖声明的顺序决定了谁会被解析使用，顺序最前的那个依赖优胜。

  ```xml
  A -> B -> Y(1.0)
  c -> D -> Y(2.0)
  ```

  该示例中，会优先使用Y(1.0)

我们可以使用如下代码：

```maven
<exclusions>
    <exclusion>
        <artifactId>poi</artifactId>
        <groupId>org.apache.poi</groupId>
    </exclusion>
</exclusions>
```

去排除对应冲突的依赖包。

### 热点数据更新业务设计

有一种方案，搞一张表，把更新操作改为插入操作，并记录每次插入时的序号，这个序号可能要全局递增。然后后续可以根据该表慢慢的去确保数据的最终一致性。

# 面试收获

其实能不加锁就不要加锁。因为怎么协商锁的时间是多少，业务执行的时间不好估计。如果业务执行中发生了死锁，或者说业务发起的rpc请求一直没有响应，可能会导致锁无法及时释放。

抖音内部很多操作可能都是不加事物的，那么说怎么保证消息的一个可靠性呢？





# 手写：

### 手写ArrayList:

```java
public class ArrayList<E>{
    private Object[] elementData;
    private size;
    private static final int DEFAULT_CAPACITY = 10;
    public ArrayList(){
    elementData = new Object[DEFAULT_CAPACITY];
    }
    public void add(E e){
        elementData[size++] = e;
    }

}
```

# 算法：

### 二分模板：

- 当我们将区间[l, r]划分成[l, mid]和[mid + 1, r]时，其更新操作是r = mid或者l = mid + 1;，计算mid时不需要加1。如果不存在目标值，返回大于/小于目标值的**最小值下标**（压缩右边界，找最小下标）

  ```c++
  int bsearch_1(int l, int r)
  {
      while (l < r)
      {
          int mid = l + r >> 1;//向下取整
          if (check(mid)) r = mid;//mid符合题意且mid在左区间，说明[l, mid]区间是符合题意的，则将r指针指到mid
          else l = mid + 1;
      }
      return l;
  }
  ```

- 当我们将区间[l, r]划分成[l, mid - 1]和[mid, r]时，其更新操作是r = mid - 1或者l = mid;，此时为了防止死循环，计算mid时需要加1，如果有序序列中没有目标值，**返回小于目标值的最大值下标**（压缩左边界，找最大下标）

- ```C++
  int bsearch_2(int l, int r)
  {
      while (l < r)
      {
          int mid = l + r + 1 >> 1;//向上取整
          if (check(mid)) l = mid;//mid符合题意且mid在右区间，说明[mid, r]符合题意(存在答案)，则将l指针指向mid
          else r = mid - 1;
      }
      return l;
  }
  ```

### 环形链表：

给定一个链表的头节点  `head` ，返回链表开始入环的第一个节点。 *如果链表无环，则返回 `null`*

```java
/**
 * Definition for singly-linked list.
 * class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode(int x) {
 *         val = x;
 *         next = null;
 *     }
 * }
 */
public class Solution {
    public ListNode detectCycle(ListNode head) {
        if(head == null){
            return null;
        }
        ListNode slow = head;
        ListNode fast = head;
        while(fast != null){
            slow = slow.next;
            fast = fast.next;
            if(fast != null){
                fast = fast.next;
            }else{
                return null;
            }

            if(slow == fast){
                ListNode p = head;
                while(p != slow){
                    p = p.next;
                    slow = slow.next;
                }
                return p;
            }
        }

        return null;
    }
}
```

### 排序算法：

![image-20250314134719076](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250314134719076.png)

![image-20250331151805939](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250331151805939.png)

- #### 冒泡排序：

  ```java
  void sort(int[] a){
      int n = a.length;
      for(int bound = 0; bound < n - 1; bound++){
          boolean isSwap = false;
          for(int i = 1; i < n - bound; i++){
              if(a[i - 1] > a[i]){
                  int sp = a[i];
                  a[i] = a[i - 1];
                  a[i] = sp;
                  isSwap = true;
              }
          }
          if(!isSwap){
              break;
          }
      }
  }
  ```

  

- #### 选择排序：

  ```java
  void sort(int[] a){
      int n = a.length;
      for(int i = 0; i < n - 1; i++){
          int minIdx = i;
          for(int j = i + 1; j < n; j++){
              if(a[j] < a[minIdx]){
                  minIdx = j;
              }
          }
          if(minIdx != i){
              int sp = a[i];
              a[i] = a[minIdx];
              a[minIdx] = sp;
          }
      }
  }
  ```

  

- #### 插入排序：

  ```java
  void sort(int[] a){
      int n = a.length;
      for(int i = 1; i < n; i++){
          int k = a[i];
          int j = i - 1;
          while(j >= 0 && a[j] > k){
              a[j + 1] = a[j];
              j--;
          } 
          a[j + 1] = k;
      }
  }
  ```

  

- #### 快速排序：

  选择一个基准，将基于元素按照大小排在基准元素两边，在对这左右两边的区间进行递归排序

  ```java
  void sort(int[] a， int s, int e){
      if(s >= e){
          return ;
      }
      int base = subSort(a, s, e);
      sort(a, s, base - 1);
      sort(a, base + 1, e);
  } 
  
  int subSort(int[] a, int low, int hight){
      int base = a[low];
      int l = low;
      int r = hight;
      while(l < r){
          while(l < r && a[r] >= base){
              --r;
          }
          a[l] = a[r];
          
          while(l < r && a[l] <= base){
              ++l;
          }
          a[r] = a[l];
      }
      a[l] = base;
      return l;
  }
  ```

  

- 归并排序

  ```java
  
  void mergeSort(int[] nums, int l, int r){
      if(l >= r){
          return ;
      }
      int m = (l + r) / 2;
      mergeSort(nums, l, m);
      mergeSort(nums, m + 1, r);
      int n = nums.length;
      int[] temp = new int[n];
      int i = l;
      int j = m + 1;
      int k = 0;
      while(i <= m && j <= r){
          if(nums[i] <= nums[j]){
              temp[k++] = nums[i++];
          }else{
              temp[k++] = nums[j++];
          }
      }
      
      while(i <= m){
          temp[k++] = nums[i++];
      }
      
      while(j <= r){
          temp[k++] = nums[j++];
      }
      
      nums = temp;
      
      
  }
  ```

  

- 在无序序列中快速找到中位数

  ```java
  int main(int[] nums){
      int n = nums.length;
      if(n % 2 == 1){
          //数量为奇数
          return quickSelect(nums, 0, n - 1, n / 2);
      }else{
          int l = quickSelect(nums, 0, n - 1, n / 2 - 1);
          int r = quickSelect(nums, 0, n - 1, n / 2);
          return (l + r) / 2;
      }
  }
  
  int quickSelect(int[] nums, int l, int r, int k){//将[l,r]以nums[l]为基准划分为两个分区，并判断划分后的nums[l]的下标位置是不是中位数下标k
      int q = quickSort(nums, l, r);
      if(k == q){
          return nums[q];
      }else if(q < k){
          return quickSelect(nums, q + 1, r, k);
      }else{
          return quickSelect(nums, l, q - 1, k);
      }
  }
  
  
  int quickSort(int[] nums, int left, int right){
      int base = nums[left];
      int l = left;
      int r = right;
      while(l < r){
          while(l < r && nums[r] >= base){
              r--;
          } 
          nums[l] = nums[r];
          while(l < r && nums[l] <= base){
              ++l;
          }
          nums[r] = nums[l];
      }
      
      nums[l] = base;
      return l;
      
  }
  ```

- 堆排序

- ```java
  void adjust(int[] a, int start, int end){
      int parent = start;
      int child = 2 * start + 1;
      while(child <= end){
          if(child + 1 <= end && a[child] < a[child + 1]) ++child;
          
          if(a[start] >= a[child]) break;
          else{
              int tmp = a[start];
              a[start] = a[child];
              a[child] = tmp;
          }
          parent = child;
          child = child * 2 + 1;
      }
  }
  
  
  void sort(int[] a){
      int n = a.length;
      //构建大根堆
      //从最后一个非叶子节点开始向上遍历，
      for(int i = (n - 1- 1) / 2; i >= 0; i--){
          adjust(a, i, n - 1);
      }
      //每次将堆顶元素方法数组最后，然后调整前半部分的堆
      for(int i = n - 1; i >= 0; i++){
          int tmp = a[i];
          a[i] = a[0];
          a[0] = tmp;
          adjust(a, 0, i - 1);
      }
  }
  ```

  

### LRU

使用HashMap和LinkedList(自定义类)

```java
class DLinked{
    int key;
    int val;
    DLinked next;
    DLinked pre;
    
    public DLinked(){}
    public DLinked(int k, int v){
        this.key = k;
        this.val = v;
    }
}

class LRU{
    Map<Integer, DLinked> mp;
    DLinked head;
    DLinked tail;
    int sz;
    int caps
    public LRU(int caps){
        this.caps = caps;
        this.sz = 0;
        mp = new HashMap<>();
        head = new DLinked();
        tail = new DLinked();
        head.next = tail;
    	tail.pre = head;
    }
    public int get(int key){
        DLinked node = mp.get(key);
        if(node == null){
            return -1;
        }
        moveToHead(node);
        return node.val;
    }
    public put(int key, int val){
        DLinked node = mp.get(key);
        if(node == null){
            DLinked newNode = new DLinked(key, val);
            mp.put(key, newNode);
            addNode(newNode);
            ++sz;
            if(sz >= caps){
                //容量不够，删除链表最后的元素
                DLinked outNode = removeTail();
                mp.remove(outNode.key);
                --sz;
            }
        }else{
            //已存在，覆盖
            node.val = val;
            moveToHead(node);
        }
    }
    
    public void moveToHead(DLinked node){
        removeNode(node);
        addNode(node);
    }
    
    public void addNode(DLinked node){
        node.pre = head;
        node.next = head.next;
        head.next.pre = node;
        head.next = node;
    }
    
    public void removeNode(DLinked node){
        node.pre.next = node.next;
        node.next.pre = node.pre;
    }
    
    public DLinked removeTail(){
        DLinked node = tail.pre;
        removeNode(node);
        return node;
    }
    
    
}
```

### 动态规划

#### 0-1背包问题：

有 N件物品和一个容量为 V的背包，每件物品有各自的价值且**只能被选择一次**，要求在有限的背包容量下，装入的物品总价值最大。

设递归函数dfs(i, v):前i件物品，且容量为v的最优解，则对于第i件物品有：

1. 选择：

   ```java
   dfs(i, v) = dfs(i - 1, v - w[i]) + value[i]
   ```

2. 不选择：

   ```java
   dfs(i, v) = dfs(i - 1, v)
   ```

综合得到：

```java
dfs(i, v) = max(dfs(i - 1, v), dfs(i - 1, v - w[i]) + value[i])
```

由递归到状态转移方程(循环)：

```java
f[i][v] = max(f[i - 1][v], f[i - 1][v - w[i]] + value[i])
```

伪代码：

```java
int[] nums
int n, m;//数量和体积
int[][] f = new int[n + 1][m + 1];
for(int i = 1; i <=n; i++){
    for(int j = 1; j <= m; i++){
        if(nums[i] > j){
            //容量不够，只能不选
            f[i][j] = f[i - 1][j];
        }else{
            f[i][j] = Math.max(f[i - 1][j], f[i - 1][j - w[i]] + value[i]);
        }
    }
}
System.out.println(f[n][m]);
```

空间优化1：二维->一维

分析状态转移方程：

```java
分析是否能够将
f[i][v] = max(f[i - 1][v], f[i - 1][v - w[i]] + value[i])//
变为：
f[v] = max(f[v], f[v - w[i]] + value[i])
```

|        | v    | v    | v    | v    | v    | v    | v    |
| ------ | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| i - 1: | 1    | 2    | 3    | 4    | 5    | 6    | 7    |
| i:     | 1    | 2    | 3    | 4    | 5    | 6    | 7    |

i行只由第i-1行的数组得到，因此如果只是单纯地变为一维(**正序**)，会使得新计算的i行的值覆盖掉第i- 1的值，导致后面的计算不是来自第i-1行，而是来自第i行。

但是，可以逆序计算第i行，这样覆盖的是高位的，不影响低位的计算

```java
int[] nums
int n, m;//数量和体积
int[] f = new int[m + 1];
for(int i = 1; i <=n; i++){
    for(int j = m; j >= numes[i]; j--){
        f[j] = Math.max(f[j], f[j - w[i]] + value[i]);
    }
}
System.out.println(f[n][m]);
```

**总结：0-1背包问题是逆序，完全背包是正序** 

#### 完全背包

有 N 种物品和一个容量是 V 的背包，每种物品都有**无限件可用**，由于每件物品是无限可用，需要考虑0，1，2....件的情况，伪代码：

```java
int[] nums
int n, m;//数量和体积
int[][] f = new int[n + 1][m + 1];
for(int i = 1; i <=n; i++){//数量
    for(int j = 0; j <= m; i++){//容量
        for(int k = 0; k * w[i] <= j; k++){//每件取得数量
            f[i][j] = Math.max(f[i - 1][j - k * w[i]] + k * value[i]);
        }
    }
}
System.out.println(f[n][m]);
```

时间优化：

```java
f[i][j] = Math.max(f[i - 1][j], f[i - 1][j - w[i]], f[i - 1][j - 2 * w[i]],...,f[i - 1][j - k * w[i]] + k * value[i]);


f[i][j - w[i]] = Math.max(f[i - 1][j - w[i]], f[i - 1][j - 2 * w[i]], f[i - 1][j - 3 * w[i]],...,f[i - 1][j - k * w[i]] + k * value[i]);

//我们发现f[i][j]可以通过f[i][j - w[i]]得来
f[i][j] = Math.max(f[i - 1][j], f[i][j - w[i]] + value[i])//!!!!!重要
```

根据上面优化的动态转移公式可以有伪代码：

```java
int[] nums
int n, m;//数量和体积
int[][] f = new int[n + 1][m + 1];
for(int i = 1; i <=n; i++){//数量
    for(int j = 0; j <= m; i++){//容量
        f[i][j] = Math.max(f[i - 1][j], f[i][j - w[i]] + value[i])；
    }
}
System.out.println(f[n][m]);
```

**空间优化：一维->二维**

根据优化后的动态转移公式，我们自然想到0-1背包的空间优化

|       | V    | V    | V    | V    | V    |
| ----- | ---- | ---- | ---- | ---- | ---- |
| I - 1 | 1    | 2    | 3    | 4    | 5    |
| I     | 1    | 2    | 3    | 4    | 5    |

根据最新的公式可知：

1. 更新第i行需要第i-1行的数据和**第i行前面的数据**
2. 假设我们使用一维，当更新后的i行的数据去覆盖第i-1行的数据，我们发现这对后面的更新不会产生影响，因为i行容量为j用到i-1行的数据只有容量j，使得i行容量j+1,j+2....不会用到更新的数据，因此完全背包可以使用正序

**最终代码：**

```java
int[] nums
int n, m;//数量和体积
int[] f = new int[m + 1];
for(int i = 1; i <=n; i++){//数量
    for(int j = 0; j <= m; i++){//容量
        f[j] = Math.max(f[j], f[j - w[i]] + value[i])；
    }
}
System.out.println(f[n][m]);
```

#### 多重背包I：

有 N 种物品和一个容量是 V的背包。第 i种物品最多有 si件，每件体积是 vi，价值是 wi。求解将哪些物品装入背包，可使物品体积总和不超过背包容量，且价值总和最大。输出最大价值。

**解题思路：**拆分为多个0-1背包，**即将si件同一种物品拆成si件不同的物品**，虽然体积和价值是一样



#### 多重背包II：

是多重背包的优化，思路：由于物品的数量有限制，我们使用二进制的方式将物品数量进行分组，比如物品有200件，分组为：1、2、4、8、16、32、64、73，每一组当成不一样的一种物品，**这样分组后，比如说选择第一第二组，相当于分组前选择这件物品第一组+第二组数量的方案**，伪代码：

```java
int[] nums
int n, m;//数量和体积
int[] f = new int[m + 1];
int[] newV;//物品的体积
int[] newValue; //物品的价值
int idx = 0;
for(int i = 1; i <= n; i++){//分组
    int s = in.next();//物品的数量
    int value = in.next();//物品的价值
    int v = in.next();//物品的体积
    int k = 1;
    while(k <= s){
        cnt++;
        newV[cnt] = k * v;
        newValue[cnt] = k * value;
        s -= k;
        k = k * 2;
    }
    
    if(s > 0){//剩余的
        cnt++;
        newV[cnt] = s * v;
        newValue[cnt++] = s * value;
    }
}
n = cnt;
for(int i = 1; i <= n; i++){//数量
    for(int j = m; j >= newV[i]; j--){//容量
        f[j] = Math.max(f[j], f[j - w[i]] + newValue[i])；
    }
}
System.out.println(f[n][m]);
```



#### 分组背包

有 N组物品和一个容量是 V的背包。每组物品有若干个，同一组内的物品最多只能选一个。每件物品的体积是 vij，价值是 wij，其中 i是组号，j是组内编号。求解将哪些物品装入背包，可使物品总体积不超过背包容量，且总价值最大。

解题思路:在0-1背包问题的基础上加一层循环，遍历每一组的不同物品选择，状态转移方程：

```java
f[j] = max(f[j], f[j - v1] + w1, f[j - v2] + w2....)
```

伪代码有：

```java
for(int i = 1; i <= n; i++){//
    for(int j = m; j >= 0; j--){
        for(int k = 0; k <= s[i]; k++){
            if(w[i][k] <= j){
                f[j] = Math.max(f[j], f[j - w[i][k]] + value[i][k]);
            }
        }
    }
}
System.out.println(f[m]);
```

#### 线性DP

![image-20250324105749362](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250324105749362.png)

![image-20250324105735443](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250324105735443.png)

![image-20250324105812173](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250324105812173.png)

#### 区间dp

![image-20250324121724270](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250324121724270.png)



![image-20250324121753773](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250324121753773.png)

```java
for (int len = 1; len <= n; len++) {         // 区间长度
    for (int i = 1; i + len - 1 <= n; i++) { // 枚举起点
        int j = i + len - 1;                 // 区间终点
        if (len == 1) {
            dp[i][j] = 初始值
            continue;
        }

        for (int k = i; k < j; k++) {        // 枚举分割点，构造状态转移方程
            dp[i][j] = min(dp[i][j], dp[i][k] + dp[k + 1][j] + w[i][j]);
        }
    }
}

```

还可以使用前缀和+记忆化搜索

计数DP：完全背包的变形

![image-20250324131700739](C:\Users\MILK\AppData\Roaming\Typora\typora-user-images\image-20250324131700739.png)

```java
f[i][j] 表示前i(1,2,3,...,i)个数,和为j的方案数(等价于前i个物品，容量为j, 数量无限)
初始值：求最值初始为0；方案数初始值为1，前i个方案都不选也是一种方案
f[i][j] = f[i - 1][j] + f[i - 1][j - i] + f[i - 1][j - 2 * i].....
f[i][j - i] = f[i - 1][j - i] + f[i - 1][j - 2 * i] + f[i - 1][j - 3 * i].....
f[i][j] = f[i - 1][j] + f[i - 1][j - i]
化简
f[j] = f[j] + f[j - i]
```



# 项目

### 超卖如何避免

- 数据库层面：使用select for update 排它锁(行锁)、where stock > 0
- 使用分布式锁：
  - setnx、解锁时要先判断加锁的是不是自己，然后再删除锁，这两个步骤不是原子性的，需要使用lua
  - redission：看门狗机制，会一段时间检测锁的状态，会对锁进行自动续时，默认为默认锁时间的一般
- 利用redis的incr、decr的原子性 + lua脚本 + 异步队列

### 库存预扣与最终扣减如何保证数据一致性？

- 使用resdis预扣库存、消息队列异步落库、补偿机制（延时消息处理超时订单）
- resdis和mysql的数据一致性：旁路策略、对于读：先读缓存，未命中读db，再写入缓存；对于写：先写db,直接删除原缓存，写入新缓存（可能存在删除失败，可以使用消息队列进行重试删除）

### 利⽤ Spring AOP切⾯注解和 Redisson分布式锁，通过加锁并设置过期时间，防⽌前端请求重复提交(短时间不能重复提交)

- 通过token构建redssion锁key
- 获得redssion锁
- 尝试加锁，设置加锁时间(0.若加锁成功则继续进行业务；  1.加锁失败则说明以及有线程加过锁(已经提交过，不能再提交了))

### 采用布隆过滤器+空值缓存防止大量恶意请求不存在的数据导致缓存穿透

- 检查布隆过滤器是否不存在(0.不存在直接返回null 1.否则查询redis缓存)
- 查询redis缓存(1.存在返回查询的值  1.缓存没有查询数据库)
- 查询数据库(返回查询结果，并同时将值放到布隆过滤器中)
- 思考：如果查询数据库也没有，是不是缓存穿透，将null放入redis呢？

### 采用CompletableFuture 构建异步处理链，分为三个阶段处理去雾操作，提高系统吞吐量，降低响应延迟

- 流程：1.同步处理，存储图片(本地或者OSS)，生成任务id ； 2.异步处理，构建访问链访问python服务，回调返回结果路径等信息；3.构建respose,返回结果

- ```java
  
  @Configuration
  public class AppConfig {
  
      // Python服务调用线程池
      @Bean(name = "pythonTaskExecutor")
      public Executor pythonTaskExecutor() {
          ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
          executor.setCorePoolSize(5);
          executor.setMaxPoolSize(10);
          executor.setQueueCapacity(25);
          executor.setThreadNamePrefix("python-task-");
          executor.initialize();
          return executor;
      }
  
      // WebClient配置
      @Bean
      public WebClient webClient() {
          return WebClient.builder().build();
      }
  }
  ```

- ```java
  @Service
  public class ImageDehazeService {
  
      @Autowired
      private TaskRepository taskRepository;
  
      @Autowired
      private WebClient webClient;
  
      @Autowired
      private MinioClient minioClient;
  
      @Value("${minio.bucket.name}")
      private String bucketName;
  
      @Value("${python.service.url}")
      private String pythonServiceUrl;
  
      // 预处理阶段（同步执行）
      public TaskInfo preprocessImage(MultipartFile file, String params) {
          try {
              // 1. 参数校验
              if (file == null || file.isEmpty()) {
                  throw new ServiceException(StatusCode.INVALID_PARAM, "图像文件不能为空");
              }
  
              // 2. 生成唯一任务ID
              String taskId = UUID.randomUUID().toString();
  
              // 3. 存储原始图像
              String originalFilePath = storeFile(file, taskId, "original");
  
              // 4. 创建并保存任务信息
              TaskInfo taskInfo = new TaskInfo();
              taskInfo.setTaskId(taskId);
              taskInfo.setOriginalFilePath(originalFilePath);
              taskInfo.setProcessingParams(params);
              taskInfo.setStatus(StatusCode.PROCESSING);
  
              return taskRepository.save(taskInfo);
  
          } catch (IOException e) {
              throw new ServiceException(StatusCode.SYSTEM_ERROR, "文件存储失败", e);
          }
      }
  
      // 模型调用阶段（异步执行）
      @Async("pythonTaskExecutor")
      public CompletableFuture<TaskInfo> invokePythonService(TaskInfo taskInfo) {
          try {
              // 构建请求参数
              ProcessRequest request = new ProcessRequest();
              request.setTaskId(taskInfo.getTaskId());
              request.setOriginalFilePath(taskInfo.getOriginalFilePath());
              request.setParams(taskInfo.getProcessingParams());
  
              // 异步调用Python服务
              return webClient.post()
                      .uri(pythonServiceUrl + "/process")
                      .body(Mono.just(request), ProcessRequest.class)
                      .retrieve()
                      .bodyToMono(ProcessResponse.class)
                      .toFuture()
                      .thenApply(response -> {
                          // 更新任务信息
                          taskInfo.setProcessedFilePath(response.getResultPath());
                          taskInfo.setProcessingTime(response.getProcessingTime());
                          return taskInfo;
                      });
  
          } catch (Exception e) {
              // 异常处理
              taskInfo.setStatus(StatusCode.FAILED);
              taskInfo.setErrorMessage(e.getMessage());
              taskRepository.save(taskInfo);
              return CompletableFuture.failedFuture(e);
          }
      }
  
      // 后处理阶段（同步执行）
      public ProcessResponse postprocessResult(TaskInfo taskInfo) {
          try {
              // 1. 更新任务状态为完成
              taskInfo.setStatus(StatusCode.SUCCESS);
              taskRepository.save(taskInfo);
  
              // 2. 构建响应对象
              ProcessResponse response = new ProcessResponse();
              response.setTaskId(taskInfo.getTaskId());
              response.setResultPath(taskInfo.getProcessedFilePath());
              response.setProcessingTime(taskInfo.getProcessingTime());
              response.setStatus(StatusCode.SUCCESS.getCode());
              response.setMessage("处理成功");
  
              return response;
  
          } catch (Exception e) {
              // 异常处理
              taskInfo.setStatus(StatusCode.FAILED);
              taskInfo.setErrorMessage(e.getMessage());
              taskRepository.save(taskInfo);
              
              throw new ServiceException(StatusCode.SYSTEM_ERROR, "后处理失败", e);
          }
      }
  
      // 文件存储方法
      private String storeFile(MultipartFile file, String taskId, String type) throws IOException {
          // 生成存储路径
          String fileName = taskId + "_" + type + "." + getFileExtension(file.getOriginalFilename());
          Path filePath = Path.of("uploads", fileName);
  
          // 保存文件
          Files.createDirectories(filePath.getParent());
          Files.copy(file.getInputStream(), filePath, StandardCopyOption.REPLACE_EXISTING);
  
          // 存储到MinIO
          minioClient.putObject(PutObjectArgs.builder()
                  .bucket(bucketName)
                  .object(fileName)
                  .stream(file.getInputStream(), file.getSize(), -1)
                  .contentType(file.getContentType())
                  .build());
  
          return fileName;
      }
  
      private String getFileExtension(String fileName) {
          if (fileName == null) return "";
          int lastIndex = fileName.lastIndexOf('.');
          return lastIndex >= 0 ? fileName.substring(lastIndex + 1) : "";
      }
  }
  ```

- ```java
  @RestController
  @RequestMapping("/api/dehaze")
  public class ImageDehazeController {
  
      @Autowired
      private ImageDehazeService dehazeService;
  
      @PostMapping(consumes = "multipart/form-data")
      public CompletableFuture<ProcessResponse> processImage(
              @RequestParam("image") MultipartFile file,
              @RequestParam(value = "params", defaultValue = "{}") String params) {
  
          // 1. 同步执行预处理
          TaskInfo taskInfo = dehazeService.preprocessImage(file, params);
  
          // 2. 异步执行模型调用和后处理
          return dehazeService.invokePythonService(taskInfo)
                  .thenApply(dehazeService::postprocessResult)
                  .exceptionally(ex -> {
                      // 统一异常处理
                      ProcessResponse response = new ProcessResponse();
                      response.setTaskId(taskInfo.getTaskId());
                      response.setStatus(500);
                      response.setMessage("处理失败: " + ex.getMessage());
                      return response;
                  });
      }
  }
  ```

  

### 自我介绍

面试官你好，我叫缪康，现就读于重庆邮电大学研二，我的专业是软件工程，我现在的技术栈是java及其集合框架和多线程，spring和spring boot，中间件rabbitmq和redis,我的项目是一个秒杀系统，我主要负责订单服务和库存服务的代码编写；我有一段在用友的实习经历，主要职责是对接erp系统，设计自定义属性，并将将PLM的BOM信息、变更信息和自定义属性对接到ERP系统。



1.登陆问题，版本不同导致加密(sm4加密)的层数不一样：之前前端没使用MD5加密，后端会对明文密码进行加密后保存。解决方法：将数据库的密码解密后在进行MD5加密，在和前端的传参进行对比

2.bom数据太多oom

3.erp第一次将bom信息传到plm系统时不希望触发返回资源图。原理：开发平台在redis存入事件和对应的事件处理接口，当在新增或修改时发布事件；事件监听器中监听到对应事件会从redis取出对应的事件处理接口，然后使用消息队列异步去执行

### 职业规划

- 1-2年：多参与实际项目的开发与调试，积累工程实践经验。这个阶段的目标是成为一名能独立负责模块开发的‘合格开发者’，少踩技术坑，提升代码质量和问题解决能力。
- 3-5年：深入Java后端，比如分布式系统，微服务或者落地AI





# AI

### RAG中的幻觉问题如何缓解?引用溯源(Citation)如何实现?

问题来源：检索的文档和原始问题无关-文档的多个chunk存在矛盾-模型没有使用现有文档或太依赖自有参数去回答问题